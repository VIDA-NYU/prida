{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we train random forest models using different definitions of 'gain' and 'loss' classes to see which one leads to the best generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ALL_FEATURES = ['query_num_of_columns', 'query_num_of_rows', 'query_row_column_ratio',\n",
    "                'query_max_skewness', 'query_max_kurtosis', 'query_max_unique', \n",
    "                'candidate_num_rows', 'candidate_max_skewness', 'candidate_max_kurtosis',\n",
    "                'candidate_max_unique', 'query_target_max_pearson', \n",
    "                'query_target_max_spearman', 'query_target_max_covariance', \n",
    "                'query_target_max_mutual_info', 'candidate_target_max_pearson', \n",
    "                'candidate_target_max_spearman', 'candidate_target_max_covariance', \n",
    "                'candidate_target_max_mutual_info', 'containment_fraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initially, we'll consider 'containment_fraction' as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml_training = pd.read_csv('training-simplified-data-generation-many-candidates-different-class-definitions.csv')\n",
    "openml_training = openml_training.drop(['median_based_class_x'], axis=1)\n",
    "openml_training = openml_training.rename(columns={'median_based_class_y':'median_based_class'})\n",
    "openml_test = pd.read_csv('test-simplified-data-generation-many-candidates-different-class-definitions.csv')\n",
    "college_debt = pd.read_csv('college-debt-different-class-definitions.csv')\n",
    "taxi_collision = pd.read_csv('taxi-vehicle-collision-different-class-definitions.csv')\n",
    "poverty_estimation = pd.read_csv('poverty-estimation-different-class-definitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(features, classes):\n",
    "    '''\n",
    "    Builds a model using features to predict associated classes\n",
    "    '''\n",
    "\n",
    "    # normalizing data first\n",
    "    # although it makes no difference in the shape of the forest,\n",
    "    # the features for the case studies and/or test data might be in \n",
    "    # totally different scales...\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    features_train = feature_scaler.fit_transform(features)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(features_train, classes)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pos_neg = train_model(openml_training[ALL_FEATURES], openml_training['class_pos_neg'])\n",
    "\n",
    "model_harsh_grad = train_model(openml_training[ALL_FEATURES], openml_training['harsh_grad_class'])\n",
    "\n",
    "model_2nd_grad_drop = train_model(openml_training[ALL_FEATURES], openml_training['2th_grad_drop_class'])\n",
    "\n",
    "model_order_of_mag_drop = train_model(openml_training[ALL_FEATURES], openml_training['order_of_mag_drop_class'])\n",
    "\n",
    "model_median_based = train_model(openml_training[ALL_FEATURES], openml_training['median_based_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    '''\n",
    "    This function normalizes features using sklearn's StandardScaler\n",
    "    '''\n",
    "    feature_scaler = StandardScaler()\n",
    "    return feature_scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.59      0.37      0.45     37058\n",
      "        loss       0.55      0.76      0.64     38680\n",
      "\n",
      "    accuracy                           0.57     75738\n",
      "   macro avg       0.57      0.56      0.55     75738\n",
      "weighted avg       0.57      0.57      0.55     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pos_neg_preds = model_pos_neg.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "test_pos_neg_preds_probs = model_pos_neg.predict_proba(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['class_pos_neg'], test_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.82      0.05      0.10      2602\n",
      "        loss       0.97      1.00      0.98     73136\n",
      "\n",
      "    accuracy                           0.97     75738\n",
      "   macro avg       0.90      0.53      0.54     75738\n",
      "weighted avg       0.96      0.97      0.95     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_harsh_grad_preds = model_harsh_grad.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "test_harsh_grad_preds_probs = model_harsh_grad.predict_proba(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['harsh_grad_class'], test_harsh_grad_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.70      0.05      0.10      5590\n",
      "        loss       0.93      1.00      0.96     70148\n",
      "\n",
      "    accuracy                           0.93     75738\n",
      "   macro avg       0.81      0.52      0.53     75738\n",
      "weighted avg       0.91      0.93      0.90     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_2nd_grad_drop_preds = model_2nd_grad_drop.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "test_2nd_grad_drop_preds_probs = model_2nd_grad_drop.predict_proba(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['2th_grad_drop_class'], test_2nd_grad_drop_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.53      0.06      0.11     13648\n",
      "        loss       0.83      0.99      0.90     62090\n",
      "\n",
      "    accuracy                           0.82     75738\n",
      "   macro avg       0.68      0.52      0.51     75738\n",
      "weighted avg       0.77      0.82      0.76     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_order_of_mag_drop_preds = model_order_of_mag_drop.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "test_order_of_mag_drop_preds_probs = model_order_of_mag_drop.predict_proba(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['order_of_mag_drop_class'], test_order_of_mag_drop_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.50      0.22      0.31     26548\n",
      "        loss       0.68      0.88      0.77     49190\n",
      "\n",
      "    accuracy                           0.65     75738\n",
      "   macro avg       0.59      0.55      0.54     75738\n",
      "weighted avg       0.61      0.65      0.60     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "openml_test = openml_test.drop(['median_based_class_x'], axis=1)\n",
    "openml_test = openml_test.rename(columns={'median_based_class_y':'median_based_class'})\n",
    "\n",
    "test_median_based_preds = model_median_based.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "test_median_based_preds_probs = model_median_based.predict_proba(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['median_based_class'], test_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well... Results were not very good for this example of test, with the best class strategy being the positive/negative one (f1-score of 0.45 for class 'gain')... Let's see how it works for the case studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.14      1.00      0.25       130\n",
      "        loss       1.00      0.18      0.30       973\n",
      "\n",
      "    accuracy                           0.28      1103\n",
      "   macro avg       0.57      0.59      0.27      1103\n",
      "weighted avg       0.90      0.28      0.30      1103\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       1.00      0.96      0.98      1102\n",
      "\n",
      "    accuracy                           0.96      1103\n",
      "   macro avg       0.50      0.48      0.49      1103\n",
      "weighted avg       1.00      0.96      0.98      1103\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.05      0.67      0.09         3\n",
      "        loss       1.00      0.97      0.98      1100\n",
      "\n",
      "    accuracy                           0.96      1103\n",
      "   macro avg       0.52      0.82      0.54      1103\n",
      "weighted avg       1.00      0.96      0.98      1103\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.18      0.50      0.26        24\n",
      "        loss       0.99      0.95      0.97      1079\n",
      "\n",
      "    accuracy                           0.94      1103\n",
      "   macro avg       0.58      0.72      0.62      1103\n",
      "weighted avg       0.97      0.94      0.95      1103\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.15      0.91      0.26       130\n",
      "        loss       0.96      0.32      0.48       973\n",
      "\n",
      "    accuracy                           0.39      1103\n",
      "   macro avg       0.56      0.61      0.37      1103\n",
      "weighted avg       0.87      0.39      0.45      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt = college_debt.rename(columns={'harsh_grad_class_y':'harsh_grad_class', \n",
    "                                       '2th_grad_drop_class_y': '2th_grad_drop_class', \n",
    "                                       'order_of_mag_drop_class_y': 'order_of_mag_drop_class',\n",
    "                                       'median_based_class_y': 'median_based_class'})\n",
    "\n",
    "college_debt_pos_neg_preds = model_pos_neg.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "college_debt_pos_neg_preds_probs = model_pos_neg.predict_proba(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_pos_neg_preds))\n",
    "\n",
    "college_debt_harsh_grad_preds = model_harsh_grad.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "college_debt_harsh_grad_preds_probs = model_harsh_grad.predict_proba(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt['harsh_grad_class'], college_debt_harsh_grad_preds))\n",
    "\n",
    "college_debt_2nd_grad_drop_preds = model_2nd_grad_drop.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "college_debt_2nd_grad_drop_preds_probs = model_2nd_grad_drop.predict_proba(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt['2th_grad_drop_class'], college_debt_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_order_of_mag_drop_preds = model_order_of_mag_drop.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "college_debt_order_of_mag_drop_preds_probs = model_order_of_mag_drop.predict_proba(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(college_debt['order_of_mag_drop_class'], college_debt_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_median_based_preds = model_median_based.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "college_debt_median_based_preds_probs = model_median_based.predict_proba(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(college_debt['median_based_class'], college_debt_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.87      0.93       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87       447\n",
      "   macro avg       0.50      0.44      0.47       447\n",
      "weighted avg       1.00      0.87      0.93       447\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         3\n",
      "        loss       0.99      0.94      0.96       444\n",
      "\n",
      "    accuracy                           0.93       447\n",
      "   macro avg       0.50      0.47      0.48       447\n",
      "weighted avg       0.99      0.93      0.96       447\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.04      0.50      0.07         4\n",
      "        loss       0.99      0.88      0.93       443\n",
      "\n",
      "    accuracy                           0.87       447\n",
      "   macro avg       0.51      0.69      0.50       447\n",
      "weighted avg       0.99      0.87      0.92       447\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.96      0.14      0.25       444\n",
      "        loss       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.14       447\n",
      "   macro avg       0.48      0.07      0.13       447\n",
      "weighted avg       0.95      0.14      0.25       447\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.49      0.89      0.63       222\n",
      "        loss       0.46      0.09      0.15       225\n",
      "\n",
      "    accuracy                           0.49       447\n",
      "   macro avg       0.47      0.49      0.39       447\n",
      "weighted avg       0.47      0.49      0.39       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_pos_neg_preds = model_pos_neg.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "taxi_collision_pos_neg_preds_probs = model_pos_neg.predict_proba(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_pos_neg_preds))\n",
    "\n",
    "taxi_collision_harsh_grad_preds = model_harsh_grad.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "taxi_collision_harsh_grad_preds_probs = model_harsh_grad.predict_proba(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision['harsh_grad_class'], taxi_collision_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_2nd_grad_drop_preds = model_2nd_grad_drop.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "taxi_collision_2nd_grad_drop_preds_probs = model_2nd_grad_drop.predict_proba(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision['2th_grad_drop_class'], taxi_collision_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_order_of_mag_drop_preds = model_order_of_mag_drop.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "taxi_collision_order_of_mag_drop_preds_probs = model_order_of_mag_drop.predict_proba(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(taxi_collision['order_of_mag_drop_class'], taxi_collision_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_median_based_preds = model_median_based.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "taxi_collision_median_based_preds_probs = model_median_based.predict_proba(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(taxi_collision['median_based_class'], taxi_collision_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.09      1.00      0.16     11526\n",
      "        loss       1.00      0.00      0.00    119402\n",
      "\n",
      "    accuracy                           0.09    130928\n",
      "   macro avg       0.54      0.50      0.08    130928\n",
      "weighted avg       0.92      0.09      0.01    130928\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       1.00      0.97      0.98    130927\n",
      "\n",
      "    accuracy                           0.97    130928\n",
      "   macro avg       0.50      0.48      0.49    130928\n",
      "weighted avg       1.00      0.97      0.98    130928\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        13\n",
      "        loss       1.00      0.92      0.96    130915\n",
      "\n",
      "    accuracy                           0.92    130928\n",
      "   macro avg       0.50      0.46      0.48    130928\n",
      "weighted avg       1.00      0.92      0.96    130928\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.08      0.15      0.10      6390\n",
      "        loss       0.95      0.90      0.93    124538\n",
      "\n",
      "    accuracy                           0.87    130928\n",
      "   macro avg       0.51      0.53      0.51    130928\n",
      "weighted avg       0.91      0.87      0.89    130928\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.09      0.89      0.17     10835\n",
      "        loss       0.96      0.24      0.38    120093\n",
      "\n",
      "    accuracy                           0.29    130928\n",
      "   macro avg       0.53      0.56      0.28    130928\n",
      "weighted avg       0.89      0.29      0.36    130928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_pos_neg_preds = model_pos_neg.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "poverty_estimation_pos_neg_preds_probs = model_pos_neg.predict_proba(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_harsh_grad_preds = model_harsh_grad.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "poverty_estimation_harsh_grad_preds_probs = model_harsh_grad.predict_proba(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation['harsh_grad_class'], poverty_estimation_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_2nd_grad_drop_preds = model_2nd_grad_drop.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "poverty_estimation_2nd_grad_drop_preds_probs = model_2nd_grad_drop.predict_proba(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation['2th_grad_drop_class'], poverty_estimation_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_order_of_mag_drop_preds = model_order_of_mag_drop.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "poverty_estimation_order_of_mag_drop_preds_probs = model_order_of_mag_drop.predict_proba(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation['order_of_mag_drop_class'], poverty_estimation_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_median_based_preds = model_median_based.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "poverty_estimation_median_based_preds_probs = model_median_based.predict_proba(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(poverty_estimation['median_based_class'], poverty_estimation_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, results are not good for case studies when we use models created over openml-train (with many candidates per query)... Low containment rates and mean imputation strategies might be creating problems here. Note that the results get worse when there are *very few* examples in class \"gain\".\n",
    "\n",
    "### Before we move on to experiments in which we only consider high containment rates, let's see which features were most important for each one of the models we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(feature_names, gini_indices):\n",
    "    '''\n",
    "    Given the names of the features and their Gini indices \n",
    "    for a given random forest model, this function prints the \n",
    "    features' importances in order.\n",
    "    '''\n",
    "    return sorted([(name, importance) for name, importance in zip(feature_names, gini_indices)],\n",
    "                  key=lambda x: x[1],\n",
    "                  reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FEATURE IMPORTANCES -- model_pos_neg\n",
      "[('candidate_target_max_spearman', 0.09327154524434599), ('candidate_target_max_pearson', 0.09269963717573605), ('candidate_max_skewness', 0.08560987541738488), ('candidate_max_kurtosis', 0.08484251778868), ('candidate_target_max_mutual_info', 0.07243872886740163), ('query_row_column_ratio', 0.06428677375367618), ('query_num_of_columns', 0.06208084094257545), ('candidate_max_unique', 0.05894097014923773), ('candidate_num_rows', 0.05747051085668549), ('query_max_kurtosis', 0.04813827898098861), ('query_target_max_spearman', 0.04759890774884748), ('query_target_max_pearson', 0.0473440303159694), ('query_max_skewness', 0.045533674264868707), ('query_target_max_mutual_info', 0.03869156670888208), ('query_max_unique', 0.03807734956417052), ('containment_fraction', 0.034187330841214066), ('query_num_of_rows', 0.025831986522149214), ('candidate_target_max_covariance', 0.0019964131553971217), ('query_target_max_covariance', 0.0009590617017893569)]\n"
     ]
    }
   ],
   "source": [
    "print('*** FEATURE IMPORTANCES -- model_pos_neg')\n",
    "print(show_feature_importances(ALL_FEATURES, model_pos_neg.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FEATURE IMPORTANCES -- model_harsh_grad\n",
      "[('candidate_target_max_pearson', 0.12845309121785464), ('candidate_target_max_spearman', 0.12679667282820742), ('candidate_max_skewness', 0.08268012547662078), ('candidate_max_kurtosis', 0.07772789793934655), ('query_row_column_ratio', 0.06956562485914608), ('candidate_target_max_mutual_info', 0.06752709580716859), ('query_num_of_columns', 0.05514659112429107), ('candidate_max_unique', 0.0483843050297933), ('query_target_max_pearson', 0.04773428644279254), ('query_target_max_spearman', 0.047406711792386196), ('query_max_kurtosis', 0.04532020057709763), ('query_max_skewness', 0.04450310005850299), ('candidate_num_rows', 0.038461371090134026), ('query_target_max_mutual_info', 0.03518462271998167), ('query_max_unique', 0.0345012678217499), ('query_num_of_rows', 0.024834090082620462), ('containment_fraction', 0.02045612683734786), ('candidate_target_max_covariance', 0.00456069437512219), ('query_target_max_covariance', 0.0007561239198360735)]\n"
     ]
    }
   ],
   "source": [
    "print('*** FEATURE IMPORTANCES -- model_harsh_grad')\n",
    "print(show_feature_importances(ALL_FEATURES, model_harsh_grad.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FEATURE IMPORTANCES -- model_2nd_grad_drop\n",
      "[('candidate_target_max_spearman', 0.12317088163047275), ('candidate_target_max_pearson', 0.11635787055716527), ('candidate_max_skewness', 0.08462908918814994), ('candidate_max_kurtosis', 0.08270441142206873), ('query_row_column_ratio', 0.07181546141796596), ('candidate_target_max_mutual_info', 0.06623251675126447), ('query_num_of_columns', 0.05865295134027073), ('candidate_max_unique', 0.05077788936991163), ('query_target_max_pearson', 0.048565333480530624), ('query_target_max_spearman', 0.04843698831217798), ('query_max_kurtosis', 0.04772405351829744), ('query_max_skewness', 0.045602710883535444), ('candidate_num_rows', 0.0414059222273426), ('query_target_max_mutual_info', 0.032218037311034835), ('query_max_unique', 0.03029921398912687), ('containment_fraction', 0.023901042213157416), ('query_num_of_rows', 0.021233675750339454), ('candidate_target_max_covariance', 0.004252139384316361), ('query_target_max_covariance', 0.002019811252871486)]\n"
     ]
    }
   ],
   "source": [
    "print('*** FEATURE IMPORTANCES -- model_2nd_grad_drop')\n",
    "print(show_feature_importances(ALL_FEATURES, model_2nd_grad_drop.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FEATURE IMPORTANCES -- model_order_of_mag_drop\n",
      "[('candidate_target_max_spearman', 0.09327154524434599), ('candidate_target_max_pearson', 0.09269963717573605), ('candidate_max_skewness', 0.08560987541738488), ('candidate_max_kurtosis', 0.08484251778868), ('candidate_target_max_mutual_info', 0.07243872886740163), ('query_row_column_ratio', 0.06428677375367618), ('query_num_of_columns', 0.06208084094257545), ('candidate_max_unique', 0.05894097014923773), ('candidate_num_rows', 0.05747051085668549), ('query_max_kurtosis', 0.04813827898098861), ('query_target_max_spearman', 0.04759890774884748), ('query_target_max_pearson', 0.0473440303159694), ('query_max_skewness', 0.045533674264868707), ('query_target_max_mutual_info', 0.03869156670888208), ('query_max_unique', 0.03807734956417052), ('containment_fraction', 0.034187330841214066), ('query_num_of_rows', 0.025831986522149214), ('candidate_target_max_covariance', 0.0019964131553971217), ('query_target_max_covariance', 0.0009590617017893569)]\n"
     ]
    }
   ],
   "source": [
    "print('*** FEATURE IMPORTANCES -- model_order_of_mag_drop')\n",
    "print(show_feature_importances(ALL_FEATURES, model_pos_neg.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** FEATURE IMPORTANCES -- model_median_based\n",
      "[('candidate_target_max_spearman', 0.09327154524434599), ('candidate_target_max_pearson', 0.09269963717573605), ('candidate_max_skewness', 0.08560987541738488), ('candidate_max_kurtosis', 0.08484251778868), ('candidate_target_max_mutual_info', 0.07243872886740163), ('query_row_column_ratio', 0.06428677375367618), ('query_num_of_columns', 0.06208084094257545), ('candidate_max_unique', 0.05894097014923773), ('candidate_num_rows', 0.05747051085668549), ('query_max_kurtosis', 0.04813827898098861), ('query_target_max_spearman', 0.04759890774884748), ('query_target_max_pearson', 0.0473440303159694), ('query_max_skewness', 0.045533674264868707), ('query_target_max_mutual_info', 0.03869156670888208), ('query_max_unique', 0.03807734956417052), ('containment_fraction', 0.034187330841214066), ('query_num_of_rows', 0.025831986522149214), ('candidate_target_max_covariance', 0.0019964131553971217), ('query_target_max_covariance', 0.0009590617017893569)]\n"
     ]
    }
   ],
   "source": [
    "print('*** FEATURE IMPORTANCES -- model_median_based')\n",
    "print(show_feature_importances(ALL_FEATURES, model_pos_neg.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's undeniable that features candidate_target_max_spearman and candidate_target_max_pearson are absolutely crucial for all the models... As a matter of fact, the ordering across the features does not vary a lot for the different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check how results change when we consider higher containment ratios alone (and stop using containment ratio as a feature). For now, just to make sure that this orthogonal issue of \"missing data imputation\" gets out of the way, I'll only consider instances (for training and test) with containment ratio $\\theta = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['query_num_of_columns', 'query_num_of_rows', 'query_row_column_ratio',\n",
    "            'query_max_skewness', 'query_max_kurtosis', 'query_max_unique', \n",
    "            'candidate_num_rows', 'candidate_max_skewness', 'candidate_max_kurtosis',\n",
    "            'candidate_max_unique', 'query_target_max_pearson', \n",
    "            'query_target_max_spearman', 'query_target_max_covariance', \n",
    "            'query_target_max_mutual_info', 'candidate_target_max_pearson', \n",
    "            'candidate_target_max_spearman', 'candidate_target_max_covariance', \n",
    "            'candidate_target_max_mutual_info']\n",
    "THETA = 1\n",
    "\n",
    "openml_training_high_containment = openml_training.loc[openml_training['containment_fraction'] >= THETA]\n",
    "\n",
    "model_pos_neg_high_containment = train_model(openml_training_high_containment[FEATURES], \n",
    "                                             openml_training_high_containment['class_pos_neg'])\n",
    "\n",
    "model_harsh_grad_high_containment = train_model(openml_training_high_containment[FEATURES], \n",
    "                                                openml_training_high_containment['harsh_grad_class'])\n",
    "\n",
    "model_2nd_grad_drop_high_containment = train_model(openml_training_high_containment[FEATURES], \n",
    "                                                   openml_training_high_containment['2th_grad_drop_class'])\n",
    "\n",
    "model_order_of_mag_drop_high_containment = train_model(openml_training_high_containment[FEATURES], \n",
    "                                                       openml_training_high_containment['order_of_mag_drop_class'])\n",
    "\n",
    "model_median_based_high_containment = train_model(openml_training_high_containment[FEATURES], \n",
    "                                                  openml_training_high_containment['median_based_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.54      0.47      0.50     19748\n",
      "        loss       0.53      0.60      0.56     20028\n",
      "\n",
      "    accuracy                           0.54     39776\n",
      "   macro avg       0.54      0.53      0.53     39776\n",
      "weighted avg       0.54      0.54      0.53     39776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "openml_test_high_containment = openml_test.loc[openml_test['containment_fraction'] >= THETA]\n",
    "\n",
    "test_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.92      0.08      0.14      1807\n",
      "        loss       0.96      1.00      0.98     37969\n",
      "\n",
      "    accuracy                           0.96     39776\n",
      "   macro avg       0.94      0.54      0.56     39776\n",
      "weighted avg       0.96      0.96      0.94     39776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['harsh_grad_class'], test_high_containment_harsh_grad_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.83      0.05      0.10      3509\n",
      "        loss       0.92      1.00      0.96     36267\n",
      "\n",
      "    accuracy                           0.92     39776\n",
      "   macro avg       0.87      0.53      0.53     39776\n",
      "weighted avg       0.91      0.92      0.88     39776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_2nd_grad_drop_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.70      0.07      0.12      8221\n",
      "        loss       0.80      0.99      0.89     31555\n",
      "\n",
      "    accuracy                           0.80     39776\n",
      "   macro avg       0.75      0.53      0.50     39776\n",
      "weighted avg       0.78      0.80      0.73     39776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['order_of_mag_drop_class'], test_high_containment_order_of_mag_drop_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.56      0.20      0.29     14622\n",
      "        loss       0.66      0.91      0.77     25154\n",
      "\n",
      "    accuracy                           0.65     39776\n",
      "   macro avg       0.61      0.55      0.53     39776\n",
      "weighted avg       0.62      0.65      0.59     39776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['median_based_class'], test_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, results seem to be better for positive/negative definition of class... Let's see how it goes to the case studies, now also with higher containment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      1.00      1.00         6\n",
      "        loss       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.44      0.50      0.47         9\n",
      "weighted avg       0.79      0.89      0.84         9\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.44      0.50      0.47         9\n",
      "weighted avg       0.79      0.89      0.84         9\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         6\n",
      "        loss       0.33      1.00      0.50         3\n",
      "\n",
      "    accuracy                           0.33         9\n",
      "   macro avg       0.17      0.50      0.25         9\n",
      "weighted avg       0.11      0.33      0.17         9\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.33      0.50         6\n",
      "        loss       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.71      0.67      0.55         9\n",
      "weighted avg       0.81      0.56      0.53         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment = college_debt.loc[college_debt['containment_fraction'] >= THETA]\n",
    "\n",
    "college_debt_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_pos_neg_preds))\n",
    "\n",
    "college_debt_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['harsh_grad_class'], college_debt_high_containment_harsh_grad_preds))\n",
    "\n",
    "college_debt_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['2th_grad_drop_class'], college_debt_high_containment_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['order_of_mag_drop_class'], college_debt_high_containment_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['median_based_class'], college_debt_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.22      0.36        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.50      0.11      0.18        18\n",
      "weighted avg       1.00      0.22      0.36        18\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.07      0.12        15\n",
      "        loss       0.18      1.00      0.30         3\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.59      0.53      0.21        18\n",
      "weighted avg       0.86      0.22      0.15        18\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.25      0.09      0.13        11\n",
      "        loss       0.29      0.57      0.38         7\n",
      "\n",
      "    accuracy                           0.28        18\n",
      "   macro avg       0.27      0.33      0.26        18\n",
      "weighted avg       0.26      0.28      0.23        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment = taxi_collision.loc[taxi_collision['containment_fraction'] >= THETA]\n",
    "\n",
    "taxi_collision_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_pos_neg_preds))\n",
    "\n",
    "taxi_collision_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['harsh_grad_class'], taxi_collision_high_containment_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['2th_grad_drop_class'], taxi_collision_high_containment_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['order_of_mag_drop_class'], taxi_collision_high_containment_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['median_based_class'], taxi_collision_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.36      0.53        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36        11\n",
      "   macro avg       0.50      0.18      0.27        11\n",
      "weighted avg       1.00      0.36      0.53        11\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        10\n",
      "        loss       0.09      1.00      0.17         1\n",
      "\n",
      "    accuracy                           0.09        11\n",
      "   macro avg       0.05      0.50      0.08        11\n",
      "weighted avg       0.01      0.09      0.02        11\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.18      0.31        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.18        11\n",
      "   macro avg       0.50      0.09      0.15        11\n",
      "weighted avg       1.00      0.18      0.31        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment = poverty_estimation.loc[poverty_estimation['containment_fraction'] >= THETA]\n",
    "\n",
    "poverty_estimation_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['harsh_grad_class'], poverty_estimation_high_containment_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['2th_grad_drop_class'], poverty_estimation_high_containment_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['order_of_mag_drop_class'], poverty_estimation_high_containment_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['median_based_class'], poverty_estimation_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results do seem to get better when no mean data imputation is performed. What if we keep the models with $\\theta = 1$ but accept a certain level of missing data imputation in test and use cases (say $\\theta = 0.5$)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.56      0.43      0.49     23212\n",
      "        loss       0.53      0.65      0.59     23169\n",
      "\n",
      "    accuracy                           0.54     46381\n",
      "   macro avg       0.54      0.54      0.54     46381\n",
      "weighted avg       0.54      0.54      0.54     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.89      0.07      0.13      2114\n",
      "        loss       0.96      1.00      0.98     44267\n",
      "\n",
      "    accuracy                           0.96     46381\n",
      "   macro avg       0.93      0.54      0.55     46381\n",
      "weighted avg       0.95      0.96      0.94     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.82      0.05      0.09      4237\n",
      "        loss       0.91      1.00      0.95     42144\n",
      "\n",
      "    accuracy                           0.91     46381\n",
      "   macro avg       0.87      0.52      0.52     46381\n",
      "weighted avg       0.90      0.91      0.87     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.69      0.06      0.12      9862\n",
      "        loss       0.80      0.99      0.88     36519\n",
      "\n",
      "    accuracy                           0.79     46381\n",
      "   macro avg       0.74      0.53      0.50     46381\n",
      "weighted avg       0.77      0.79      0.72     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.55      0.21      0.31     17380\n",
      "        loss       0.66      0.90      0.76     29001\n",
      "\n",
      "    accuracy                           0.64     46381\n",
      "   macro avg       0.60      0.55      0.53     46381\n",
      "weighted avg       0.62      0.64      0.59     46381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "THETA = 0.5\n",
    "\n",
    "openml_test_high_containment = openml_test.loc[openml_test['containment_fraction'] >= THETA]\n",
    "\n",
    "test_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_pos_neg_preds))\n",
    "\n",
    "test_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['harsh_grad_class'], test_high_containment_harsh_grad_preds))\n",
    "\n",
    "test_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_2nd_grad_drop_preds))\n",
    "\n",
    "test_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['order_of_mag_drop_class'], test_high_containment_order_of_mag_drop_preds))\n",
    "\n",
    "test_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "test_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['median_based_class'], test_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.95      0.41      0.58        92\n",
      "        loss       0.30      0.92      0.45        25\n",
      "\n",
      "    accuracy                           0.52       117\n",
      "   macro avg       0.62      0.67      0.51       117\n",
      "weighted avg       0.81      0.52      0.55       117\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       0.99      0.98      0.99       116\n",
      "\n",
      "    accuracy                           0.97       117\n",
      "   macro avg       0.50      0.49      0.49       117\n",
      "weighted avg       0.98      0.97      0.98       117\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.17      0.67      0.27         3\n",
      "        loss       0.99      0.91      0.95       114\n",
      "\n",
      "    accuracy                           0.91       117\n",
      "   macro avg       0.58      0.79      0.61       117\n",
      "weighted avg       0.97      0.91      0.93       117\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.69      0.56      0.62        16\n",
      "        loss       0.93      0.96      0.95       101\n",
      "\n",
      "    accuracy                           0.91       117\n",
      "   macro avg       0.81      0.76      0.78       117\n",
      "weighted avg       0.90      0.91      0.90       117\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.42      0.60        92\n",
      "        loss       0.32      1.00      0.49        25\n",
      "\n",
      "    accuracy                           0.55       117\n",
      "   macro avg       0.66      0.71      0.54       117\n",
      "weighted avg       0.85      0.55      0.57       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment = college_debt.loc[college_debt['containment_fraction'] >= THETA]\n",
    "\n",
    "college_debt_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_pos_neg_preds))\n",
    "\n",
    "college_debt_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['harsh_grad_class'], college_debt_high_containment_harsh_grad_preds))\n",
    "\n",
    "college_debt_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['2th_grad_drop_class'], college_debt_high_containment_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['order_of_mag_drop_class'], college_debt_high_containment_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "college_debt_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['median_based_class'], college_debt_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.22      0.36        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.50      0.11      0.18        18\n",
      "weighted avg       1.00      0.22      0.36        18\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.07      0.12        15\n",
      "        loss       0.18      1.00      0.30         3\n",
      "\n",
      "    accuracy                           0.22        18\n",
      "   macro avg       0.59      0.53      0.21        18\n",
      "weighted avg       0.86      0.22      0.15        18\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.25      0.09      0.13        11\n",
      "        loss       0.29      0.57      0.38         7\n",
      "\n",
      "    accuracy                           0.28        18\n",
      "   macro avg       0.27      0.33      0.26        18\n",
      "weighted avg       0.26      0.28      0.23        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment = taxi_collision.loc[taxi_collision['containment_fraction'] >= THETA]\n",
    "\n",
    "taxi_collision_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_pos_neg_preds))\n",
    "\n",
    "taxi_collision_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['harsh_grad_class'], taxi_collision_high_containment_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['2th_grad_drop_class'], taxi_collision_high_containment_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['order_of_mag_drop_class'], taxi_collision_high_containment_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "taxi_collision_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['median_based_class'], taxi_collision_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.36      0.53        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36        11\n",
      "   macro avg       0.50      0.18      0.27        11\n",
      "weighted avg       1.00      0.36      0.53        11\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        10\n",
      "        loss       0.09      1.00      0.17         1\n",
      "\n",
      "    accuracy                           0.09        11\n",
      "   macro avg       0.05      0.50      0.08        11\n",
      "weighted avg       0.01      0.09      0.02        11\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.18      0.31        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.18        11\n",
      "   macro avg       0.50      0.09      0.15        11\n",
      "weighted avg       1.00      0.18      0.31        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment = poverty_estimation.loc[poverty_estimation['containment_fraction'] >= THETA]\n",
    "\n",
    "poverty_estimation_high_containment_pos_neg_preds = model_pos_neg_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_pos_neg_preds_probs = model_pos_neg_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_high_containment_harsh_grad_preds = model_harsh_grad_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_harsh_grad_preds_probs = model_harsh_grad_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['harsh_grad_class'], poverty_estimation_high_containment_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_high_containment_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['2th_grad_drop_class'], poverty_estimation_high_containment_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['order_of_mag_drop_class'], poverty_estimation_high_containment_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_median_based_preds = model_median_based_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "poverty_estimation_high_containment_median_based_preds_probs = model_median_based_high_containment.predict_proba(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['median_based_class'], poverty_estimation_high_containment_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with a few more candidates, we still can say that the results are not very good, but the POSITIVE/NEGATIVE and the MEDIAN-BASED policy seem to be the best.\n",
    "\n",
    "### For all the next experiments, we'll use $\\theta = 1$ for building models and consider $\\theta = 0.5$ for test data and case studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maybe some of the features we've been using are adding problems to the data? To check this out, we'll take a minimalistic approach and create models that use only EITHER candidate_target_max_spearman OR candidate_target_max_pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEARSON = ['candidate_target_max_pearson']\n",
    "SPEARMAN = ['candidate_target_max_spearman']\n",
    "\n",
    "model_pos_neg_high_containment_pearson = train_model(openml_training_high_containment[PEARSON],\n",
    "                                                     openml_training_high_containment['class_pos_neg'])\n",
    "\n",
    "model_harsh_grad_high_containment_pearson = train_model(openml_training_high_containment[PEARSON],\n",
    "                                                        openml_training_high_containment['harsh_grad_class'])\n",
    "\n",
    "model_2nd_grad_drop_high_containment_pearson = train_model(openml_training_high_containment[PEARSON],\n",
    "                                                           openml_training_high_containment['2th_grad_drop_class'])\n",
    "\n",
    "model_order_of_mag_drop_high_containment_pearson = train_model(openml_training_high_containment[PEARSON],\n",
    "                                                               openml_training_high_containment['order_of_mag_drop_class'])\n",
    "\n",
    "model_median_based_high_containment_pearson = train_model(openml_training_high_containment[PEARSON],\n",
    "                                                          openml_training_high_containment['median_based_class'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_pos_neg_high_containment_spearman = train_model(openml_training_high_containment[SPEARMAN],\n",
    "                                                      openml_training_high_containment['class_pos_neg'])\n",
    "\n",
    "model_harsh_grad_high_containment_spearman = train_model(openml_training_high_containment[SPEARMAN],\n",
    "                                                         openml_training_high_containment['harsh_grad_class'])\n",
    "\n",
    "model_2nd_grad_drop_high_containment_spearman = train_model(openml_training_high_containment[SPEARMAN],\n",
    "                                                            openml_training_high_containment['2th_grad_drop_class'])\n",
    "\n",
    "model_order_of_mag_drop_high_containment_spearman = train_model(openml_training_high_containment[SPEARMAN],\n",
    "                                                                openml_training_high_containment['order_of_mag_drop_class'])\n",
    "\n",
    "model_median_based_high_containment_spearman = train_model(openml_training_high_containment[SPEARMAN],\n",
    "                                                          openml_training_high_containment['median_based_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with Pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.51      0.47      0.49     23212\n",
      "        loss       0.50      0.54      0.52     23169\n",
      "\n",
      "    accuracy                           0.51     46381\n",
      "   macro avg       0.51      0.51      0.51     46381\n",
      "weighted avg       0.51      0.51      0.51     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.18      0.05      0.08      2114\n",
      "        loss       0.96      0.99      0.97     44267\n",
      "\n",
      "    accuracy                           0.95     46381\n",
      "   macro avg       0.57      0.52      0.52     46381\n",
      "weighted avg       0.92      0.95      0.93     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.19      0.05      0.08      4237\n",
      "        loss       0.91      0.98      0.94     42144\n",
      "\n",
      "    accuracy                           0.89     46381\n",
      "   macro avg       0.55      0.51      0.51     46381\n",
      "weighted avg       0.85      0.89      0.86     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.23      0.13      0.17      9862\n",
      "        loss       0.79      0.88      0.83     36519\n",
      "\n",
      "    accuracy                           0.72     46381\n",
      "   macro avg       0.51      0.51      0.50     46381\n",
      "weighted avg       0.67      0.72      0.69     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.39      0.35      0.37     17380\n",
      "        loss       0.63      0.67      0.65     29001\n",
      "\n",
      "    accuracy                           0.55     46381\n",
      "   macro avg       0.51      0.51      0.51     46381\n",
      "weighted avg       0.54      0.55      0.54     46381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_pearson_pos_neg_preds = model_pos_neg_high_containment_pearson.predict(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "test_high_containment_pearson_pos_neg_preds_probs = model_pos_neg_high_containment_pearson.predict_proba(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_pearson_pos_neg_preds))\n",
    "\n",
    "test_high_containment_pearson_harsh_grad_preds = model_harsh_grad_high_containment_pearson.predict(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "test_high_containment_pearson_harsh_grad_preds_probs = model_harsh_grad_high_containment_pearson.predict_proba(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "print(classification_report(openml_test_high_containment['harsh_grad_class'], test_high_containment_pearson_harsh_grad_preds))\n",
    "\n",
    "test_high_containment_pearson_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_pearson.predict(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "test_high_containment_pearson_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_pearson.predict_proba(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_pearson_2nd_grad_drop_preds))\n",
    "\n",
    "test_high_containment_pearson_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_pearson.predict(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "test_high_containment_pearson_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_pearson.predict_proba(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "print(classification_report(openml_test_high_containment['order_of_mag_drop_class'], test_high_containment_pearson_order_of_mag_drop_preds))\n",
    "\n",
    "test_high_containment_pearson_median_based_preds = model_median_based_high_containment_pearson.predict(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "test_high_containment_pearson_median_based_preds_probs = model_median_based_high_containment_pearson.predict_proba(normalize_features(openml_test_high_containment[PEARSON]))\n",
    "print(classification_report(openml_test_high_containment['median_based_class'], test_high_containment_pearson_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.89      0.37      0.52        92\n",
      "        loss       0.27      0.84      0.40        25\n",
      "\n",
      "    accuracy                           0.47       117\n",
      "   macro avg       0.58      0.60      0.46       117\n",
      "weighted avg       0.76      0.47      0.50       117\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       0.99      0.96      0.97       116\n",
      "\n",
      "    accuracy                           0.95       117\n",
      "   macro avg       0.50      0.48      0.49       117\n",
      "weighted avg       0.98      0.95      0.97       117\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         3\n",
      "        loss       0.97      0.96      0.96       114\n",
      "\n",
      "    accuracy                           0.93       117\n",
      "   macro avg       0.49      0.48      0.48       117\n",
      "weighted avg       0.95      0.93      0.94       117\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.33      0.19      0.24        16\n",
      "        loss       0.88      0.94      0.91       101\n",
      "\n",
      "    accuracy                           0.84       117\n",
      "   macro avg       0.61      0.56      0.57       117\n",
      "weighted avg       0.80      0.84      0.82       117\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.30      0.47        92\n",
      "        loss       0.28      1.00      0.44        25\n",
      "\n",
      "    accuracy                           0.45       117\n",
      "   macro avg       0.64      0.65      0.45       117\n",
      "weighted avg       0.85      0.45      0.46       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment_pearson_pos_neg_preds = model_pos_neg_high_containment_pearson.predict(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "college_debt_high_containment_pearson_pos_neg_preds_probs = model_pos_neg_high_containment_pearson.predict_proba(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_pearson_pos_neg_preds))\n",
    "\n",
    "college_debt_high_containment_pearson_harsh_grad_preds = model_harsh_grad_high_containment_pearson.predict(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "college_debt_high_containment_pearson_harsh_grad_preds_probs = model_harsh_grad_high_containment_pearson.predict_proba(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['harsh_grad_class'], college_debt_high_containment_pearson_harsh_grad_preds))\n",
    "\n",
    "college_debt_high_containment_pearson_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_pearson.predict(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "college_debt_high_containment_pearson_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_pearson.predict_proba(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['2th_grad_drop_class'], college_debt_high_containment_pearson_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_high_containment_pearson_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_pearson.predict(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "college_debt_high_containment_pearson_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_pearson.predict_proba(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['order_of_mag_drop_class'], college_debt_high_containment_pearson_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_high_containment_pearson_median_based_preds = model_median_based_high_containment_pearson.predict(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "college_debt_high_containment_pearson_median_based_preds_probs = model_median_based_high_containment_pearson.predict_proba(normalize_features(college_debt_high_containment[PEARSON]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['median_based_class'], college_debt_high_containment_pearson_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.50      0.67        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.50      0.25      0.33        18\n",
      "weighted avg       1.00      0.50      0.67        18\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.20      0.33        15\n",
      "        loss       0.20      1.00      0.33         3\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.60      0.60      0.33        18\n",
      "weighted avg       0.87      0.33      0.33        18\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.83      0.45      0.59        11\n",
      "        loss       0.50      0.86      0.63         7\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.67      0.66      0.61        18\n",
      "weighted avg       0.70      0.61      0.61        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment_pearson_pos_neg_preds = model_pos_neg_high_containment_pearson.predict(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "taxi_collision_high_containment_pearson_pos_neg_preds_probs = model_pos_neg_high_containment_pearson.predict_proba(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_pearson_pos_neg_preds))\n",
    "\n",
    "taxi_collision_high_containment_pearson_harsh_grad_preds = model_harsh_grad_high_containment_pearson.predict(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "taxi_collision_high_containment_pearson_harsh_grad_preds_probs = model_harsh_grad_high_containment_pearson.predict_proba(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['harsh_grad_class'], taxi_collision_high_containment_pearson_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_high_containment_pearson_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_pearson.predict(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "taxi_collision_high_containment_pearson_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_pearson.predict_proba(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['2th_grad_drop_class'], taxi_collision_high_containment_pearson_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_pearson_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_pearson.predict(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "taxi_collision_high_containment_pearson_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_pearson.predict_proba(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['order_of_mag_drop_class'], taxi_collision_high_containment_pearson_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_pearson_median_based_preds = model_median_based_high_containment_pearson.predict(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "taxi_collision_high_containment_pearson_median_based_preds_probs = model_median_based_high_containment_pearson.predict_proba(normalize_features(taxi_collision_high_containment[PEARSON]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['median_based_class'], taxi_collision_high_containment_pearson_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.36      0.53        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.36        11\n",
      "   macro avg       0.50      0.18      0.27        11\n",
      "weighted avg       1.00      0.36      0.53        11\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        10\n",
      "        loss       0.09      1.00      0.17         1\n",
      "\n",
      "    accuracy                           0.09        11\n",
      "   macro avg       0.05      0.50      0.08        11\n",
      "weighted avg       0.01      0.09      0.02        11\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00      11.0\n",
      "        loss       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      11.0\n",
      "   macro avg       0.00      0.00      0.00      11.0\n",
      "weighted avg       0.00      0.00      0.00      11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment_pearson_pos_neg_preds = model_pos_neg_high_containment_pearson.predict(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "poverty_estimation_high_containment_pearson_pos_neg_preds_probs = model_pos_neg_high_containment_pearson.predict_proba(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_pearson_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_high_containment_pearson_harsh_grad_preds = model_harsh_grad_high_containment_pearson.predict(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "poverty_estimation_high_containment_pearson_harsh_grad_preds_probs = model_harsh_grad_high_containment_pearson.predict_proba(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['harsh_grad_class'], poverty_estimation_high_containment_pearson_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_high_containment_pearson_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_pearson.predict(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "poverty_estimation_high_containment_pearson_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_pearson.predict_proba(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['2th_grad_drop_class'], poverty_estimation_high_containment_pearson_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_pearson_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_pearson.predict(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "poverty_estimation_high_containment_pearson_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_pearson.predict_proba(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['order_of_mag_drop_class'], poverty_estimation_high_containment_pearson_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_pearson_median_based_preds = model_median_based_high_containment_pearson.predict(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "poverty_estimation_high_containment_pearson_median_based_preds_probs = model_median_based_high_containment_pearson.predict_proba(normalize_features(poverty_estimation_high_containment[PEARSON]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['median_based_class'], poverty_estimation_high_containment_pearson_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do the same with Spearman alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.51      0.46      0.48     23212\n",
      "        loss       0.51      0.56      0.53     23169\n",
      "\n",
      "    accuracy                           0.51     46381\n",
      "   macro avg       0.51      0.51      0.51     46381\n",
      "weighted avg       0.51      0.51      0.51     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.11      0.03      0.05      2114\n",
      "        loss       0.96      0.99      0.97     44267\n",
      "\n",
      "    accuracy                           0.95     46381\n",
      "   macro avg       0.53      0.51      0.51     46381\n",
      "weighted avg       0.92      0.95      0.93     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.14      0.04      0.06      4237\n",
      "        loss       0.91      0.98      0.94     42144\n",
      "\n",
      "    accuracy                           0.89     46381\n",
      "   macro avg       0.53      0.51      0.50     46381\n",
      "weighted avg       0.84      0.89      0.86     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.23      0.13      0.16      9862\n",
      "        loss       0.79      0.89      0.84     36519\n",
      "\n",
      "    accuracy                           0.73     46381\n",
      "   macro avg       0.51      0.51      0.50     46381\n",
      "weighted avg       0.67      0.73      0.69     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.39      0.34      0.36     17380\n",
      "        loss       0.63      0.69      0.66     29001\n",
      "\n",
      "    accuracy                           0.56     46381\n",
      "   macro avg       0.51      0.51      0.51     46381\n",
      "weighted avg       0.54      0.56      0.55     46381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_spearman_pos_neg_preds = model_pos_neg_high_containment_spearman.predict(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "test_high_containment_spearman_pos_neg_preds_probs = model_pos_neg_high_containment_spearman.predict_proba(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "test_high_containment_spearman_pos_neg_preds_probs = model_pos_neg_high_containment_spearman.predict_proba(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_spearman_pos_neg_preds))\n",
    "\n",
    "test_high_containment_spearman_harsh_grad_preds = model_harsh_grad_high_containment_spearman.predict(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "test_high_containment_spearman_harsh_grad_preds_probs = model_harsh_grad_high_containment_spearman.predict_proba(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "print(classification_report(openml_test_high_containment['harsh_grad_class'], test_high_containment_spearman_harsh_grad_preds))\n",
    "\n",
    "test_high_containment_spearman_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_spearman.predict(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "test_high_containment_spearman_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_spearman.predict_proba(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_spearman_2nd_grad_drop_preds))\n",
    "\n",
    "test_high_containment_spearman_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_spearman.predict(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "test_high_containment_spearman_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_spearman.predict_proba(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "print(classification_report(openml_test_high_containment['order_of_mag_drop_class'], test_high_containment_spearman_order_of_mag_drop_preds))\n",
    "\n",
    "test_high_containment_spearman_median_based_preds = model_median_based_high_containment_spearman.predict(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "test_high_containment_spearman_median_based_preds_probs = model_median_based_high_containment_spearman.predict_proba(normalize_features(openml_test_high_containment[SPEARMAN]))\n",
    "print(classification_report(openml_test_high_containment['median_based_class'], test_high_containment_spearman_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.85      0.36      0.50        92\n",
      "        loss       0.24      0.76      0.37        25\n",
      "\n",
      "    accuracy                           0.44       117\n",
      "   macro avg       0.54      0.56      0.44       117\n",
      "weighted avg       0.72      0.44      0.47       117\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      1.00      1.00         1\n",
      "        loss       1.00      1.00      1.00       116\n",
      "\n",
      "    accuracy                           1.00       117\n",
      "   macro avg       1.00      1.00      1.00       117\n",
      "weighted avg       1.00      1.00      1.00       117\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.33      0.50         3\n",
      "        loss       0.98      1.00      0.99       114\n",
      "\n",
      "    accuracy                           0.98       117\n",
      "   macro avg       0.99      0.67      0.75       117\n",
      "weighted avg       0.98      0.98      0.98       117\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.56      0.31      0.40        16\n",
      "        loss       0.90      0.96      0.93       101\n",
      "\n",
      "    accuracy                           0.87       117\n",
      "   macro avg       0.73      0.64      0.66       117\n",
      "weighted avg       0.85      0.87      0.86       117\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.84      0.23      0.36        92\n",
      "        loss       0.23      0.84      0.36        25\n",
      "\n",
      "    accuracy                           0.36       117\n",
      "   macro avg       0.53      0.53      0.36       117\n",
      "weighted avg       0.71      0.36      0.36       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment_spearman_pos_neg_preds = model_pos_neg_high_containment_spearman.predict(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "college_debt_high_containment_spearman_pos_neg_preds_probs = model_pos_neg_high_containment_spearman.predict_proba(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_spearman_pos_neg_preds))\n",
    "\n",
    "college_debt_high_containment_spearman_harsh_grad_preds = model_harsh_grad_high_containment_spearman.predict(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "college_debt_high_containment_spearman_harsh_grad_preds_probs = model_harsh_grad_high_containment_spearman.predict_proba(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['harsh_grad_class'], college_debt_high_containment_spearman_harsh_grad_preds))\n",
    "\n",
    "college_debt_high_containment_spearman_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_spearman.predict(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "college_debt_high_containment_spearman_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_spearman.predict_proba(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['2th_grad_drop_class'], college_debt_high_containment_spearman_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_high_containment_spearman_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_spearman.predict(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "college_debt_high_containment_spearman_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_spearman.predict_proba(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['order_of_mag_drop_class'], college_debt_high_containment_spearman_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_high_containment_spearman_median_based_preds = model_median_based_high_containment_spearman.predict(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "college_debt_high_containment_spearman_median_based_preds_probs = model_median_based_high_containment_spearman.predict_proba(normalize_features(college_debt_high_containment[SPEARMAN]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(college_debt_high_containment['median_based_class'], college_debt_high_containment_spearman_median_based_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.33      0.50        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.50      0.17      0.25        18\n",
      "weighted avg       1.00      0.33      0.50        18\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        15\n",
      "        loss       0.17      1.00      0.29         3\n",
      "\n",
      "    accuracy                           0.17        18\n",
      "   macro avg       0.08      0.50      0.14        18\n",
      "weighted avg       0.03      0.17      0.05        18\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.33      0.09      0.14        11\n",
      "        loss       0.33      0.71      0.45         7\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.33      0.40      0.30        18\n",
      "weighted avg       0.33      0.33      0.26        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment_spearman_pos_neg_preds = model_pos_neg_high_containment_spearman.predict(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "taxi_collision_high_containment_spearman_pos_neg_preds_probs = model_pos_neg_high_containment_spearman.predict_proba(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_spearman_pos_neg_preds))\n",
    "\n",
    "taxi_collision_high_containment_spearman_harsh_grad_preds = model_harsh_grad_high_containment_spearman.predict(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "taxi_collision_high_containment_spearman_harsh_grad_preds_probs = model_harsh_grad_high_containment_spearman.predict_proba(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['harsh_grad_class'], taxi_collision_high_containment_spearman_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_high_containment_spearman_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_spearman.predict(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "taxi_collision_high_containment_spearman_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_spearman.predict_proba(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['2th_grad_drop_class'], taxi_collision_high_containment_spearman_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_spearman_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_spearman.predict(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "taxi_collision_high_containment_spearman_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_spearman.predict_proba(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['order_of_mag_drop_class'], taxi_collision_high_containment_spearman_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_spearman_median_based_preds = model_median_based_high_containment_spearman.predict(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "taxi_collision_high_containment_spearman_median_based_preds_probs = model_median_based_high_containment_spearman.predict_proba(normalize_features(taxi_collision_high_containment[SPEARMAN]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(taxi_collision_high_containment['median_based_class'], taxi_collision_high_containment_spearman_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** POSITIVE AND NEGATIVE POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.64      0.78        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.50      0.32      0.39        11\n",
      "weighted avg       1.00      0.64      0.78        11\n",
      "\n",
      "**** HARSH GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** SECOND GRADIENT DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "**** ORDER OF MAGNITUDE DROP POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        10\n",
      "        loss       0.09      1.00      0.17         1\n",
      "\n",
      "    accuracy                           0.09        11\n",
      "   macro avg       0.05      0.50      0.08        11\n",
      "weighted avg       0.01      0.09      0.02        11\n",
      "\n",
      "**** MEDIAN-BASED POLICY ****\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.45      0.62        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.45        11\n",
      "   macro avg       0.50      0.23      0.31        11\n",
      "weighted avg       1.00      0.45      0.62        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment_spearman_pos_neg_preds = model_pos_neg_high_containment_spearman.predict(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "poverty_estimation_high_containment_spearman_pos_neg_preds_probs = model_pos_neg_high_containment_spearman.predict_proba(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "print('**** POSITIVE AND NEGATIVE POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_spearman_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_high_containment_spearman_harsh_grad_preds = model_harsh_grad_high_containment_spearman.predict(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "poverty_estimation_high_containment_spearman_harsh_grad_preds_probs = model_harsh_grad_high_containment_spearman.predict_proba(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "print('**** HARSH GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['harsh_grad_class'], poverty_estimation_high_containment_spearman_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_high_containment_spearman_2nd_grad_drop_preds = model_2nd_grad_drop_high_containment_spearman.predict(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "poverty_estimation_high_containment_spearman_2nd_grad_drop_preds_probs = model_2nd_grad_drop_high_containment_spearman.predict_proba(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "print('**** SECOND GRADIENT DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['2th_grad_drop_class'], poverty_estimation_high_containment_spearman_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_spearman_order_of_mag_drop_preds = model_order_of_mag_drop_high_containment_spearman.predict(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "poverty_estimation_high_containment_spearman_order_of_mag_drop_preds_probs = model_order_of_mag_drop_high_containment_spearman.predict_proba(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "print('**** ORDER OF MAGNITUDE DROP POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['order_of_mag_drop_class'], poverty_estimation_high_containment_spearman_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_spearman_median_based_preds = model_median_based_high_containment_spearman.predict(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "poverty_estimation_high_containment_spearman_median_based_preds_probs = model_median_based_high_containment_spearman.predict_proba(normalize_features(poverty_estimation_high_containment[SPEARMAN]))\n",
    "print('**** MEDIAN-BASED POLICY ****')\n",
    "print(classification_report(poverty_estimation_high_containment['median_based_class'], poverty_estimation_high_containment_spearman_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, results with positive/negative and median-based policies worked best (especially positive/negative). Note that results do get a bit worse when we use just these two features (one at a time)...\n",
    "\n",
    "### For now on, let's use FEATURES again (i.e., ALL_FEATURES - ['containment_ratio'])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if, instead of using a random forest classifier, we use SVM variations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def train_linear_svm(features, classes):\n",
    "    '''\n",
    "    Builds a model using features to predict associated classes\n",
    "    '''\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    features_train = feature_scaler.fit_transform(features)\n",
    "    \n",
    "    clf = LinearSVC(random_state=42, tol=1e-5)\n",
    "    clf.fit(features_train, classes)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_pos_neg_high_containment = train_linear_svm(openml_training_high_containment[FEATURES],\n",
    "                                                       openml_training_high_containment['class_pos_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm_harsh_grad_high_containment = train_linear_svm(openml_training_high_containment[FEATURES],\n",
    "                                                          openml_training_high_containment['harsh_grad_class'])\n",
    "\n",
    "linear_svm_2nd_grad_drop_high_containment = train_linear_svm(openml_training_high_containment[FEATURES],\n",
    "                                                             openml_training_high_containment['2th_grad_drop_class'])\n",
    "\n",
    "linear_svm_order_of_mag_drop_high_containment = train_linear_svm(openml_training_high_containment[FEATURES],\n",
    "                                                                 openml_training_high_containment['order_of_mag_drop_class'])\n",
    "\n",
    "linear_svm_median_based_high_containment = train_linear_svm(openml_training_high_containment[FEATURES],\n",
    "                                                              openml_training_high_containment['median_based_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.57      0.46      0.51     23212\n",
      "        loss       0.55      0.66      0.60     23169\n",
      "\n",
      "    accuracy                           0.56     46381\n",
      "   macro avg       0.56      0.56      0.55     46381\n",
      "weighted avg       0.56      0.56      0.55     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.00      0.00      2114\n",
      "        loss       0.95      1.00      0.98     44267\n",
      "\n",
      "    accuracy                           0.95     46381\n",
      "   macro avg       0.98      0.50      0.49     46381\n",
      "weighted avg       0.96      0.95      0.93     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.92      0.00      0.01      4237\n",
      "        loss       0.91      1.00      0.95     42144\n",
      "\n",
      "    accuracy                           0.91     46381\n",
      "   macro avg       0.92      0.50      0.48     46381\n",
      "weighted avg       0.91      0.91      0.87     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.80      0.01      0.02      9862\n",
      "        loss       0.79      1.00      0.88     36519\n",
      "\n",
      "    accuracy                           0.79     46381\n",
      "   macro avg       0.80      0.50      0.45     46381\n",
      "weighted avg       0.79      0.79      0.70     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.66      0.05      0.10     17380\n",
      "        loss       0.63      0.98      0.77     29001\n",
      "\n",
      "    accuracy                           0.64     46381\n",
      "   macro avg       0.65      0.52      0.44     46381\n",
      "weighted avg       0.65      0.64      0.52     46381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_linear_svm_pos_neg_preds = linear_svm_pos_neg_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_linear_svm_pos_neg_preds))\n",
    "\n",
    "test_high_containment_linear_svm_harsh_grad_preds = linear_svm_harsh_grad_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['harsh_grad_class'], test_high_containment_linear_svm_harsh_grad_preds))\n",
    "\n",
    "test_high_containment_linear_svm_2nd_grad_drop_preds = linear_svm_2nd_grad_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_linear_svm_2nd_grad_drop_preds))\n",
    "\n",
    "test_high_containment_linear_svm_order_of_mag_drop_preds = linear_svm_order_of_mag_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['order_of_mag_drop_class'], test_high_containment_linear_svm_order_of_mag_drop_preds))\n",
    "\n",
    "test_high_containment_linear_svm_median_based_preds = linear_svm_median_based_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['median_based_class'], test_high_containment_linear_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.15      0.26        92\n",
      "        loss       0.24      1.00      0.39        25\n",
      "\n",
      "    accuracy                           0.33       117\n",
      "   macro avg       0.62      0.58      0.33       117\n",
      "weighted avg       0.84      0.33      0.29       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       0.99      1.00      1.00       116\n",
      "\n",
      "    accuracy                           0.99       117\n",
      "   macro avg       0.50      0.50      0.50       117\n",
      "weighted avg       0.98      0.99      0.99       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         3\n",
      "        loss       0.97      1.00      0.99       114\n",
      "\n",
      "    accuracy                           0.97       117\n",
      "   macro avg       0.49      0.50      0.49       117\n",
      "weighted avg       0.95      0.97      0.96       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        16\n",
      "        loss       0.86      1.00      0.93       101\n",
      "\n",
      "    accuracy                           0.86       117\n",
      "   macro avg       0.43      0.50      0.46       117\n",
      "weighted avg       0.75      0.86      0.80       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.04      0.08        92\n",
      "        loss       0.22      1.00      0.36        25\n",
      "\n",
      "    accuracy                           0.25       117\n",
      "   macro avg       0.61      0.52      0.22       117\n",
      "weighted avg       0.83      0.25      0.14       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment_linear_svm_pos_neg_preds = linear_svm_pos_neg_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_linear_svm_pos_neg_preds))\n",
    "\n",
    "college_debt_high_containment_linear_svm_harsh_grad_preds = linear_svm_harsh_grad_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['harsh_grad_class'], college_debt_high_containment_linear_svm_harsh_grad_preds))\n",
    "\n",
    "college_debt_high_containment_linear_svm_2nd_grad_drop_preds = linear_svm_2nd_grad_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['2th_grad_drop_class'], college_debt_high_containment_linear_svm_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_high_containment_linear_svm_order_of_mag_drop_preds = linear_svm_order_of_mag_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['order_of_mag_drop_class'], college_debt_high_containment_linear_svm_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_high_containment_linear_svm_median_based_preds = linear_svm_median_based_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['median_based_class'], college_debt_high_containment_linear_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.11      0.20        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11        18\n",
      "   macro avg       0.50      0.06      0.10        18\n",
      "weighted avg       1.00      0.11      0.20        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        18\n",
      "   macro avg       1.00      1.00      1.00        18\n",
      "weighted avg       1.00      1.00      1.00        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        15\n",
      "        loss       0.17      1.00      0.29         3\n",
      "\n",
      "    accuracy                           0.17        18\n",
      "   macro avg       0.08      0.50      0.14        18\n",
      "weighted avg       0.03      0.17      0.05        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        11\n",
      "        loss       0.39      1.00      0.56         7\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.19      0.50      0.28        18\n",
      "weighted avg       0.15      0.39      0.22        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment_linear_svm_pos_neg_preds = linear_svm_pos_neg_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_linear_svm_pos_neg_preds))\n",
    "\n",
    "taxi_collision_high_containment_linear_svm_harsh_grad_preds = linear_svm_harsh_grad_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['harsh_grad_class'], taxi_collision_high_containment_linear_svm_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_high_containment_linear_svm_2nd_grad_drop_preds = linear_svm_2nd_grad_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['2th_grad_drop_class'], taxi_collision_high_containment_linear_svm_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_linear_svm_order_of_mag_drop_preds = linear_svm_order_of_mag_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['order_of_mag_drop_class'], taxi_collision_high_containment_linear_svm_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_linear_svm_median_based_preds = linear_svm_median_based_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['median_based_class'], taxi_collision_high_containment_linear_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.09      0.17        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.09        11\n",
      "   macro avg       0.50      0.05      0.08        11\n",
      "weighted avg       1.00      0.09      0.17        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00        10\n",
      "        loss       0.09      1.00      0.17         1\n",
      "\n",
      "    accuracy                           0.09        11\n",
      "   macro avg       0.05      0.50      0.08        11\n",
      "weighted avg       0.01      0.09      0.02        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00      11.0\n",
      "        loss       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      11.0\n",
      "   macro avg       0.00      0.00      0.00      11.0\n",
      "weighted avg       0.00      0.00      0.00      11.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment_linear_svm_pos_neg_preds = linear_svm_pos_neg_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_linear_svm_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_high_containment_linear_svm_harsh_grad_preds = linear_svm_harsh_grad_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['harsh_grad_class'], poverty_estimation_high_containment_linear_svm_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_high_containment_linear_svm_2nd_grad_drop_preds = linear_svm_2nd_grad_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['2th_grad_drop_class'], poverty_estimation_high_containment_linear_svm_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_linear_svm_order_of_mag_drop_preds = linear_svm_order_of_mag_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['order_of_mag_drop_class'], poverty_estimation_high_containment_linear_svm_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_linear_svm_median_based_preds = linear_svm_median_based_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['median_based_class'], poverty_estimation_high_containment_linear_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's experiment with an RBF variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def train_rbf_svm(features, classes):\n",
    "    '''\n",
    "    Builds a model using features to predict associated classes\n",
    "    '''\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    features_train = feature_scaler.fit_transform(features)\n",
    "    \n",
    "    clf = SVC(max_iter=1000, gamma='auto')\n",
    "    clf.fit(features_train, classes)\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm_pos_neg_high_containment = train_rbf_svm(openml_training_high_containment[FEATURES],\n",
    "                                                 openml_training_high_containment['class_pos_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm_harsh_grad_high_containment = train_rbf_svm(openml_training_high_containment[FEATURES],\n",
    "                                                    openml_training_high_containment['harsh_grad_class'])\n",
    "\n",
    "rbf_svm_2nd_grad_drop_high_containment = train_rbf_svm(openml_training_high_containment[FEATURES],\n",
    "                                                       openml_training_high_containment['2th_grad_drop_class'])\n",
    "\n",
    "rbf_svm_order_of_mag_drop_high_containment = train_rbf_svm(openml_training_high_containment[FEATURES],\n",
    "                                                           openml_training_high_containment['order_of_mag_drop_class'])\n",
    "\n",
    "rbf_svm_median_based_high_containment = train_rbf_svm(openml_training_high_containment[FEATURES],\n",
    "                                                        openml_training_high_containment['median_based_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.48      0.39      0.43     23212\n",
      "        loss       0.49      0.57      0.53     23169\n",
      "\n",
      "    accuracy                           0.48     46381\n",
      "   macro avg       0.48      0.48      0.48     46381\n",
      "weighted avg       0.48      0.48      0.48     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.07      0.26      0.11      2114\n",
      "        loss       0.96      0.83      0.89     44267\n",
      "\n",
      "    accuracy                           0.80     46381\n",
      "   macro avg       0.51      0.55      0.50     46381\n",
      "weighted avg       0.92      0.80      0.85     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.10      0.35      0.15      4237\n",
      "        loss       0.91      0.67      0.77     42144\n",
      "\n",
      "    accuracy                           0.64     46381\n",
      "   macro avg       0.50      0.51      0.46     46381\n",
      "weighted avg       0.84      0.64      0.72     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.23      0.61      0.33      9862\n",
      "        loss       0.80      0.44      0.57     36519\n",
      "\n",
      "    accuracy                           0.47     46381\n",
      "   macro avg       0.52      0.52      0.45     46381\n",
      "weighted avg       0.68      0.47      0.52     46381\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.36      0.39      0.37     17380\n",
      "        loss       0.61      0.58      0.60     29001\n",
      "\n",
      "    accuracy                           0.51     46381\n",
      "   macro avg       0.49      0.49      0.49     46381\n",
      "weighted avg       0.52      0.51      0.51     46381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['harsh_grad_class'], test_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['order_of_mag_drop_class'], test_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['median_based_class'], test_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.74      0.76      0.75        92\n",
      "        loss       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.60       117\n",
      "   macro avg       0.37      0.38      0.37       117\n",
      "weighted avg       0.58      0.60      0.59       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.02      1.00      0.04         1\n",
      "        loss       1.00      0.60      0.75       116\n",
      "\n",
      "    accuracy                           0.61       117\n",
      "   macro avg       0.51      0.80      0.40       117\n",
      "weighted avg       0.99      0.61      0.75       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.06      1.00      0.12         3\n",
      "        loss       1.00      0.60      0.75       114\n",
      "\n",
      "    accuracy                           0.61       117\n",
      "   macro avg       0.53      0.80      0.43       117\n",
      "weighted avg       0.98      0.61      0.73       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.12      0.62      0.20        16\n",
      "        loss       0.82      0.27      0.40       101\n",
      "\n",
      "    accuracy                           0.32       117\n",
      "   macro avg       0.47      0.45      0.30       117\n",
      "weighted avg       0.72      0.32      0.38       117\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.73      0.74      0.74        92\n",
      "        loss       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.58       117\n",
      "   macro avg       0.37      0.37      0.37       117\n",
      "weighted avg       0.57      0.58      0.58       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['harsh_grad_class'], college_debt_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['2th_grad_drop_class'], college_debt_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['order_of_mag_drop_class'], college_debt_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['median_based_class'], college_debt_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.33      0.50        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.50      0.17      0.25        18\n",
      "weighted avg       1.00      0.33      0.50        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         0\n",
      "        loss       1.00      0.72      0.84        18\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.50      0.36      0.42        18\n",
      "weighted avg       1.00      0.72      0.84        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         0\n",
      "        loss       1.00      0.72      0.84        18\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.50      0.36      0.42        18\n",
      "weighted avg       1.00      0.72      0.84        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.86      0.80      0.83        15\n",
      "        loss       0.25      0.33      0.29         3\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.55      0.57      0.56        18\n",
      "weighted avg       0.76      0.72      0.74        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.50      0.27      0.35        11\n",
      "        loss       0.33      0.57      0.42         7\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.42      0.42      0.39        18\n",
      "weighted avg       0.44      0.39      0.38        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['harsh_grad_class'], taxi_collision_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['2th_grad_drop_class'], taxi_collision_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['order_of_mag_drop_class'], taxi_collision_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['median_based_class'], taxi_collision_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.55      0.71        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.50      0.27      0.35        11\n",
      "weighted avg       1.00      0.55      0.71        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         0\n",
      "        loss       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.70      0.82        10\n",
      "        loss       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.62      0.85      0.61        11\n",
      "weighted avg       0.93      0.73      0.79        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.82      0.90        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['harsh_grad_class'], poverty_estimation_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['2th_grad_drop_class'], poverty_estimation_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['order_of_mag_drop_class'], poverty_estimation_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['median_based_class'], poverty_estimation_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks like the SVM-RBF classifier was in fact the best for our problem! This is not in line with the results we had from the AutoML pipeline, but probably because of the class policy we were using, and because of the data we were using. \n",
    "\n",
    "### Let's see how SVM-RBF works for when $\\theta = 1$ not only for the training data but also for the test data and case studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 1\n",
    "openml_test_high_containment = openml_test.loc[openml_test['containment_fraction'] >= THETA]\n",
    "college_debt_high_containment = college_debt.loc[college_debt['containment_fraction'] >= THETA]\n",
    "taxi_collision_high_containment = taxi_collision.loc[taxi_collision['containment_fraction'] >= THETA]\n",
    "poverty_estimation_high_containment = poverty_estimation.loc[poverty_estimation['containment_fraction'] >= THETA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.48      0.40      0.43     19748\n",
      "        loss       0.49      0.57      0.53     20028\n",
      "\n",
      "    accuracy                           0.48     39776\n",
      "   macro avg       0.48      0.48      0.48     39776\n",
      "weighted avg       0.48      0.48      0.48     39776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.07      0.28      0.12      1807\n",
      "        loss       0.96      0.83      0.89     37969\n",
      "\n",
      "    accuracy                           0.80     39776\n",
      "   macro avg       0.52      0.56      0.50     39776\n",
      "weighted avg       0.92      0.80      0.85     39776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.10      0.37      0.15      3509\n",
      "        loss       0.92      0.66      0.77     36267\n",
      "\n",
      "    accuracy                           0.63     39776\n",
      "   macro avg       0.51      0.51      0.46     39776\n",
      "weighted avg       0.84      0.63      0.71     39776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.22      0.60      0.32      8221\n",
      "        loss       0.81      0.45      0.58     31555\n",
      "\n",
      "    accuracy                           0.48     39776\n",
      "   macro avg       0.52      0.52      0.45     39776\n",
      "weighted avg       0.69      0.48      0.52     39776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.35      0.40      0.37     14622\n",
      "        loss       0.62      0.58      0.60     25154\n",
      "\n",
      "    accuracy                           0.51     39776\n",
      "   macro avg       0.49      0.49      0.49     39776\n",
      "weighted avg       0.52      0.51      0.52     39776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['harsh_grad_class'], test_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['order_of_mag_drop_class'], test_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "test_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['median_based_class'], test_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.57      0.67      0.62         6\n",
      "        loss       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.29      0.33      0.31         9\n",
      "weighted avg       0.38      0.44      0.41         9\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         1\n",
      "        loss       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.89         9\n",
      "   macro avg       0.44      0.50      0.47         9\n",
      "weighted avg       0.79      0.89      0.84         9\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.25      1.00      0.40         1\n",
      "        loss       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.67         9\n",
      "   macro avg       0.62      0.81      0.58         9\n",
      "weighted avg       0.92      0.67      0.73         9\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.67      0.80         6\n",
      "        loss       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.80      0.83      0.77         9\n",
      "weighted avg       0.87      0.78      0.78         9\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.67      0.80         6\n",
      "        loss       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.78         9\n",
      "   macro avg       0.80      0.83      0.77         9\n",
      "weighted avg       0.87      0.78      0.78         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['harsh_grad_class'], college_debt_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['2th_grad_drop_class'], college_debt_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['order_of_mag_drop_class'], college_debt_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['median_based_class'], college_debt_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.33      0.50        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.50      0.17      0.25        18\n",
      "weighted avg       1.00      0.33      0.50        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         0\n",
      "        loss       1.00      0.72      0.84        18\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.50      0.36      0.42        18\n",
      "weighted avg       1.00      0.72      0.84        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         0\n",
      "        loss       1.00      0.72      0.84        18\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.50      0.36      0.42        18\n",
      "weighted avg       1.00      0.72      0.84        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.86      0.80      0.83        15\n",
      "        loss       0.25      0.33      0.29         3\n",
      "\n",
      "    accuracy                           0.72        18\n",
      "   macro avg       0.55      0.57      0.56        18\n",
      "weighted avg       0.76      0.72      0.74        18\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.50      0.27      0.35        11\n",
      "        loss       0.33      0.57      0.42         7\n",
      "\n",
      "    accuracy                           0.39        18\n",
      "   macro avg       0.42      0.42      0.39        18\n",
      "weighted avg       0.44      0.39      0.38        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['harsh_grad_class'], taxi_collision_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['2th_grad_drop_class'], taxi_collision_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['order_of_mag_drop_class'], taxi_collision_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['median_based_class'], taxi_collision_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.55      0.71        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.50      0.27      0.35        11\n",
      "weighted avg       1.00      0.55      0.71        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        loss       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         0\n",
      "        loss       1.00      0.82      0.90        11\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.70      0.82        10\n",
      "        loss       0.25      1.00      0.40         1\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.62      0.85      0.61        11\n",
      "weighted avg       0.93      0.73      0.79        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.82      0.90        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_rbf_svm_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['harsh_grad_class'], poverty_estimation_high_containment_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['2th_grad_drop_class'], poverty_estimation_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['order_of_mag_drop_class'], poverty_estimation_high_containment_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_high_containment_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['median_based_class'], poverty_estimation_high_containment_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about using this SVM-RBF model trained with $\\theta = 1$ over test data and use cases with $\\theta = 0$ (i.e., over all the test and use case data)? Here, 'containment ratio' is not a feature again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.45      0.40      0.42     37058\n",
      "        loss       0.48      0.54      0.51     38680\n",
      "\n",
      "    accuracy                           0.47     75738\n",
      "   macro avg       0.47      0.47      0.47     75738\n",
      "weighted avg       0.47      0.47      0.47     75738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.04      0.24      0.07      2602\n",
      "        loss       0.97      0.81      0.88     73136\n",
      "\n",
      "    accuracy                           0.79     75738\n",
      "   macro avg       0.51      0.52      0.48     75738\n",
      "weighted avg       0.94      0.79      0.86     75738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.10      0.37      0.15      3509\n",
      "        loss       0.92      0.66      0.77     36267\n",
      "\n",
      "    accuracy                           0.63     39776\n",
      "   macro avg       0.51      0.51      0.46     39776\n",
      "weighted avg       0.84      0.63      0.71     39776\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.20      0.60      0.30     13648\n",
      "        loss       0.84      0.47      0.60     62090\n",
      "\n",
      "    accuracy                           0.49     75738\n",
      "   macro avg       0.52      0.53      0.45     75738\n",
      "weighted avg       0.72      0.49      0.54     75738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.33      0.39      0.35     26548\n",
      "        loss       0.63      0.57      0.60     49190\n",
      "\n",
      "    accuracy                           0.51     75738\n",
      "   macro avg       0.48      0.48      0.48     75738\n",
      "weighted avg       0.53      0.51      0.51     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print(classification_report(openml_test['class_pos_neg'], test_rbf_svm_pos_neg_preds))\n",
    "\n",
    "test_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print(classification_report(openml_test['harsh_grad_class'], test_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "test_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['2th_grad_drop_class'], test_high_containment_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "test_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print(classification_report(openml_test['order_of_mag_drop_class'], test_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "test_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print(classification_report(openml_test['median_based_class'], test_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.37      0.94      0.53       130\n",
      "        loss       0.99      0.78      0.88       973\n",
      "\n",
      "    accuracy                           0.80      1103\n",
      "   macro avg       0.68      0.86      0.70      1103\n",
      "weighted avg       0.92      0.80      0.83      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      1.00      0.00         1\n",
      "        loss       1.00      0.63      0.77      1102\n",
      "\n",
      "    accuracy                           0.63      1103\n",
      "   macro avg       0.50      0.81      0.39      1103\n",
      "weighted avg       1.00      0.63      0.77      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.01      1.00      0.01         3\n",
      "        loss       1.00      0.47      0.64      1100\n",
      "\n",
      "    accuracy                           0.47      1103\n",
      "   macro avg       0.50      0.73      0.32      1103\n",
      "weighted avg       1.00      0.47      0.64      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.01      0.17      0.01        24\n",
      "        loss       0.95      0.32      0.48      1079\n",
      "\n",
      "    accuracy                           0.32      1103\n",
      "   macro avg       0.48      0.24      0.25      1103\n",
      "weighted avg       0.93      0.32      0.47      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.44      0.85      0.58       130\n",
      "        loss       0.98      0.86      0.91       973\n",
      "\n",
      "    accuracy                           0.86      1103\n",
      "   macro avg       0.71      0.86      0.75      1103\n",
      "weighted avg       0.91      0.86      0.87      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_rbf_svm_pos_neg_preds))\n",
    "\n",
    "college_debt_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print(classification_report(college_debt['harsh_grad_class'], college_debt_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "college_debt_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print(classification_report(college_debt['2th_grad_drop_class'], college_debt_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print(classification_report(college_debt['order_of_mag_drop_class'], college_debt_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print(classification_report(college_debt['median_based_class'], college_debt_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.71      0.83       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.71       447\n",
      "   macro avg       0.50      0.36      0.42       447\n",
      "weighted avg       1.00      0.71      0.83       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         3\n",
      "        loss       0.99      0.88      0.93       444\n",
      "\n",
      "    accuracy                           0.87       447\n",
      "   macro avg       0.50      0.44      0.47       447\n",
      "weighted avg       0.99      0.87      0.93       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00         4\n",
      "        loss       0.99      0.68      0.80       443\n",
      "\n",
      "    accuracy                           0.67       447\n",
      "   macro avg       0.49      0.34      0.40       447\n",
      "weighted avg       0.98      0.67      0.80       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.42      0.59       444\n",
      "        loss       0.01      1.00      0.02         3\n",
      "\n",
      "    accuracy                           0.43       447\n",
      "   macro avg       0.51      0.71      0.31       447\n",
      "weighted avg       0.99      0.43      0.59       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.55      0.65      0.60       222\n",
      "        loss       0.58      0.48      0.53       225\n",
      "\n",
      "    accuracy                           0.57       447\n",
      "   macro avg       0.57      0.57      0.56       447\n",
      "weighted avg       0.57      0.57      0.56       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_rbf_svm_pos_neg_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print(classification_report(taxi_collision['harsh_grad_class'], taxi_collision_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print(classification_report(taxi_collision['2th_grad_drop_class'], taxi_collision_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print(classification_report(taxi_collision['order_of_mag_drop_class'], taxi_collision_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print(classification_report(taxi_collision['median_based_class'], taxi_collision_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.09      0.23      0.13     11526\n",
      "        loss       0.91      0.77      0.84    119402\n",
      "\n",
      "    accuracy                           0.72    130928\n",
      "   macro avg       0.50      0.50      0.48    130928\n",
      "weighted avg       0.84      0.72      0.77    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      1.00      0.00         1\n",
      "        loss       1.00      0.88      0.93    130927\n",
      "\n",
      "    accuracy                           0.88    130928\n",
      "   macro avg       0.50      0.94      0.47    130928\n",
      "weighted avg       1.00      0.88      0.93    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.08      0.00        13\n",
      "        loss       1.00      0.77      0.87    130915\n",
      "\n",
      "    accuracy                           0.77    130928\n",
      "   macro avg       0.50      0.42      0.44    130928\n",
      "weighted avg       1.00      0.77      0.87    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.03      0.30      0.06      6390\n",
      "        loss       0.94      0.52      0.67    124538\n",
      "\n",
      "    accuracy                           0.51    130928\n",
      "   macro avg       0.48      0.41      0.36    130928\n",
      "weighted avg       0.89      0.51      0.64    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.09      0.22      0.12     10835\n",
      "        loss       0.92      0.79      0.85    120093\n",
      "\n",
      "    accuracy                           0.74    130928\n",
      "   macro avg       0.50      0.50      0.49    130928\n",
      "weighted avg       0.85      0.74      0.79    130928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_rbf_svm_pos_neg_preds = rbf_svm_pos_neg_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_rbf_svm_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print(classification_report(poverty_estimation['harsh_grad_class'], poverty_estimation_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print(classification_report(poverty_estimation['2th_grad_drop_class'], poverty_estimation_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print(classification_report(poverty_estimation['order_of_mag_drop_class'], poverty_estimation_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_median_based_preds = rbf_svm_median_based_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print(classification_report(poverty_estimation['median_based_class'], poverty_estimation_rbf_svm_median_based_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about if we train an ordinary SVM-RBF model over openml_training using ALL_FEATURES and $\\theta = 0$ and see how it works over all test and use case data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm_pos_neg = train_rbf_svm(openml_training[ALL_FEATURES],\n",
    "                                openml_training['class_pos_neg'])\n",
    "\n",
    "rbf_svm_harsh_grad = train_rbf_svm(openml_training[ALL_FEATURES],\n",
    "                                   openml_training['harsh_grad_class'])\n",
    "\n",
    "rbf_svm_2nd_grad_drop = train_rbf_svm(openml_training[ALL_FEATURES],\n",
    "                                      openml_training['2th_grad_drop_class'])\n",
    "\n",
    "rbf_svm_order_of_mag_drop = train_rbf_svm(openml_training[ALL_FEATURES],\n",
    "                                          openml_training['order_of_mag_drop_class'])\n",
    "\n",
    "rbf_svm_median_based = train_rbf_svm(openml_training[ALL_FEATURES],\n",
    "                                     openml_training['median_based_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.47      0.46      0.46     37058\n",
      "        loss       0.49      0.51      0.50     38680\n",
      "\n",
      "    accuracy                           0.48     75738\n",
      "   macro avg       0.48      0.48      0.48     75738\n",
      "weighted avg       0.48      0.48      0.48     75738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.05      0.33      0.09      2602\n",
      "        loss       0.97      0.80      0.88     73136\n",
      "\n",
      "    accuracy                           0.78     75738\n",
      "   macro avg       0.51      0.56      0.48     75738\n",
      "weighted avg       0.94      0.78      0.85     75738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.09      0.43      0.14      5590\n",
      "        loss       0.93      0.63      0.76     70148\n",
      "\n",
      "    accuracy                           0.62     75738\n",
      "   macro avg       0.51      0.53      0.45     75738\n",
      "weighted avg       0.87      0.62      0.71     75738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.19      0.83      0.30     13648\n",
      "        loss       0.84      0.20      0.32     62090\n",
      "\n",
      "    accuracy                           0.31     75738\n",
      "   macro avg       0.51      0.52      0.31     75738\n",
      "weighted avg       0.73      0.31      0.32     75738\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.35      0.48      0.40     26548\n",
      "        loss       0.65      0.52      0.58     49190\n",
      "\n",
      "    accuracy                           0.51     75738\n",
      "   macro avg       0.50      0.50      0.49     75738\n",
      "weighted avg       0.55      0.51      0.52     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_rbf_svm_pos_neg_preds = rbf_svm_pos_neg.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['class_pos_neg'], test_rbf_svm_pos_neg_preds))\n",
    "\n",
    "test_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['harsh_grad_class'], test_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "test_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['2th_grad_drop_class'], test_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "test_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['order_of_mag_drop_class'], test_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "test_rbf_svm_median_based_preds = rbf_svm_median_based.predict(normalize_features(openml_test[ALL_FEATURES]))\n",
    "print(classification_report(openml_test['median_based_class'], test_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.26      1.00      0.41       130\n",
      "        loss       1.00      0.61      0.76       973\n",
      "\n",
      "    accuracy                           0.66      1103\n",
      "   macro avg       0.63      0.81      0.58      1103\n",
      "weighted avg       0.91      0.66      0.72      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      1.00      0.01         1\n",
      "        loss       1.00      0.74      0.85      1102\n",
      "\n",
      "    accuracy                           0.74      1103\n",
      "   macro avg       0.50      0.87      0.43      1103\n",
      "weighted avg       1.00      0.74      0.85      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.01      1.00      0.03         3\n",
      "        loss       1.00      0.80      0.89      1100\n",
      "\n",
      "    accuracy                           0.80      1103\n",
      "   macro avg       0.51      0.90      0.46      1103\n",
      "weighted avg       1.00      0.80      0.89      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.01      0.58      0.03        24\n",
      "        loss       0.90      0.08      0.15      1079\n",
      "\n",
      "    accuracy                           0.09      1103\n",
      "   macro avg       0.46      0.33      0.09      1103\n",
      "weighted avg       0.88      0.09      0.15      1103\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.00      0.00       130\n",
      "        loss       0.88      1.00      0.94       973\n",
      "\n",
      "    accuracy                           0.88      1103\n",
      "   macro avg       0.44      0.50      0.47      1103\n",
      "weighted avg       0.78      0.88      0.83      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_rbf_svm_pos_neg_preds = rbf_svm_pos_neg.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_rbf_svm_pos_neg_preds))\n",
    "\n",
    "college_debt_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print(classification_report(college_debt['harsh_grad_class'], college_debt_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "college_debt_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print(classification_report(college_debt['2th_grad_drop_class'], college_debt_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "college_debt_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print(classification_report(college_debt['order_of_mag_drop_class'], college_debt_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "college_debt_rbf_svm_median_based_preds = rbf_svm_median_based.predict(normalize_features(college_debt[ALL_FEATURES]))\n",
    "print(classification_report(college_debt['median_based_class'], college_debt_rbf_svm_median_based_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.68      0.81       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.68       447\n",
      "   macro avg       0.50      0.34      0.41       447\n",
      "weighted avg       1.00      0.68      0.81       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.02      0.67      0.04         3\n",
      "        loss       1.00      0.81      0.89       444\n",
      "\n",
      "    accuracy                           0.81       447\n",
      "   macro avg       0.51      0.74      0.47       447\n",
      "weighted avg       0.99      0.81      0.89       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.04      1.00      0.07         4\n",
      "        loss       1.00      0.77      0.87       443\n",
      "\n",
      "    accuracy                           0.77       447\n",
      "   macro avg       0.52      0.88      0.47       447\n",
      "weighted avg       0.99      0.77      0.86       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.93      0.96       444\n",
      "        loss       0.08      1.00      0.15         3\n",
      "\n",
      "    accuracy                           0.93       447\n",
      "   macro avg       0.54      0.96      0.56       447\n",
      "weighted avg       0.99      0.93      0.96       447\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.69      0.49      0.57       222\n",
      "        loss       0.61      0.78      0.68       225\n",
      "\n",
      "    accuracy                           0.64       447\n",
      "   macro avg       0.65      0.63      0.63       447\n",
      "weighted avg       0.65      0.64      0.63       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_rbf_svm_pos_neg_preds = rbf_svm_pos_neg.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_rbf_svm_pos_neg_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print(classification_report(taxi_collision['harsh_grad_class'], taxi_collision_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print(classification_report(taxi_collision['2th_grad_drop_class'], taxi_collision_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print(classification_report(taxi_collision['order_of_mag_drop_class'], taxi_collision_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_median_based_preds = rbf_svm_median_based.predict(normalize_features(taxi_collision[ALL_FEATURES]))\n",
    "print(classification_report(taxi_collision['median_based_class'], taxi_collision_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.11      0.32      0.16     11526\n",
      "        loss       0.92      0.74      0.82    119402\n",
      "\n",
      "    accuracy                           0.70    130928\n",
      "   macro avg       0.51      0.53      0.49    130928\n",
      "weighted avg       0.85      0.70      0.76    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      1.00      0.00         1\n",
      "        loss       1.00      0.80      0.89    130927\n",
      "\n",
      "    accuracy                           0.80    130928\n",
      "   macro avg       0.50      0.90      0.44    130928\n",
      "weighted avg       1.00      0.80      0.89    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.00      0.31      0.00        13\n",
      "        loss       1.00      0.64      0.78    130915\n",
      "\n",
      "    accuracy                           0.64    130928\n",
      "   macro avg       0.50      0.48      0.39    130928\n",
      "weighted avg       1.00      0.64      0.78    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.05      0.98      0.10      6390\n",
      "        loss       0.98      0.05      0.10    124538\n",
      "\n",
      "    accuracy                           0.10    130928\n",
      "   macro avg       0.52      0.52      0.10    130928\n",
      "weighted avg       0.94      0.10      0.10    130928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.06      0.02      0.03     10835\n",
      "        loss       0.92      0.96      0.94    120093\n",
      "\n",
      "    accuracy                           0.89    130928\n",
      "   macro avg       0.49      0.49      0.49    130928\n",
      "weighted avg       0.85      0.89      0.86    130928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_rbf_svm_pos_neg_preds = rbf_svm_pos_neg.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_rbf_svm_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_harsh_grad_preds = rbf_svm_harsh_grad.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print(classification_report(poverty_estimation['harsh_grad_class'], poverty_estimation_rbf_svm_harsh_grad_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_2nd_grad_drop_preds = rbf_svm_2nd_grad_drop.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print(classification_report(poverty_estimation['2th_grad_drop_class'], poverty_estimation_rbf_svm_2nd_grad_drop_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_order_of_mag_drop_preds = rbf_svm_order_of_mag_drop.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print(classification_report(poverty_estimation['order_of_mag_drop_class'], poverty_estimation_rbf_svm_order_of_mag_drop_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_median_based_preds = rbf_svm_median_based.predict(normalize_features(poverty_estimation[ALL_FEATURES]))\n",
    "print(classification_report(poverty_estimation['median_based_class'], poverty_estimation_rbf_svm_median_based_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, it looks like not even RBF is capable of working well when no restriction is made on $\\theta$..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focusing on SVM-RBF trained over instances with $\\theta = 1$ and tested over instances with $\\theta = 0.5$, what happens when we changed our training data to something that has only one candidate per query? \n",
    "\n",
    "### Naturally, in this case the only policy that makes sense is positive-negative, as there's only one candidate per query in the training data.\n",
    "\n",
    "### How does SVM-RBF behave in this case? And how does it compare with Random Forests in the same scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml_training_single = pd.read_csv('../classification/training-simplified-data-generation.csv')\n",
    "openml_training_single['class_pos_neg'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in openml_training_single.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7566, 36)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THETA = 1\n",
    "openml_training_single_high_containment = openml_training_single.loc[openml_training_single['containment_fraction'] >= THETA]\n",
    "openml_training_single_high_containment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rather small dataset... But let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svm_single_pos_neg_high_containment = train_rbf_svm(openml_training_single_high_containment[FEATURES], \n",
    "                                                        openml_training_single_high_containment['class_pos_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 0.5\n",
    "openml_test_high_containment = openml_test.loc[openml_test['containment_fraction'] >= THETA]\n",
    "college_debt_high_containment = college_debt.loc[college_debt['containment_fraction'] >= THETA]\n",
    "taxi_collision_high_containment = taxi_collision.loc[taxi_collision['containment_fraction'] >= THETA]\n",
    "poverty_estimation_high_containment = poverty_estimation.loc[poverty_estimation['containment_fraction'] >= THETA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.49      0.40      0.44     23212\n",
      "        loss       0.50      0.59      0.54     23169\n",
      "\n",
      "    accuracy                           0.49     46381\n",
      "   macro avg       0.49      0.49      0.49     46381\n",
      "weighted avg       0.49      0.49      0.49     46381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.79      1.00      0.88        92\n",
      "        loss       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.79       117\n",
      "   macro avg       0.39      0.50      0.44       117\n",
      "weighted avg       0.62      0.79      0.69       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.67      0.80        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.67        18\n",
      "   macro avg       0.50      0.33      0.40        18\n",
      "weighted avg       1.00      0.67      0.80        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.73      0.84        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.73        11\n",
      "   macro avg       0.50      0.36      0.42        11\n",
      "weighted avg       1.00      0.73      0.84        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's see how random forest trained over the same dataset works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_single_pos_neg_high_containment = train_model(openml_training_single_high_containment[FEATURES], \n",
    "                                                    openml_training_single_high_containment['class_pos_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.51      0.89      0.65     23212\n",
      "        loss       0.58      0.15      0.24     23169\n",
      "\n",
      "    accuracy                           0.52     46381\n",
      "   macro avg       0.55      0.52      0.44     46381\n",
      "weighted avg       0.55      0.52      0.44     46381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_high_containment_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(openml_test_high_containment[FEATURES]))\n",
    "print(classification_report(openml_test_high_containment['class_pos_neg'], test_high_containment_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.84      0.98      0.90        92\n",
      "        loss       0.80      0.32      0.46        25\n",
      "\n",
      "    accuracy                           0.84       117\n",
      "   macro avg       0.82      0.65      0.68       117\n",
      "weighted avg       0.83      0.84      0.81       117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_high_containment_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(college_debt_high_containment[FEATURES]))\n",
    "print(classification_report(college_debt_high_containment['class_pos_neg'], college_debt_high_containment_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.89      0.94        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89        18\n",
      "   macro avg       0.50      0.44      0.47        18\n",
      "weighted avg       1.00      0.89      0.94        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_high_containment_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(taxi_collision_high_containment[FEATURES]))\n",
    "print(classification_report(taxi_collision_high_containment['class_pos_neg'], taxi_collision_high_containment_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.82      0.90        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_high_containment_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(poverty_estimation_high_containment[FEATURES]))\n",
    "print(classification_report(poverty_estimation_high_containment['class_pos_neg'], poverty_estimation_high_containment_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, it looks like we get our best results when we train over this \"simpler\" dataset! And in this case, random forests behave best again... \n",
    "\n",
    "### What if we stick to random forests and this dataset, train with $\\theta = 1$ and test over the entire data (i.e., $\\theta = 0$)? How does it behave and how does it compare against an SVM-RBF trained over this simpler dataset with the same configuration of $\\theta$ values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.51      0.71      0.60     37058\n",
      "        loss       0.56      0.36      0.44     38680\n",
      "\n",
      "    accuracy                           0.53     75738\n",
      "   macro avg       0.54      0.53      0.52     75738\n",
      "weighted avg       0.54      0.53      0.52     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print(classification_report(openml_test['class_pos_neg'], test_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.12      1.00      0.21       130\n",
      "        loss       1.00      0.01      0.03       973\n",
      "\n",
      "    accuracy                           0.13      1103\n",
      "   macro avg       0.56      0.51      0.12      1103\n",
      "weighted avg       0.90      0.13      0.05      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.85      0.92       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.85       447\n",
      "   macro avg       0.50      0.42      0.46       447\n",
      "weighted avg       1.00      0.85      0.92       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.09      1.00      0.17     11526\n",
      "        loss       1.00      0.05      0.10    119402\n",
      "\n",
      "    accuracy                           0.13    130928\n",
      "   macro avg       0.55      0.53      0.13    130928\n",
      "weighted avg       0.92      0.13      0.10    130928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's see how the SVM-RBF behaves..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.46      0.38      0.42     37058\n",
      "        loss       0.49      0.57      0.52     38680\n",
      "\n",
      "    accuracy                           0.48     75738\n",
      "   macro avg       0.47      0.47      0.47     75738\n",
      "weighted avg       0.47      0.48      0.47     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print(classification_report(openml_test['class_pos_neg'], test_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.37      0.89      0.52       130\n",
      "        loss       0.98      0.79      0.88       973\n",
      "\n",
      "    accuracy                           0.81      1103\n",
      "   macro avg       0.67      0.84      0.70      1103\n",
      "weighted avg       0.91      0.81      0.84      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.44      0.61       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.44       447\n",
      "   macro avg       0.50      0.22      0.30       447\n",
      "weighted avg       1.00      0.44      0.61       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.11      0.36      0.17     11526\n",
      "        loss       0.92      0.72      0.81    119402\n",
      "\n",
      "    accuracy                           0.69    130928\n",
      "   macro avg       0.52      0.54      0.49    130928\n",
      "weighted avg       0.85      0.69      0.76    130928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, so it looks like training over this simpler dataset is the way to go. How about the main decision between whether to use SVM-RBF or Random Forest? It looks like the former behaves consistently better over case studies, but the latter performs better for openml_test. \n",
    "\n",
    "### Let me try comparing both models over a different instance of openml_test (openml_test_single)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "openml_test_single = pd.read_csv('../classification/test-simplified-data-generation.csv')\n",
    "openml_test_single['class_pos_neg'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in openml_test_single.iterrows()]\n",
    "\n",
    "THETA = 0.5\n",
    "openml_test_single_high_containment = openml_test_single.loc[openml_test_single['containment_fraction'] >= THETA]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.62      0.74      0.67      2496\n",
      "        loss       0.50      0.36      0.42      1780\n",
      "\n",
      "    accuracy                           0.58      4276\n",
      "   macro avg       0.56      0.55      0.55      4276\n",
      "weighted avg       0.57      0.58      0.57      4276\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.62      0.50      0.56      2496\n",
      "        loss       0.45      0.57      0.50      1780\n",
      "\n",
      "    accuracy                           0.53      4276\n",
      "   macro avg       0.54      0.54      0.53      4276\n",
      "weighted avg       0.55      0.53      0.53      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first, random forest.\n",
    "\n",
    "single_test_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(openml_test_single[FEATURES]))\n",
    "print(classification_report(openml_test_single['class_pos_neg'], single_test_model_single_pos_neg_preds))\n",
    "\n",
    "# then, svm-rbf.\n",
    "single_test_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(openml_test_single[FEATURES]))\n",
    "print(classification_report(openml_test_single['class_pos_neg'], single_test_rbf_svm_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yea... Well, it seems like Random Forest overfits more than SVM-RBF, but both are somewhat comparable. What if we used an ensemble and got the prediction as the \"maximum\"?\n",
    "\n",
    "### To this end, let's check how xgboost behaves first. We'll start training a positive/negative xgboost model setting $\\theta = 1$ for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(features, classes):\n",
    "    '''\n",
    "    Builds a xgboost classifier using features to predict associated classes\n",
    "    '''\n",
    "\n",
    "    feature_scaler = StandardScaler()\n",
    "    features_train = feature_scaler.fit_transform(features)\n",
    "    \n",
    "    # using the standard xgbc for now\n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(features_train, classes)\n",
    "\n",
    "    return xgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pos_neg_high_containment = train_xgboost(openml_training_high_containment[FEATURES],\n",
    "                                                 openml_training_high_containment['class_pos_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* XGBOOST --- OPENML_TRAINING_SINLE --- OPENML_TEST --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.55      0.13      0.22     37058\n",
      "        loss       0.52      0.89      0.66     38680\n",
      "\n",
      "    accuracy                           0.52     75738\n",
      "   macro avg       0.53      0.51      0.44     75738\n",
      "weighted avg       0.53      0.52      0.44     75738\n",
      "\n",
      "******* SVM-RBF --- OPENML_TRAINING_SINLE --- OPENML_TEST --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.46      0.38      0.42     37058\n",
      "        loss       0.49      0.57      0.52     38680\n",
      "\n",
      "    accuracy                           0.48     75738\n",
      "   macro avg       0.47      0.47      0.47     75738\n",
      "weighted avg       0.47      0.48      0.47     75738\n",
      "\n",
      "******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- OPENML_TEST --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.51      0.71      0.60     37058\n",
      "        loss       0.56      0.36      0.44     38680\n",
      "\n",
      "    accuracy                           0.53     75738\n",
      "   macro avg       0.54      0.53      0.52     75738\n",
      "weighted avg       0.54      0.53      0.52     75738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_xgboost_training_single_pos_neg_preds = xgboost_pos_neg_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print('******* XGBOOST --- OPENML_TRAINING_SINLE --- OPENML_TEST --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(openml_test['class_pos_neg'], test_xgboost_training_single_pos_neg_preds))\n",
    "\n",
    "test_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print('******* SVM-RBF --- OPENML_TRAINING_SINLE --- OPENML_TEST --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(openml_test['class_pos_neg'], test_rbf_svm_single_pos_neg_preds))\n",
    "\n",
    "test_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(openml_test[FEATURES]))\n",
    "print('******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- OPENML_TEST --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(openml_test['class_pos_neg'], test_model_single_pos_neg_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoah, xgboost is *very* bad over openml_test. Let's see how it compares with the other classifiers over the case studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* XGBOOST --- OPENML_TRAINING_SINLE --- COLLEGE_DEBT --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.18      1.00      0.30       130\n",
      "        loss       1.00      0.39      0.56       973\n",
      "\n",
      "    accuracy                           0.46      1103\n",
      "   macro avg       0.59      0.69      0.43      1103\n",
      "weighted avg       0.90      0.46      0.53      1103\n",
      "\n",
      "******* SVM-RBF --- OPENML_TRAINING_SINLE --- COLLEGE_DEBT --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.37      0.89      0.52       130\n",
      "        loss       0.98      0.79      0.88       973\n",
      "\n",
      "    accuracy                           0.81      1103\n",
      "   macro avg       0.67      0.84      0.70      1103\n",
      "weighted avg       0.91      0.81      0.84      1103\n",
      "\n",
      "******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- COLLEGE_DEBT --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.12      1.00      0.21       130\n",
      "        loss       1.00      0.01      0.03       973\n",
      "\n",
      "    accuracy                           0.13      1103\n",
      "   macro avg       0.56      0.51      0.12      1103\n",
      "weighted avg       0.90      0.13      0.05      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "college_debt_xgboost_training_single_pos_neg_preds = xgboost_pos_neg_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print('******* XGBOOST --- OPENML_TRAINING_SINLE --- COLLEGE_DEBT --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_xgboost_training_single_pos_neg_preds))\n",
    "\n",
    "college_debt_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print('******* SVM-RBF --- OPENML_TRAINING_SINLE --- COLLEGE_DEBT --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_rbf_svm_single_pos_neg_preds))\n",
    "\n",
    "college_debt_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(college_debt[FEATURES]))\n",
    "print('******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- COLLEGE_DEBT --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(college_debt['class_pos_neg'], college_debt_model_single_pos_neg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* XGBOOST --- OPENML_TRAINING_SINLE --- TAXI_COLLISION --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.22      0.37       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.22       447\n",
      "   macro avg       0.50      0.11      0.18       447\n",
      "weighted avg       1.00      0.22      0.37       447\n",
      "\n",
      "******* SVM-RBF --- OPENML_TRAINING_SINLE --- TAXI_COLLISION --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.44      0.61       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.44       447\n",
      "   macro avg       0.50      0.22      0.30       447\n",
      "weighted avg       1.00      0.44      0.61       447\n",
      "\n",
      "******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- TAXI_COLLISION --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.85      0.92       447\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.85       447\n",
      "   macro avg       0.50      0.42      0.46       447\n",
      "weighted avg       1.00      0.85      0.92       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_collision_xgboost_training_single_pos_neg_preds = xgboost_pos_neg_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print('******* XGBOOST --- OPENML_TRAINING_SINLE --- TAXI_COLLISION --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_xgboost_training_single_pos_neg_preds))\n",
    "\n",
    "taxi_collision_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print('******* SVM-RBF --- OPENML_TRAINING_SINLE --- TAXI_COLLISION --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_rbf_svm_single_pos_neg_preds))\n",
    "\n",
    "taxi_collision_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(taxi_collision[FEATURES]))\n",
    "print('******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- TAXI_COLLISION --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(taxi_collision['class_pos_neg'], taxi_collision_model_single_pos_neg_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* XGBOOST --- OPENML_TRAINING_SINLE --- POVERTY_ESTIMATION --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.13      0.24      0.17     11526\n",
      "        loss       0.92      0.85      0.88    119402\n",
      "\n",
      "    accuracy                           0.80    130928\n",
      "   macro avg       0.53      0.54      0.53    130928\n",
      "weighted avg       0.85      0.80      0.82    130928\n",
      "\n",
      "******* SVM-RBF --- OPENML_TRAINING_SINLE --- POVERTY_ESTIMATION --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.11      0.36      0.17     11526\n",
      "        loss       0.92      0.72      0.81    119402\n",
      "\n",
      "    accuracy                           0.69    130928\n",
      "   macro avg       0.52      0.54      0.49    130928\n",
      "weighted avg       0.85      0.69      0.76    130928\n",
      "\n",
      "******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- POVERTY_ESTIMATION --- POSITIVE/NEGATIVE CLASSES ********\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.09      1.00      0.17     11526\n",
      "        loss       1.00      0.05      0.10    119402\n",
      "\n",
      "    accuracy                           0.13    130928\n",
      "   macro avg       0.55      0.53      0.13    130928\n",
      "weighted avg       0.92      0.13      0.10    130928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poverty_estimation_xgboost_training_single_pos_neg_preds = xgboost_pos_neg_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print('******* XGBOOST --- OPENML_TRAINING_SINLE --- POVERTY_ESTIMATION --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_xgboost_training_single_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_rbf_svm_single_pos_neg_preds = rbf_svm_single_pos_neg_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print('******* SVM-RBF --- OPENML_TRAINING_SINLE --- POVERTY_ESTIMATION --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_rbf_svm_single_pos_neg_preds))\n",
    "\n",
    "poverty_estimation_model_single_pos_neg_preds = model_single_pos_neg_high_containment.predict(normalize_features(poverty_estimation[FEATURES]))\n",
    "print('******* RANDOM FOREST --- OPENML_TRAINING_SINLE --- POVERTY_ESTIMATION --- POSITIVE/NEGATIVE CLASSES ********')\n",
    "print(classification_report(poverty_estimation['class_pos_neg'], poverty_estimation_model_single_pos_neg_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
