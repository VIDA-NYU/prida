{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we generate results for multiple thresholds on containment fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training-simplified-data-generation.csv')\n",
    "test = pd.read_csv('test-simplified-data-generation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's (sanity-)check how many candidates per query there are in these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_queries = set(training['query'])\n",
    "test_queries = set(test['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_queries) == training.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_queries) == test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok. So there's no overlap in query features in both the training and the test set, which is good for our current analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_queries & test_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alright. So if there's no overlap, we can generate different versions of these datasets based on distinct containment ratio thresholds $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLDS = [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.5,\n",
    "              0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.0]\n",
    "def generate_different_dataset_versions(dataset):\n",
    "    pruned_datasets = []\n",
    "    for thresh in THRESHOLDS:\n",
    "        pruned_datasets.append(dataset.loc[dataset['containment_fraction'] >= thresh])\n",
    "    return pruned_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_datasets_different_theta = generate_different_dataset_versions(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datasets_different_theta = generate_different_dataset_versions(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's train and test taking the thresholds into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['query_num_of_columns', 'query_num_of_rows', 'query_row_column_ratio',\n",
    "                'query_max_skewness', 'query_max_kurtosis', 'query_max_unique', \n",
    "                'candidate_num_rows', 'candidate_max_skewness', 'candidate_max_kurtosis',\n",
    "                'candidate_max_unique', 'query_target_max_pearson', \n",
    "                'query_target_max_spearman', 'query_target_max_covariance', \n",
    "                'query_target_max_mutual_info', 'candidate_target_max_pearson', \n",
    "                'candidate_target_max_spearman', 'candidate_target_max_covariance', \n",
    "                'candidate_target_max_mutual_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "NORMALIZABLE_FEATURES = ['query_num_of_columns', 'query_num_of_rows', 'query_row_column_ratio',\n",
    "                'query_max_skewness', 'query_max_kurtosis', 'query_max_unique', \n",
    "                'candidate_num_rows', 'candidate_max_skewness', 'candidate_max_kurtosis',\n",
    "                'candidate_max_unique', 'query_target_max_covariance', \n",
    "                'query_target_max_mutual_info', 'candidate_target_max_covariance', \n",
    "                'candidate_target_max_mutual_info']\n",
    "\n",
    "def normalize_dataset(dataset):\n",
    "    standard_scaler = StandardScaler()\n",
    "    for feature in NORMALIZABLE_FEATURES:\n",
    "        dataset[feature] = standard_scaler.fit_transform(np.array(dataset[feature]).reshape(-1, 1))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm adding a simple normalization method here but I'm not sure about how we should use it to normalize test data. Should we normalize candidate features considering only candidates for a same query? And how should we normalize the query features (I know there's only one candidate per query here, but there are cases where there are many)? In a practical scenario, we only get one query at a time, so we won't have much of a \"reference\" against which we can normalize query features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_for_different_training_and_test_pairs(training_datasets, test_datasets):\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    for training, test in zip(training_datasets, test_datasets):\n",
    "        normed_training = normalize_dataset(training)\n",
    "        normed_training['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in normed_training.iterrows()]\n",
    "        normed_test = normalize_dataset(test)\n",
    "        normed_test['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in normed_test.iterrows()]\n",
    "        rf.fit(normed_training[FEATURES], normed_training['class'])\n",
    "        preds = rf.predict(normed_test[FEATURES])\n",
    "        print(classification_report(normed_test['class'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.78      0.71      1960\n",
      "        loss       0.52      0.37      0.43      1305\n",
      "\n",
      "    accuracy                           0.61      3265\n",
      "   macro avg       0.59      0.57      0.57      3265\n",
      "weighted avg       0.60      0.61      0.60      3265\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.78      0.71      1962\n",
      "        loss       0.52      0.35      0.42      1310\n",
      "\n",
      "    accuracy                           0.61      3272\n",
      "   macro avg       0.58      0.57      0.56      3272\n",
      "weighted avg       0.60      0.61      0.59      3272\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.78      0.71      1967\n",
      "        loss       0.53      0.37      0.44      1314\n",
      "\n",
      "    accuracy                           0.62      3281\n",
      "   macro avg       0.59      0.58      0.57      3281\n",
      "weighted avg       0.60      0.62      0.60      3281\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.63      0.81      0.71      1972\n",
      "        loss       0.50      0.29      0.37      1315\n",
      "\n",
      "    accuracy                           0.60      3287\n",
      "   macro avg       0.56      0.55      0.54      3287\n",
      "weighted avg       0.58      0.60      0.57      3287\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.71      0.68      1977\n",
      "        loss       0.50      0.44      0.47      1323\n",
      "\n",
      "    accuracy                           0.60      3300\n",
      "   macro avg       0.58      0.57      0.58      3300\n",
      "weighted avg       0.59      0.60      0.60      3300\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.63      0.77      0.69      1983\n",
      "        loss       0.49      0.33      0.40      1331\n",
      "\n",
      "    accuracy                           0.59      3314\n",
      "   macro avg       0.56      0.55      0.54      3314\n",
      "weighted avg       0.57      0.59      0.57      3314\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.66      0.66      0.66      1991\n",
      "        loss       0.49      0.48      0.49      1333\n",
      "\n",
      "    accuracy                           0.59      3324\n",
      "   macro avg       0.57      0.57      0.57      3324\n",
      "weighted avg       0.59      0.59      0.59      3324\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.69      0.67      2007\n",
      "        loss       0.49      0.44      0.47      1342\n",
      "\n",
      "    accuracy                           0.59      3349\n",
      "   macro avg       0.57      0.57      0.57      3349\n",
      "weighted avg       0.59      0.59      0.59      3349\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.77      0.71      2026\n",
      "        loss       0.53      0.39      0.45      1350\n",
      "\n",
      "    accuracy                           0.62      3376\n",
      "   macro avg       0.59      0.58      0.58      3376\n",
      "weighted avg       0.60      0.62      0.60      3376\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.63      0.75      0.69      2030\n",
      "        loss       0.48      0.35      0.41      1357\n",
      "\n",
      "    accuracy                           0.59      3387\n",
      "   macro avg       0.56      0.55      0.55      3387\n",
      "weighted avg       0.57      0.59      0.58      3387\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.67      0.62      0.64      2050\n",
      "        loss       0.49      0.54      0.51      1371\n",
      "\n",
      "    accuracy                           0.59      3421\n",
      "   macro avg       0.58      0.58      0.58      3421\n",
      "weighted avg       0.60      0.59      0.59      3421\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.66      0.70      0.68      2072\n",
      "        loss       0.50      0.45      0.48      1386\n",
      "\n",
      "    accuracy                           0.60      3458\n",
      "   macro avg       0.58      0.57      0.58      3458\n",
      "weighted avg       0.59      0.60      0.60      3458\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.64      0.70      0.67      2082\n",
      "        loss       0.48      0.41      0.45      1395\n",
      "\n",
      "    accuracy                           0.59      3477\n",
      "   macro avg       0.56      0.56      0.56      3477\n",
      "weighted avg       0.58      0.59      0.58      3477\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.67      0.60      0.63      2101\n",
      "        loss       0.48      0.56      0.52      1410\n",
      "\n",
      "    accuracy                           0.58      3511\n",
      "   macro avg       0.57      0.58      0.57      3511\n",
      "weighted avg       0.59      0.58      0.58      3511\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.70      0.54      0.61      2126\n",
      "        loss       0.49      0.65      0.56      1432\n",
      "\n",
      "    accuracy                           0.58      3558\n",
      "   macro avg       0.59      0.59      0.58      3558\n",
      "weighted avg       0.61      0.58      0.59      3558\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.66      0.63      0.64      2145\n",
      "        loss       0.49      0.52      0.50      1456\n",
      "\n",
      "    accuracy                           0.59      3601\n",
      "   macro avg       0.57      0.57      0.57      3601\n",
      "weighted avg       0.59      0.59      0.59      3601\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.67      0.56      0.61      2161\n",
      "        loss       0.49      0.60      0.54      1483\n",
      "\n",
      "    accuracy                           0.58      3644\n",
      "   macro avg       0.58      0.58      0.57      3644\n",
      "weighted avg       0.60      0.58      0.58      3644\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.66      0.62      0.64      2197\n",
      "        loss       0.49      0.54      0.51      1502\n",
      "\n",
      "    accuracy                           0.59      3699\n",
      "   macro avg       0.58      0.58      0.58      3699\n",
      "weighted avg       0.59      0.59      0.59      3699\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.68      0.55      0.61      2227\n",
      "        loss       0.49      0.63      0.55      1527\n",
      "\n",
      "    accuracy                           0.58      3754\n",
      "   macro avg       0.58      0.59      0.58      3754\n",
      "weighted avg       0.60      0.58      0.58      3754\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.68      0.51      0.58      2267\n",
      "        loss       0.48      0.65      0.55      1579\n",
      "\n",
      "    accuracy                           0.57      3846\n",
      "   macro avg       0.58      0.58      0.57      3846\n",
      "weighted avg       0.60      0.57      0.57      3846\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.58      0.61      2496\n",
      "        loss       0.49      0.57      0.53      1780\n",
      "\n",
      "    accuracy                           0.57      4276\n",
      "   macro avg       0.57      0.57      0.57      4276\n",
      "weighted avg       0.59      0.57      0.58      4276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_performance_for_different_training_and_test_pairs(training_datasets_different_theta, test_datasets_different_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fmeasures_and_supports(fmeasures, supports, title):\n",
    "  fig, ax1 = plt.subplots()\n",
    "  color = '#1d3557'\n",
    "  ax1.set_xlabel(r'Threshold $\\theta$')\n",
    "  ax1.xaxis.label.set_size(16)\n",
    "  #ax1.set_xlim(xmin=0.248,xmax=0.652)\n",
    "  #extraticks = [0.25, 0.35, 0.45, 0.55, 0.65]\n",
    "  #ax1.set_xticks(extraticks) #list(ax1.get_xticks()) +\n",
    "  ax1.set_ylabel(r'Support', color=color) # ($\\ln$)\n",
    "  ax1.yaxis.label.set_size(16)\n",
    "  ax1.plot(THRESHOLDS, supports, 'o--', dashes=(5,10), color=color, linewidth=3, label='support')\n",
    "  ax1.tick_params(axis='y', labelcolor=color, labelsize=12)\n",
    "  ax1.tick_params(axis='x',  labelsize=12)\n",
    "\n",
    "  ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "  #ax2.set_xlim(xmin=0.248,xmax=0.652)\n",
    "  ax2.xaxis.label.set_size(16)\n",
    "  #ax2.set_xticks(list(ax2.get_xticks()) + extraticks)\n",
    "  color = '#e63946'\n",
    "  ax2.set_ylabel(r'F-measure', color=color)  # we already handled the x-label with ax1\n",
    "  ax2.yaxis.label.set_size(16)\n",
    "  #ax2.set_ylim(ymin=0.475,ymax=0.585)\n",
    "  ax2.plot(THRESHOLDS, fmeasures, 'o-', color=color, linewidth=3, label='f-measure')\n",
    "  ax2.tick_params(axis='y', labelcolor=color, labelsize=12)\n",
    "  ax2.tick_params(axis='x',  labelsize=12)\n",
    "  plt.title(title)\n",
    "  fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "  plt.savefig('varying-containment.png', dpi=600)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the f-score increases as the containment ratio threshold increases as well... Let's plot support and f-measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fmeasures = [0.71, 0.71, 0.71, 0.71, 0.68, 0.69, 0.66, 0.67, 0.71, \n",
    "             0.69, 0.64, 0.68, 0.67, 0.63, 0.61, 0.64, 0.61, 0.64, 0.61, 0.58, 0.61]\n",
    "positive_supports = [1960, 1962, 1967, 1972, 1977, 1983, 1991, 2007, 2026, 2030, 2050, 2072, \n",
    "            2082, 2101, 2126, 2145, 2161, 2197, 2227, 2267, 2496]\n",
    "supports = [3265, 3272, 3281, 3287, 3300, 3314, 3324, 3349, 3376, 3387, 3421, 3458,\n",
    "            3477, 3511, 3558, 3601, 3644, 3699, 3754, 3846, 4276]\n",
    "plot_fmeasures_and_supports(fmeasures, supports, 'OpenML-Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that there is an ascending trend in the F-Measure, but it is hard to know where to \"cut\" here: 0.3? 0.4? 0.5? For now, we'll use $\\theta$ == 0.6 for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets \n",
    "\n",
    "pruned_training = training_datasets_different_theta[8]\n",
    "pruned_test = test_datasets_different_theta[8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7932, 36)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3376, 36)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4774, 36)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_training.loc[pruned_training['class'] == 'gain'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2026, 36)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_test.loc[pruned_test['class'] == 'gain'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare the results we obtained with $\\theta$ = 0.6 against other methodologies (one with added noise and one with many candidates per query, both also using threshold $\\theta$ = 0.6.\n",
    "\n",
    "#### It was taking too long to get results for the \"many-candidates\" methodology on this notebook, so I generated the results on ipython on my terminal and attached them below as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 0.6\n",
    "\n",
    "training_official = pruned_training\n",
    "\n",
    "training_noise = pd.read_csv('training-with-noise-data-generation.csv')\n",
    "training_noise = training_noise.loc[training_noise['containment_fraction'] >= THETA]\n",
    "training_noise = normalize_dataset(training_noise)\n",
    "training_noise['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in training_noise.iterrows()]\n",
    "\n",
    "test = pruned_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.77      0.71      2026\n",
      "        loss       0.53      0.39      0.45      1350\n",
      "\n",
      "    accuracy                           0.62      3376\n",
      "   macro avg       0.59      0.58      0.58      3376\n",
      "weighted avg       0.60      0.62      0.60      3376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_official = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_official.fit(training_official[FEATURES], training_official['class'])\n",
    "preds = rf_official.predict(test[FEATURES])\n",
    "print(classification_report(test['class'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.67      0.58      0.62      2026\n",
      "        loss       0.48      0.58      0.52      1350\n",
      "\n",
      "    accuracy                           0.58      3376\n",
      "   macro avg       0.58      0.58      0.57      3376\n",
      "weighted avg       0.59      0.58      0.58      3376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_noise = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_noise.fit(training_noise[FEATURES], training_noise['class'])\n",
    "preds = rf_noise.predict(test[FEATURES])\n",
    "print(classification_report(test['class'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for \"many candidates\" methodology:\n",
    "\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.69      0.59      0.63      2026\n",
    "        loss       0.49      0.60      0.54      1350\n",
    "\n",
    "    accuracy                           0.59      3376\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the percentage of successful and unsuccessful augmentations for all these different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_official -- number of rows 7932 positive augs 0.6018658598083712 negative augs 0.39813414019162885\n"
     ]
    }
   ],
   "source": [
    "print('training_official -- number of rows', training_official.shape[0], \n",
    "      'positive augs', float(training_official.loc[training_official['class'] == 'gain'].shape[0])/training_official.shape[0],\n",
    "      'negative augs', float(training_official.loc[training_official['class'] == 'loss'].shape[0])/training_official.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test -- number of rows 3376 positive augs 0.6001184834123223 negative augs 0.39988151658767773\n"
     ]
    }
   ],
   "source": [
    "print('test -- number of rows', test.shape[0], \n",
    "      'positive augs', float(test.loc[test['class'] == 'gain'].shape[0])/test.shape[0],\n",
    "      'negative augs', float(test.loc[test['class'] == 'loss'].shape[0])/test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_noise -- number of rows 5013 positive augs 0.5344105326152004 negative augs 0.4655894673847995\n"
     ]
    }
   ],
   "source": [
    "print('training_noise -- number of rows', training_noise.shape[0], \n",
    "      'positive augs', float(training_noise.loc[training_noise['class'] == 'gain'].shape[0])/training_noise.shape[0],\n",
    "      'negative augs', float(training_noise.loc[training_noise['class'] == 'loss'].shape[0])/training_noise.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the \"many candidates\" methodology, we have 1266624 rows, 48% positive and 52% negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see which features are most important for rf_official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('candidate_target_max_pearson', 0.09849076660016301), ('candidate_target_max_spearman', 0.0938912234672648), ('query_row_column_ratio', 0.08464838829542287), ('candidate_max_kurtosis', 0.07204317764663211), ('candidate_max_skewness', 0.07195784973431611), ('query_target_max_pearson', 0.0651465659091578), ('query_num_of_columns', 0.06386297563720769), ('query_target_max_spearman', 0.06381621444399013), ('query_max_kurtosis', 0.06212454990794925), ('query_max_skewness', 0.05720125836070155), ('candidate_target_max_mutual_info', 0.04862111068774083), ('candidate_max_unique', 0.042091229099697536), ('candidate_num_rows', 0.03757524954044709), ('query_target_max_mutual_info', 0.036941819371807606), ('query_max_unique', 0.03689081270259695), ('query_num_of_rows', 0.024573660137982397), ('query_target_max_covariance', 0.021799436516301448), ('candidate_target_max_covariance', 0.018323711940620838)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted([(i, j) for i, j in zip(FEATURES, rf_official.feature_importances_)],\n",
    "            key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare rf_official with a few baselines now. Let's start with a hierarchical one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.65      0.47      0.54      2026\n",
      "        loss       0.44      0.62      0.51      1350\n",
      "\n",
      "    accuracy                           0.53      3376\n",
      "   macro avg       0.54      0.54      0.53      3376\n",
      "weighted avg       0.56      0.53      0.53      3376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATASET_QUERY_FEATURES = ['query_target_max_pearson', \n",
    "                'query_target_max_spearman', 'query_target_max_covariance', \n",
    "                'query_target_max_mutual_info', 'candidate_target_max_pearson', \n",
    "                'candidate_target_max_spearman', 'candidate_target_max_covariance', \n",
    "                'candidate_target_max_mutual_info']\n",
    "\n",
    "DATASET_FEATURES = ['query_num_of_columns', 'query_num_of_rows', 'query_row_column_ratio',\n",
    "                'query_max_skewness', 'query_max_kurtosis', 'query_max_unique', \n",
    "                'candidate_num_rows', 'candidate_max_skewness', 'candidate_max_kurtosis',\n",
    "                'candidate_max_unique']\n",
    "\n",
    "\n",
    "rf_dataset_query_features = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_dataset_query_features.fit(training_official[DATASET_QUERY_FEATURES], training_official['class'])\n",
    "preds_dataset_query_features = rf_dataset_query_features.predict(test[DATASET_QUERY_FEATURES])\n",
    "\n",
    "rf_dataset_features = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_dataset_features.fit(training_official[DATASET_FEATURES], training_official['class'])\n",
    "preds_dataset_features = rf_dataset_features.predict(test[DATASET_FEATURES])\n",
    "\n",
    "preds = ['gain' if i == 'gain' and j == 'gain' else 'loss' for i, j in zip(preds_dataset_query_features, preds_dataset_features)]\n",
    "print(classification_report(test['class'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.66      0.63      0.65      2026\n",
      "        loss       0.48      0.52      0.50      1350\n",
      "\n",
      "    accuracy                           0.59      3376\n",
      "   macro avg       0.57      0.58      0.57      3376\n",
      "weighted avg       0.59      0.59      0.59      3376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "import random\n",
    "\n",
    "positive_centroid = training_official.loc[training_official['class'] == 'gain'][FEATURES].mean()\n",
    "negative_centroid = training_official.loc[training_official['class'] == 'loss'][FEATURES].mean()\n",
    "\n",
    "preds = []\n",
    "for index, row in test.iterrows():\n",
    "    dist_pos = euclidean(positive_centroid, row[FEATURES])\n",
    "    dist_neg = euclidean(negative_centroid, row[FEATURES])\n",
    "    if dist_pos < dist_neg:\n",
    "        preds.append('gain')\n",
    "    else: \n",
    "        preds.append('loss')\n",
    "print(classification_report(test['class'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's check the probability distribution of predictions for test with rf_official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54, 0.53, 0.54, 0.57, 0.49, 0.56, 0.52, 0.57, 0.7, 0.51, 0.44, 0.61, 0.66, 0.41, 0.53, 0.695, 0.49, 0.5916666666666667, 0.84, 0.77, 0.53, 0.63, 0.58, 0.44, 0.43, 0.46, 0.47, 0.57, 0.49333333333333335, 0.5533333333333332, 0.54, 0.45, 0.79, 0.46, 0.59, 0.69, 0.445, 0.49, 0.42, 0.68, 0.48, 0.5533333333333332, 0.58, 0.49, 0.47, 0.48, 0.78, 0.48, 0.53, 0.7125, 0.63, 0.44, 0.49, 0.81, 0.48, 0.51, 0.44, 0.44, 0.47, 0.42, 0.47, 0.55, 0.55, 0.47, 0.44, 0.43, 0.39, 0.56, 0.59, 0.43, 0.46, 0.4666666666666666, 0.55, 0.43, 0.51, 0.52, 0.59, 0.5, 0.5, 0.48, 0.6725, 0.42, 0.69, 0.62, 0.595, 0.41, 0.68, 0.54, 0.56, 0.62, 0.6, 0.53, 0.53, 0.5, 0.6, 0.59, 0.59, 0.48, 0.685, 0.82, 0.5366666666666667, 0.54, 0.45, 0.54, 0.9, 0.6, 0.53, 0.475, 0.5, 0.51, 0.5, 0.71, 0.4, 0.52, 0.58, 0.58, 0.52, 0.67, 0.53, 0.53, 0.415, 0.51, 0.77, 0.5, 0.86, 0.53, 0.63, 0.62, 0.72, 0.57, 0.7, 0.44, 0.48, 0.58, 0.47, 0.72, 0.71, 0.77, 0.58, 0.38, 0.52, 0.32, 0.49, 0.4, 0.65, 0.61, 0.57, 0.49, 0.49, 0.6633333333333334, 0.5, 0.63, 0.39, 0.53, 0.5, 0.49, 0.39, 0.61, 0.6, 0.57, 0.72, 0.62, 0.74, 0.51, 0.43833333333333335, 0.4633333333333334, 0.51, 0.7, 0.54, 0.59, 0.41, 0.59, 0.5, 0.41, 0.54, 0.5133333333333333, 0.88, 0.73, 0.48, 0.45, 0.5133333333333333, 0.56, 0.6, 0.67, 0.53, 0.39, 0.42, 0.58, 0.3625, 0.49, 0.92, 0.44, 0.47, 0.64, 0.62, 0.44, 0.58, 0.7, 0.75, 0.45, 0.45, 0.44, 0.46, 0.5033333333333333, 0.48, 0.73, 0.56, 0.4133333333333333, 0.65, 0.4733333333333334, 0.48, 0.5933333333333334, 0.47, 0.52, 0.62, 0.52, 0.49, 0.44, 0.48, 0.53, 0.57, 0.4933333333333333, 0.76, 0.59, 0.57, 0.5, 0.52, 0.43, 0.7, 0.53, 0.44, 0.44, 0.69, 0.46, 0.65, 0.41, 0.36, 0.6, 0.49, 0.445, 0.6, 0.59, 0.54, 0.51, 0.58, 0.45, 0.46, 0.57, 0.43, 0.49, 0.415, 0.46, 0.45, 0.6, 0.48, 0.6, 0.57, 0.46, 0.42, 0.6166666666666667, 0.5, 0.57, 0.5, 0.52, 0.45, 0.72, 0.74, 0.7, 0.78, 0.726, 0.67, 0.5366666666666666, 0.72, 0.53, 0.57, 0.42, 0.54, 0.57, 0.69, 0.43, 0.44, 0.52, 0.44, 0.7, 0.59, 0.53, 0.54, 0.47, 0.77, 0.54, 0.75, 0.57, 0.58, 0.45, 0.6725, 0.49, 0.52, 0.54, 0.46, 0.5333333333333333, 0.48, 0.46, 0.48, 0.665, 0.6, 0.6, 0.49, 0.535, 0.54, 0.51, 0.4433333333333333, 0.64, 0.5133333333333333, 0.73, 0.58, 0.47, 0.55, 0.55, 0.45, 0.51, 0.82, 0.64, 0.6033333333333333, 0.49, 0.5333333333333333, 0.53, 0.57, 0.45, 0.66, 0.58, 0.55, 0.5, 0.48, 0.5466666666666667, 0.51, 0.35, 0.79, 0.49, 0.44, 0.4, 0.6966666666666665, 0.62, 0.545, 0.5, 0.56, 0.6, 0.49, 0.74, 0.42, 0.52, 0.45, 0.5, 0.41, 0.47, 0.4, 0.52, 0.48, 0.77, 0.56, 0.41, 0.54, 0.5266666666666666, 0.44, 0.62, 0.51, 0.61, 0.57, 0.5033333333333334, 0.66, 0.77, 0.61, 0.51, 0.63, 0.48, 0.52, 0.59, 0.61, 0.57, 0.55, 0.66, 0.86, 0.48, 0.6, 0.47, 0.49, 0.5825, 0.54, 0.65, 0.55, 0.44, 0.63, 0.57, 0.48, 0.61, 0.53, 0.65, 0.58, 0.425, 0.46, 0.73, 0.78, 0.5, 0.49, 0.5, 0.5625, 0.59, 0.68, 0.56, 0.56, 0.46, 0.67, 0.44, 0.58, 0.5, 0.52, 0.37, 0.46, 0.69, 0.72, 0.58, 0.48, 0.44, 0.41, 0.56, 0.545, 0.5, 0.56, 0.68, 0.52, 0.5466666666666667, 0.5533333333333333, 0.49, 0.73, 0.45, 0.5, 0.3775, 0.48, 0.8, 0.44, 0.54, 0.5, 0.45, 0.54, 0.62, 0.68, 0.59, 0.62, 0.74, 0.72, 0.55, 0.51, 0.62, 0.5, 0.5333333333333333, 0.53, 0.44, 0.57, 0.58, 0.57, 0.6, 0.6, 0.61, 0.73, 0.57, 0.47, 0.61, 0.77, 0.435, 0.49, 0.8, 0.62, 0.56, 0.5533333333333333, 0.48, 0.52, 0.63, 0.5, 0.56, 0.45, 0.51, 0.51, 0.64, 0.57, 0.52, 0.47, 0.6725, 0.76, 0.73, 0.5, 0.53, 0.92, 0.47, 0.78, 0.62, 0.4, 0.64, 0.58, 0.46, 0.45, 0.75, 0.39, 0.5, 0.66, 0.5, 0.85, 0.6, 0.55, 0.47, 0.47, 0.6, 0.46, 0.67, 0.65, 0.62, 0.38, 0.55, 0.79, 0.85, 0.52, 0.55, 0.9, 0.63, 0.51, 0.41, 0.51, 0.46, 0.43, 0.56, 0.47, 0.5566666666666666, 0.5, 0.51, 0.47, 0.5, 0.5, 0.51, 0.63, 0.52, 0.49, 0.56, 0.66, 0.64, 0.7433333333333334, 0.5358333333333334, 0.6, 0.5666666666666667, 0.83, 0.51, 0.43, 0.53, 0.46, 0.71, 0.53, 0.77, 0.68, 0.62, 0.57, 0.52, 0.5, 0.65, 0.49, 0.44, 0.55, 0.6116666666666667, 0.49, 0.55, 0.53, 0.59, 0.68, 0.86, 0.62, 0.55, 0.49, 0.52, 0.55, 0.66, 0.41, 0.61, 0.57, 0.47, 0.6825, 0.58, 0.51, 0.55, 0.55, 0.42, 0.5, 0.57, 0.49, 0.485, 0.4733333333333333, 0.82, 0.45, 0.59, 0.32, 0.48, 0.55, 0.6, 0.57, 0.6466666666666666, 0.6, 0.76, 0.58, 0.53, 0.55, 0.53, 0.56, 0.5366666666666667, 0.53, 0.57, 0.57, 0.93, 0.64, 0.52, 0.59, 0.63, 0.58, 0.43, 0.78, 0.5, 0.5266666666666667, 0.58, 0.54, 0.51, 0.48, 0.53, 0.61, 0.49, 0.82, 0.67, 0.75, 0.5, 0.5, 0.48, 0.54, 0.61, 0.43666666666666665, 0.6, 0.46, 0.79, 0.53, 0.5, 0.6383333333333333, 0.51, 0.5, 0.67, 0.67, 0.67, 0.405, 0.545, 0.52, 0.39, 0.5366666666666667, 0.4775, 0.66, 0.43, 0.83, 0.66, 0.48, 0.57, 0.63, 0.7666666666666666, 0.48, 0.56, 0.48, 0.63, 0.61, 0.74, 0.58, 0.45, 0.6, 0.46, 0.59, 0.52, 0.44, 0.41, 0.49, 0.45, 0.47, 0.5, 0.44, 0.48, 0.64, 0.61, 0.71, 0.48, 0.56, 0.43, 0.5233333333333333, 0.53, 0.66, 0.6, 0.66, 0.44, 0.6825, 0.42, 0.5, 0.5, 0.51, 0.48, 0.82, 0.7, 0.6225, 0.49, 0.72, 0.52, 0.59, 0.51, 0.62, 0.49, 0.48, 0.5333333333333333, 0.5166666666666667, 0.49, 0.61, 0.54, 0.41, 0.55, 0.51, 0.61, 0.56, 0.54, 0.54, 0.47, 0.37, 0.92, 0.51, 0.44, 0.51, 0.67, 0.51, 0.58, 0.57, 0.5, 0.48, 0.55, 0.43, 0.54, 0.92, 0.44, 0.6, 0.5133333333333333, 0.46, 0.46, 0.59, 0.55, 0.39, 0.53, 0.65, 0.51, 0.59, 0.66, 0.53, 0.41, 0.56, 0.77, 0.57, 0.42, 0.5, 0.53, 0.86, 0.5, 0.58, 0.5, 0.73, 0.52, 0.52, 0.51, 0.5, 0.68, 0.59, 0.54, 0.56, 0.4, 0.47, 0.56, 0.51, 0.41, 0.54, 0.61, 0.46, 0.58, 0.57, 0.54, 0.49, 0.6459999999999999, 0.56, 0.42, 0.58, 0.59, 0.72, 0.5733333333333334, 0.5233333333333333, 0.46, 0.5466666666666666, 0.52, 0.59, 0.45, 0.696, 0.53, 0.6, 0.6, 0.706, 0.54, 0.76, 0.49, 0.47, 0.44, 0.4133333333333333, 0.54, 0.46, 0.76, 0.53, 0.59, 0.59, 0.43, 0.56, 0.67, 0.47, 0.66, 0.49, 0.5, 0.55, 0.62, 0.57, 0.6, 0.5, 0.47, 0.48, 0.48, 0.5, 0.565, 0.51, 0.51, 0.5, 0.43, 0.55, 0.615, 0.53, 0.38, 0.47, 0.62, 0.47, 0.49, 0.42, 0.66, 0.6, 0.73, 0.575, 0.52, 0.59, 0.43, 0.55, 0.42, 0.62, 0.71, 0.5483333333333333, 0.52, 0.58, 0.72, 0.54, 0.66, 0.4, 0.41, 0.5, 0.52, 0.41, 0.62, 0.48, 0.63, 0.56, 0.4733333333333334, 0.5633333333333334, 0.46, 0.67, 0.43, 0.55, 0.53, 0.55, 0.68, 0.43666666666666665, 0.5416666666666667, 0.62, 0.4, 0.58, 0.49, 0.73, 0.52, 0.61, 0.56, 0.51, 0.45, 0.5, 0.5533333333333333, 0.55, 0.58, 0.67, 0.52, 0.63, 0.44, 0.45, 0.5633333333333332, 0.64, 0.47, 0.7766666666666666, 0.59, 0.45, 0.47, 0.49, 0.55, 0.42, 0.62, 0.51, 0.56, 0.71, 0.54, 0.59, 0.5533333333333332, 0.49, 0.64, 0.62, 0.695, 0.66, 0.53, 0.48, 0.74, 0.67, 0.55, 0.49, 0.64, 0.57, 0.56, 0.5033333333333334, 0.47, 0.6966666666666665, 0.44, 0.44, 0.51, 0.57, 0.54, 0.55, 0.58, 0.57, 0.6, 0.55, 0.45333333333333337, 0.38, 0.69, 0.55, 0.65, 0.51, 0.51, 0.62, 0.5, 0.75, 0.52, 0.51, 0.53, 0.83, 0.49, 0.55, 0.5, 0.5233333333333333, 0.49, 0.53, 0.77, 0.71, 0.4, 0.49, 0.64, 0.49, 0.42, 0.5825, 0.51, 0.43, 0.43, 0.44, 0.57, 0.88, 0.36, 0.58, 0.7, 0.62, 0.48, 0.5366666666666667, 0.4, 0.53, 0.48, 0.5816666666666667, 0.46, 0.45, 0.48, 0.5, 0.5733333333333333, 0.61, 0.5, 0.59, 0.68, 0.51, 0.41, 0.5, 0.58, 0.55, 0.48, 0.95, 0.44, 0.57, 0.71, 0.47, 0.88, 0.57, 0.5216666666666667, 0.44333333333333336, 0.73, 0.53, 0.54, 0.53, 0.4, 0.62, 0.6, 0.6625, 0.55, 0.47, 0.4733333333333334, 0.44, 0.35, 0.64, 0.54, 0.62, 0.43333333333333335, 0.59, 0.6, 0.39, 0.52, 0.62, 0.5133333333333333, 0.62, 0.53, 0.6, 0.56, 0.56, 0.75, 0.63, 0.51, 0.57, 0.5133333333333333, 0.43, 0.69, 0.65, 0.44, 0.59, 0.47, 0.47, 0.46, 0.45333333333333337, 0.51, 0.46, 0.59, 0.5833333333333334, 0.575, 0.6, 0.47, 0.62, 0.65, 0.48, 0.47666666666666674, 0.57, 0.7433333333333334, 0.61, 0.58, 0.71, 0.51, 0.73, 0.6116666666666667, 0.59, 0.52, 0.55, 0.43, 0.66, 0.47, 0.52, 0.7966666666666665, 0.48, 0.515, 0.5589999999999999, 0.58, 0.45, 0.57, 0.64, 0.455, 0.57, 0.55, 0.47, 0.65, 0.56, 0.44, 0.55, 0.53, 0.5633333333333334, 0.5833333333333333, 0.7866666666666666, 0.69, 0.7, 0.3, 0.56, 0.52, 0.54, 0.505, 0.6, 0.47, 0.56, 0.47, 0.595, 0.52, 0.51, 0.66, 0.405, 0.49, 0.57, 0.45, 0.58, 0.79, 0.53, 0.6, 0.51, 0.51, 0.5866666666666667, 0.57, 0.77, 0.74, 0.46, 0.55, 0.62, 0.53, 0.55, 0.69, 0.65, 0.45, 0.45, 0.59, 0.52, 0.55, 0.62, 0.69, 0.53, 0.49, 0.41, 0.5, 0.69, 0.69, 0.52, 0.5, 0.49, 0.67, 0.68, 0.59, 0.36, 0.48, 0.52, 0.77, 0.55, 0.74, 0.57, 0.44, 0.51, 0.94, 0.55, 0.64, 0.88, 0.44, 0.72, 0.67, 0.52, 0.46, 0.45, 0.64, 0.57, 0.52, 0.68, 0.66, 0.59, 0.47, 0.5733333333333333, 0.7866666666666666, 0.65, 0.61, 0.59, 0.54, 0.54, 0.48, 0.41, 0.47, 0.52, 0.44, 0.54, 0.54, 0.3866666666666667, 0.45, 0.53, 0.58, 0.525, 0.46, 0.67, 0.64, 0.48, 0.48, 0.47, 0.51, 0.55, 0.48, 0.5216666666666667, 0.64, 0.6, 0.5, 0.66, 0.6825, 0.51, 0.4875, 0.5, 0.65, 0.59, 0.51, 0.42, 0.54, 0.7, 0.57, 0.58, 0.54, 0.5, 0.52, 0.48, 0.5925, 0.38, 0.63, 0.54, 0.53, 0.41, 0.55, 0.5, 0.54, 0.42, 0.45, 0.56, 0.61, 0.4966666666666667, 0.73, 0.87, 0.68, 0.5916666666666667, 0.51, 0.51, 0.65, 0.45, 0.44, 0.45, 0.63, 0.47, 0.55, 0.4633333333333334, 0.54, 0.51, 0.5, 0.41, 0.58, 0.55, 0.49, 0.5233333333333333, 0.5666666666666668, 0.44, 0.75, 0.51, 0.68, 0.515, 0.7, 0.6, 0.47, 0.49, 0.39666666666666667, 0.5, 0.74, 0.5233333333333333, 0.52, 0.6625, 0.58, 0.5, 0.86, 0.5, 0.6, 0.55, 0.54, 0.51, 0.58, 0.53, 0.7, 0.64, 0.43, 0.45, 0.53, 0.42, 0.58, 0.58, 0.53, 0.5033333333333334, 0.63, 0.82, 0.59, 0.46, 0.7, 0.63, 0.4, 0.75, 0.54, 0.5766666666666667, 0.57, 0.54, 0.4, 0.58, 0.54, 0.45, 0.78, 0.358, 0.47, 0.51, 0.74, 0.66, 0.49, 0.41, 0.53, 0.47, 0.5433333333333333, 0.5, 0.5, 0.59, 0.5533333333333332, 0.5925, 0.5, 0.64, 0.46, 0.59, 0.43, 0.74, 0.49, 0.46, 0.72, 0.45, 0.5733333333333333, 0.58, 0.52, 0.45, 0.47, 0.48, 0.54, 0.44, 0.5, 0.58, 0.45, 0.48, 0.41, 0.54, 0.56, 0.46, 0.58, 0.78, 0.6, 0.59, 0.55, 0.34, 0.46333333333333326, 0.43, 0.40333333333333327, 0.55, 0.49, 0.42, 0.6, 0.6, 0.53, 0.73, 0.52, 0.59, 0.47, 0.52, 0.505, 0.57, 0.53, 0.76, 0.49, 0.54, 0.53, 0.49, 0.44, 0.64, 0.56, 0.56, 0.72, 0.51, 0.5, 0.41, 0.68, 0.77, 0.52, 0.39, 0.56, 0.6, 0.64, 0.76, 0.49, 0.53, 0.54, 0.6116666666666667, 0.44, 0.59, 0.41, 0.5, 0.71, 0.67, 0.5, 0.52, 0.46, 0.61, 0.45, 0.53, 0.47, 0.34, 0.47, 0.5, 0.535, 0.52, 0.52, 0.65, 0.68, 0.47, 0.45, 0.6, 0.6, 0.47, 0.65, 0.395, 0.77, 0.56, 0.56, 0.5, 0.8166666666666665, 0.52, 0.52, 0.69, 0.54, 0.38, 0.63, 0.77, 0.51, 0.636, 0.595, 0.49, 0.53, 0.56, 0.5066666666666667, 0.62, 0.5033333333333333, 0.58, 0.72, 0.83, 0.61, 0.66, 0.51, 0.5533333333333333, 0.67, 0.44, 0.58, 0.5733333333333333, 0.52, 0.43, 0.47, 0.4933333333333333, 0.62, 0.96, 0.54, 0.64, 0.5233333333333333, 0.77, 0.39, 0.86, 0.47, 0.74, 0.5, 0.42, 0.52, 0.665, 0.66, 0.48, 0.48, 0.62, 0.53, 0.48, 0.48, 0.43, 0.59, 0.48, 0.65, 0.5333333333333333, 0.49, 0.53, 0.56, 0.56, 0.52, 0.69, 0.555, 0.6, 0.7, 0.49, 0.5166666666666667, 0.505, 0.45, 0.7, 0.57, 0.45, 0.5, 0.57, 0.46, 0.58, 0.61, 0.56, 0.43, 0.74, 0.57, 0.49, 0.55, 0.53, 0.55, 0.59, 0.56, 0.82, 0.46, 0.64, 0.53, 0.41, 0.5, 0.7666666666666666, 0.53, 0.4575, 0.54, 0.45, 0.58, 0.56, 0.52, 0.51, 0.53, 0.43, 0.43, 0.7, 0.585, 0.47, 0.53, 0.51, 0.38, 0.49, 0.84, 0.53, 0.49, 0.41, 0.67, 0.74, 0.52, 0.49, 0.6, 0.475, 0.48, 0.6033333333333333, 0.5, 0.5, 0.49, 0.39, 0.6, 0.67, 0.75, 0.49, 0.87, 0.63, 0.73, 0.53, 0.56, 0.75, 0.6933333333333335, 0.48666666666666664, 0.49, 0.61, 0.59, 0.68, 0.93, 0.75, 0.6, 0.53, 0.56, 0.43, 0.75, 0.54, 0.48, 0.7, 0.67, 0.57, 0.53, 0.48, 0.68, 0.34, 0.59, 0.5333333333333333, 0.76, 0.46, 0.52, 0.52, 0.56, 0.56, 0.53, 0.55, 0.57, 0.65, 0.63, 0.55, 0.56, 0.57, 0.68, 0.43, 0.58, 0.5233333333333333, 0.49, 0.48, 0.5, 0.5333333333333333, 0.71, 0.66, 0.51, 0.55, 0.56, 0.59, 0.51, 0.73, 0.69, 0.42, 0.5, 0.44, 0.74, 0.85, 0.54, 0.44, 0.65, 0.5033333333333334, 0.52, 0.55, 0.44, 0.45, 0.76, 0.59, 0.43, 0.64, 0.49, 0.48, 0.59, 0.5, 0.59, 0.71, 0.77, 0.585, 0.41, 0.49, 0.52, 0.56, 0.64, 0.63, 0.38, 0.6283333333333333, 0.58, 0.59, 0.6, 0.51, 0.55, 0.5, 0.46, 0.6, 0.5825, 0.54, 0.43, 0.64, 0.54, 0.43, 0.57, 0.49333333333333335, 0.68, 0.71, 0.54, 0.49, 0.39, 0.48, 0.54, 0.52, 0.43, 0.5, 0.88, 0.61, 0.57, 0.7, 0.48, 0.83, 0.46, 0.56, 0.716, 0.52, 0.47, 0.47, 0.47, 0.55, 0.54, 0.65, 0.52, 0.43, 0.56, 0.46, 0.64, 0.54, 0.8, 0.61, 0.62, 0.57, 0.55, 0.55, 0.45, 0.51, 0.5, 0.6, 0.54, 0.36666666666666664, 0.8, 0.55, 0.64, 0.7125, 0.54, 0.48, 0.5333333333333333, 0.47, 0.5333333333333333, 0.47, 0.74, 0.41, 0.5166666666666666, 0.59, 0.43, 0.77, 0.51, 0.53, 0.52, 0.5, 0.5, 0.4233333333333333, 0.61, 0.67, 0.78, 0.46, 0.52, 0.56, 0.95, 0.47, 0.57, 0.71, 0.61, 0.64, 0.4, 0.5, 0.55, 0.56, 0.36, 0.5533333333333333, 0.405, 0.39, 0.69, 0.49, 0.57, 0.61, 0.48, 0.51, 0.49, 0.77, 0.74, 0.86, 0.51, 0.44, 0.49, 0.5, 0.41, 0.49, 0.53, 0.7, 0.58, 0.68, 0.49, 0.51, 0.64, 0.77, 0.73, 0.49, 0.44, 0.64, 0.63, 0.64, 0.7, 0.54, 0.54, 0.65, 0.49, 0.5, 0.5325, 0.57, 0.43, 0.52, 0.5, 0.525, 0.55, 0.54, 0.8, 0.52, 0.55, 0.45, 0.78, 0.5, 0.6, 0.55, 0.67, 0.47, 0.52, 0.51, 0.46, 0.58, 0.66, 0.48, 0.46, 0.73, 0.51, 0.51, 0.6, 0.47, 0.45333333333333337, 0.72, 0.45, 0.57, 0.41, 0.51, 0.63, 0.78, 0.44, 0.63, 0.48, 0.57, 0.47, 0.56, 0.56, 0.62, 0.465, 0.6283333333333334, 0.57, 0.7, 0.54, 0.505, 0.5133333333333333, 0.55, 0.55, 0.91, 0.42, 0.45, 0.49, 0.49, 0.55, 0.35, 0.64, 0.89, 0.5, 0.4, 0.43, 0.42, 0.4, 0.61, 0.74, 0.45, 0.43, 0.5666666666666667, 0.66, 0.55, 0.37, 0.65, 0.5, 0.49, 0.51, 0.35, 0.51, 0.5133333333333333, 0.55, 0.47, 0.6559999999999999, 0.42, 0.38, 0.49, 0.57, 0.5, 0.5, 0.91, 0.54, 0.54, 0.48, 0.52, 0.5, 0.73, 0.47, 0.6, 0.49, 0.63, 0.87, 0.45, 0.59, 0.4, 0.52, 0.62, 0.5033333333333334, 0.55, 0.54, 0.47, 0.5766666666666667, 0.55, 0.85, 0.72, 0.63, 0.53, 0.4, 0.48, 0.52, 0.5433333333333333, 0.55, 0.43, 0.6, 0.68, 0.66, 0.48, 0.51, 0.42, 0.48, 0.51, 0.82, 0.71, 0.6, 0.53, 0.51, 0.53, 0.54, 0.82, 0.52, 0.49, 0.56, 0.57, 0.71, 0.5566666666666666, 0.49, 0.72, 0.59, 0.3925, 0.65, 0.4, 0.5, 0.42, 0.5633333333333332, 0.62, 0.5, 0.4433333333333333, 0.38, 0.56, 0.47, 0.38, 0.5233333333333333, 0.69, 0.48, 0.48, 0.54, 0.5, 0.59, 0.61, 0.51, 0.48, 0.43, 0.49, 0.57, 0.49, 0.695, 0.51, 0.55, 0.58, 0.57, 0.5608333333333333, 0.67, 0.805, 0.54, 0.51, 0.51, 0.5, 0.385, 0.59, 0.52, 0.4, 0.57, 0.46, 0.69, 0.53, 0.71, 0.66, 0.54, 0.6133333333333333, 0.42, 0.52, 0.38, 0.72, 0.71, 0.53, 0.49333333333333335, 0.68, 0.45, 0.47, 0.5166666666666667, 0.55, 0.49, 0.6, 0.5233333333333333, 0.68, 0.59, 0.42, 0.55, 0.69, 0.5133333333333333, 0.47, 0.82, 0.49, 0.7, 0.62, 0.47, 0.56, 0.43, 0.79, 0.69, 0.57, 0.43, 0.48, 0.66, 0.71, 0.5966666666666667, 0.62, 0.53, 0.47, 0.45, 0.36, 0.71, 0.52, 0.5, 0.575, 0.49, 0.5, 0.745, 0.47, 0.61, 0.75, 0.52, 0.42, 0.51, 0.93, 0.56, 0.545, 0.49, 0.56, 0.43, 0.72, 0.57, 0.5633333333333334, 0.55, 0.64, 0.7, 0.46, 0.54, 0.49666666666666665, 0.47, 0.51, 0.41, 0.42, 0.53, 0.77, 0.46, 0.5333333333333333, 0.52, 0.71, 0.46, 0.579, 0.51, 0.5008333333333334, 0.8, 0.54, 0.94, 0.73, 0.51, 0.7, 0.5983333333333333, 0.49, 0.42, 0.58, 0.66, 0.585, 0.49, 0.5, 0.84, 0.77, 0.47, 0.5, 0.48, 0.5233333333333333, 0.76, 0.4175, 0.64, 0.6659999999999999, 0.6, 0.5, 0.7225, 0.52, 0.5233333333333333, 0.55, 0.7166666666666666, 0.47, 0.49, 0.5825, 0.7, 0.7, 0.58, 0.69, 0.4, 0.51, 0.74, 0.4533333333333333, 0.6, 0.47, 0.55, 0.54, 0.27, 0.53, 0.605, 0.67, 0.405, 0.29, 0.55, 0.48, 0.53, 0.42, 0.61, 0.61, 0.47, 0.61, 0.47, 0.63, 0.55, 0.5366666666666667, 0.58, 0.47, 0.5833333333333334, 0.63, 0.66, 0.54, 0.44, 0.47, 0.55, 0.51, 0.68, 0.53, 0.58, 0.62, 0.41, 0.58, 0.52, 0.59, 0.55, 0.43, 0.48, 0.61, 0.52, 0.43, 0.55, 0.66, 0.5, 0.68, 0.45, 0.5533333333333333, 0.52, 0.61, 0.47, 0.67, 0.75, 0.46, 0.41, 0.38, 0.55, 0.59, 0.72, 0.68, 0.5133333333333333, 0.61, 0.46, 0.55, 0.48, 0.5233333333333333, 0.44, 0.75, 0.5833333333333334, 0.5433333333333333, 0.5, 0.46, 0.47, 0.74, 0.48, 0.63, 0.72, 0.58, 0.64, 0.51, 0.55, 0.55, 0.5366666666666667, 0.48, 0.47, 0.47, 0.45, 0.65, 0.46, 0.5, 0.55, 0.79, 0.79, 0.68, 0.51, 0.62, 0.5, 0.54, 0.43, 0.75, 0.54, 0.61, 0.62, 0.5, 0.44, 0.47, 0.59, 0.53, 0.41, 0.43, 0.8266666666666665, 0.67, 0.48, 0.71, 0.56, 0.44, 0.71, 0.7, 0.465, 0.3466666666666666, 0.58, 0.61, 0.58, 0.59, 0.53, 0.39, 0.59, 0.65, 0.47, 0.77, 0.63, 0.53, 0.46, 0.47, 0.5, 0.6033333333333333, 0.59, 0.47, 0.54, 0.4, 0.62, 0.73, 0.67, 0.43, 0.64, 0.46, 0.43, 0.62, 0.5, 0.54, 0.59, 0.81, 0.58, 0.54, 0.42, 0.48, 0.45, 0.53, 0.72, 0.75, 0.57, 0.59, 0.63, 0.59, 0.51, 0.43, 0.48, 0.71, 0.5, 0.41, 0.5, 0.59, 0.44, 0.38, 0.5866666666666667, 0.51, 0.87, 0.53, 0.5033333333333334, 0.5, 0.73, 0.47, 0.54, 0.4866666666666667, 0.68, 0.56, 0.47, 0.445, 0.715, 0.37, 0.71, 0.57, 0.58, 0.8, 0.44, 0.47, 0.56, 0.5733333333333333, 0.56, 0.46, 0.59, 0.42, 0.5033333333333333, 0.4175, 0.3975, 0.51, 0.515, 0.49, 0.55, 0.62, 0.6725, 0.7, 0.6, 0.82, 0.56, 0.565, 0.58, 0.43, 0.61, 0.54, 0.53, 0.54, 0.49, 0.47, 0.51, 0.49, 0.49, 0.4733333333333334, 0.34, 0.49, 0.6066666666666667, 0.56, 0.65, 0.53, 0.47, 0.32, 0.51, 0.59, 0.48, 0.53, 0.43, 0.47, 0.54, 0.45, 0.51, 0.47, 0.63, 0.45, 0.51, 0.67, 0.54, 0.72, 0.5, 0.55, 0.49, 0.6225, 0.71, 0.45, 0.47, 0.45, 0.62, 0.5233333333333333, 0.64, 0.45, 0.5366666666666667, 0.49, 0.81, 0.52, 0.52, 0.63, 0.4, 0.39, 0.5, 0.77, 0.78, 0.5, 0.46, 0.5266666666666667, 0.47, 0.5925, 0.55, 0.55, 0.59, 0.63, 0.52, 0.52, 0.44, 0.6225, 0.6, 0.47, 0.46, 0.52, 0.65, 0.48, 0.47, 0.65, 0.56, 0.49, 0.49, 0.5, 0.56, 0.6291666666666668, 0.61, 0.59, 0.55, 0.57, 0.5266666666666667, 0.61, 0.7766666666666666, 0.77, 0.54, 0.49, 0.6, 0.56, 0.41, 0.75, 0.43, 0.58, 0.61, 0.55, 0.64, 0.6, 0.56, 0.3983333333333334, 0.64, 0.585, 0.66, 0.45, 0.46, 0.59, 0.47, 0.75, 0.47, 0.7166666666666666, 0.5033333333333334, 0.8, 0.58, 0.51, 0.6, 0.51, 0.5666666666666667, 0.5233333333333333, 0.54, 0.39, 0.555, 0.66, 0.46, 0.5, 0.53, 0.38, 0.5, 0.33, 0.82, 0.56, 0.64, 0.66, 0.51, 0.47, 0.48, 0.706, 0.57, 0.83, 0.49, 0.72, 0.61, 0.64, 0.58, 0.495, 0.41, 0.55, 0.51, 0.55, 0.6, 0.86, 0.55, 0.71, 0.84, 0.76, 0.48, 0.45, 0.74, 0.51, 0.53, 0.61, 0.65, 0.74, 0.52, 0.6, 0.6, 0.4, 0.63, 0.56, 0.63, 0.5, 0.78, 0.38, 0.86, 0.67, 0.59, 0.58, 0.55, 0.53, 0.73, 0.52, 0.5666666666666668, 0.52, 0.83, 0.61, 0.45, 0.46, 0.57, 0.47, 0.73, 0.42, 0.54, 0.77, 0.41, 0.53, 0.7, 0.57, 0.5, 0.49, 0.51, 0.48, 0.5566666666666668, 0.555, 0.45, 0.69, 0.8, 0.51, 0.61, 0.59, 0.54, 0.58, 0.49, 0.43, 0.59, 0.5133333333333333, 0.58, 0.42, 0.54, 0.82, 0.55, 0.48, 0.65, 0.46, 0.52, 0.7, 0.56, 0.47, 0.51, 0.71, 0.5233333333333333, 0.62, 0.47, 0.53, 0.59, 0.485, 0.55, 0.49, 0.66, 0.88, 0.53, 0.54, 0.43, 0.43, 0.49, 0.63, 0.48, 0.4, 0.5533333333333332, 0.46, 0.38, 0.79, 0.47, 0.48, 0.54, 0.86, 0.51, 0.47, 0.56, 0.47, 0.6825, 0.42, 0.62, 0.48, 0.71, 0.5, 0.5, 0.43, 0.78, 0.77, 0.6, 0.54, 0.5, 0.49, 0.58, 0.52, 0.53, 0.51, 0.61, 0.52, 0.48, 0.72, 0.76, 0.58, 0.52, 0.6, 0.52, 0.47, 0.55, 0.64, 0.45, 0.56, 0.51, 0.45, 0.5, 0.71, 0.595, 0.59, 0.57, 0.75, 0.44, 0.52, 0.55, 0.52, 0.3466666666666666, 0.4966666666666667, 0.48, 0.52, 0.5333333333333333, 0.57, 0.51, 0.5733333333333333, 0.67, 0.44, 0.52, 0.695, 0.47, 0.6133333333333334, 0.55, 0.55, 0.65, 0.57, 0.43, 0.73, 0.45, 0.5, 0.5, 0.51, 0.6, 0.67, 0.65, 0.59, 0.49, 0.77, 0.48333333333333334, 0.5666666666666668, 0.47, 0.52, 0.44, 0.73, 0.6659999999999999, 0.445, 0.67, 0.59, 0.56, 0.55, 0.48, 0.7, 0.71, 0.42, 0.47, 0.49, 0.64, 0.59, 0.68, 0.38, 0.46, 0.46, 0.56, 0.65, 0.44, 0.52, 0.67, 0.51, 0.58, 0.47, 0.52, 0.62, 0.63, 0.38, 0.59, 0.66, 0.52, 0.63, 0.5, 0.53, 0.55, 0.49, 0.66, 0.56, 0.55, 0.58, 0.41, 0.51, 0.57, 0.41, 0.57, 0.56, 0.43, 0.49333333333333335, 0.55, 0.62, 0.48, 0.53, 0.5, 0.5566666666666668, 0.61, 0.55, 0.55, 0.45, 0.56, 0.49, 0.78, 0.48, 0.44, 0.63, 0.6, 0.49, 0.76, 0.76, 0.52, 0.58, 0.38, 0.47, 0.51, 0.54, 0.5, 0.46, 0.485, 0.36, 0.44, 0.43, 0.69, 0.66, 0.52, 0.74, 0.38, 0.7666666666666666, 0.67, 0.39, 0.68, 0.525, 0.48, 0.44, 0.68, 0.71, 0.58, 0.57, 0.63, 0.52, 0.52, 0.59, 0.49, 0.52, 0.51, 0.53, 0.64, 0.57, 0.5333333333333333, 0.58, 0.48, 0.4, 0.58, 0.48, 0.6, 0.55, 0.91, 0.88, 0.73, 0.52, 0.53, 0.39, 0.51, 0.59, 0.46, 0.57, 0.63, 0.56, 0.46, 0.405, 0.68, 0.4, 0.45, 0.53, 0.69, 0.48, 0.55, 0.48333333333333334, 0.77, 0.46, 0.45, 0.5, 0.51, 0.45, 0.94, 0.84, 0.66, 0.49, 0.36, 0.7, 0.46, 0.51, 0.71, 0.65, 0.54, 0.58, 0.48, 0.44, 0.5516666666666667, 0.67, 0.51, 0.48, 0.43, 0.42, 0.52, 0.47, 0.6, 0.46, 0.58, 0.61, 0.69, 0.52, 0.69, 0.45, 0.65, 0.54, 0.5358333333333333, 0.47, 0.7666666666666666, 0.51, 0.67, 0.69, 0.69, 0.715, 0.585, 0.66, 0.6, 0.5133333333333333, 0.5433333333333333, 0.6683333333333334, 0.6, 0.58, 0.54, 0.64, 0.57, 0.65, 0.66, 0.55, 0.67, 0.7, 0.46, 0.51, 0.51, 0.93, 0.8066666666666665, 0.5, 0.69, 0.57, 0.48, 0.46, 0.51, 0.64, 0.59, 0.5833333333333333, 0.545, 0.55, 0.42, 0.51, 0.53, 0.48, 0.53, 0.5, 0.56, 0.62, 0.58, 0.7, 0.56, 0.66, 0.41, 0.7, 0.51, 0.51, 0.45, 0.39, 0.47, 0.73, 0.51, 0.53, 0.5, 0.96, 0.41, 0.49, 0.61, 0.69, 0.51, 0.53, 0.51, 0.54, 0.72, 0.47, 0.51, 0.55, 0.47, 0.57, 0.93, 0.64, 0.46, 0.4766666666666666, 0.53, 0.47, 0.5, 0.45, 0.5566666666666666, 0.65, 0.57, 0.56, 0.78, 0.87, 0.55, 0.42, 0.92, 0.48, 0.6, 0.54, 0.51, 0.43, 0.52, 0.6, 0.61, 0.49, 0.78, 0.5, 0.56, 0.57, 0.58, 0.5333333333333333, 0.564, 0.45, 0.41, 0.46, 0.52, 0.39, 0.5733333333333333, 0.58, 0.46, 0.64, 0.52, 0.48, 0.58, 0.52, 0.415, 0.47, 0.53, 0.57, 0.72, 0.52, 0.57, 0.46, 0.52, 0.41, 0.6, 0.52, 0.53, 0.55, 0.775, 0.52, 0.7066666666666666, 0.61, 0.75, 0.44, 0.64, 0.69, 0.44, 0.61, 0.45, 0.68, 0.61, 0.42, 0.58, 0.65, 0.51, 0.45, 0.6125, 0.61, 0.59, 0.44, 0.49, 0.54, 0.53, 0.69, 0.47, 0.54, 0.46, 0.515, 0.5, 0.40333333333333327, 0.65, 0.49, 0.57, 0.45, 0.73, 0.6625, 0.66, 0.47, 0.75, 0.69, 0.75, 0.55, 0.53, 0.43, 0.71, 0.42, 0.52, 0.49, 0.73, 0.83, 0.58, 0.49, 0.545, 0.37, 0.54, 0.6, 0.62, 0.47, 0.78, 0.5925, 0.61, 0.375, 0.58, 0.55, 0.74, 0.5, 0.54, 0.57, 0.7, 0.54, 0.56, 0.5, 0.57, 0.76, 0.55, 0.58, 0.54, 0.53, 0.49, 0.62, 0.49, 0.56, 0.55, 0.51, 0.75, 0.56, 0.36, 0.73, 0.72, 0.39, 0.52, 0.49, 0.68, 0.69, 0.52, 0.4, 0.44, 0.63, 0.42, 0.51, 0.61, 0.69, 0.5566666666666668, 0.49, 0.64, 0.54, 0.49, 0.47, 0.7, 0.5, 0.43, 0.59, 0.49, 0.47, 0.61, 0.42, 0.87, 0.6266666666666666, 0.5333333333333333, 0.56, 0.59, 0.53, 0.68, 0.56, 0.44333333333333336, 0.35, 0.47, 0.63, 0.48, 0.5, 0.41, 0.83, 0.56, 0.49, 0.53, 0.4175, 0.57, 0.5, 0.5533333333333333, 0.5133333333333333, 0.62, 0.69, 0.53, 0.57, 0.58, 0.51, 0.6, 0.58, 0.55, 0.56, 0.5, 0.51, 0.71, 0.52, 0.5133333333333333, 0.51, 0.58, 0.56, 0.83, 0.48, 0.65, 0.63, 0.47, 0.5533333333333333, 0.49, 0.7, 0.5, 0.54, 0.82, 0.67, 0.52, 0.53, 0.51, 0.6833333333333335, 0.55, 0.7, 0.57, 0.57, 0.68, 0.55, 0.72, 0.5, 0.625, 0.54, 0.62, 0.52, 0.71, 0.58, 0.7, 0.485, 0.42, 0.58, 0.52, 0.49, 0.53, 0.48, 0.6, 0.43, 0.48, 0.53, 0.5233333333333333, 0.59, 0.41, 0.41, 0.485, 0.53, 0.7066666666666666, 0.435, 0.35, 0.5233333333333333, 0.51, 0.49333333333333335, 0.54, 0.63, 0.53, 0.44, 0.42, 0.37, 0.5, 0.48, 0.59, 0.395, 0.62, 0.61, 0.7, 0.4633333333333334, 0.53, 0.41, 0.61, 0.54, 0.62, 0.62, 0.61, 0.52, 0.5925, 0.46, 0.6, 0.6, 0.48, 0.57, 0.59, 0.4733333333333333, 0.44, 0.62, 0.83, 0.44, 0.5766666666666667, 0.65, 0.54, 0.55, 0.51, 0.54, 0.48, 0.59, 0.52, 0.5866666666666667, 0.6266666666666667, 0.77, 0.53, 0.53, 0.6, 0.81, 0.53, 0.66, 0.57, 0.55, 0.56, 0.53, 0.68, 0.5233333333333333, 0.69, 0.42, 0.58, 0.54, 0.53, 0.53, 0.53, 0.53, 0.57, 0.56, 0.77, 0.48, 0.53, 0.55, 0.365, 0.49, 0.59, 0.51, 0.92, 0.5233333333333333, 0.54, 0.92, 0.55, 0.51, 0.47, 0.94, 0.73, 0.48, 0.545, 0.49, 0.6033333333333333, 0.6066666666666667, 0.45, 0.44, 0.69, 0.65, 0.72, 0.4, 0.46, 0.52, 0.47, 0.43, 0.46, 0.66, 0.4, 0.5466666666666666, 0.41, 0.47, 0.64, 0.5, 0.5, 0.51, 0.58, 0.58, 0.43, 0.5358333333333333, 0.53, 0.5733333333333334, 0.475, 0.47, 0.39, 0.5, 0.46, 0.48, 0.535, 0.65, 0.5725, 0.49, 0.67, 0.51, 0.78, 0.59, 0.73, 0.6566666666666666, 0.68, 0.68, 0.40399999999999997, 0.545, 0.66, 0.57, 0.42, 0.47, 0.48, 0.49, 0.46, 0.5, 0.67, 0.495, 0.66]\n"
     ]
    }
   ],
   "source": [
    "preds_proba = [i[0] for i in rf_official.predict_proba(test[FEATURES])]\n",
    "print(preds_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 2, 11, 77, 305, 597, 797, 617, 340, 242, 181, 107, 47, 28, 21, 4]\n"
     ]
    }
   ],
   "source": [
    "probs_hist = [len([i for i in preds_proba if i < 0.05]),\n",
    "              len([i for i in preds_proba if i >= 0.05 and i < 0.1]),\n",
    "              len([i for i in preds_proba if i >= 0.1 and i < 0.15]),\n",
    "              len([i for i in preds_proba if i >= 0.15 and i < 0.2]),\n",
    "              len([i for i in preds_proba if i >= 0.2 and i < 0.25]),\n",
    "              len([i for i in preds_proba if i >= 0.25 and i < 0.3]),\n",
    "              len([i for i in preds_proba if i >= 0.3 and i < 0.35]),\n",
    "              len([i for i in preds_proba if i >= 0.35 and i < 0.4]),\n",
    "              len([i for i in preds_proba if i >= 0.4 and i < 0.45]),\n",
    "              len([i for i in preds_proba if i >= 0.45 and i < 0.5]),\n",
    "              len([i for i in preds_proba if i >= 0.5 and i < 0.55]),\n",
    "              len([i for i in preds_proba if i >= 0.55 and i < 0.6]),\n",
    "              len([i for i in preds_proba if i >= 0.6 and i < 0.65]),\n",
    "              len([i for i in preds_proba if i >= 0.65 and i < 0.7]),\n",
    "              len([i for i in preds_proba if i >= 0.7 and i < 0.75]),\n",
    "              len([i for i in preds_proba if i >= 0.75 and i < 0.8]),\n",
    "              len([i for i in preds_proba if i >= 0.8 and i < 0.85]),\n",
    "              len([i for i in preds_proba if i >= 0.85 and i < 0.9]),\n",
    "              len([i for i in preds_proba if i >= 0.9 and i < 0.95]),\n",
    "              len([i for i in preds_proba if i >= 0.95 and i <= 1])]\n",
    "print([i for i in probs_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41291469194312796"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(597+797)/float(sum(probs_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       0.75      0.72      0.73      1242\n",
      "        loss       0.47      0.50      0.48       609\n",
      "\n",
      "    accuracy                           0.65      1851\n",
      "   macro avg       0.61      0.61      0.61      1851\n",
      "weighted avg       0.65      0.65      0.65      1851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test['official_preds'] = preds\n",
    "test['official_preds_proba'] = preds_proba\n",
    "certain_test = test.loc[(test['official_preds_proba'] < 0.45) | (test['official_preds_proba'] > 0.55)]\n",
    "print(classification_report(certain_test['class'], certain_test['official_preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5742083174360931 0.5655197657393851\n"
     ]
    }
   ],
   "source": [
    "fp = test.loc[(test['class'] == 'loss') | (test['official_preds'] == 'gain')].shape[0]\n",
    "fn = test.loc[(test['class'] == 'gain') | (test['official_preds'] == 'loss')].shape[0]\n",
    "\n",
    "certain_fp = certain_test.loc[(certain_test['class'] == 'loss') | (certain_test['official_preds'] == 'gain')].shape[0]\n",
    "certain_fn = certain_test.loc[(certain_test['class'] == 'gain') | (certain_test['official_preds'] == 'loss')].shape[0]\n",
    "print(certain_fp/float(fp), certain_fn/float(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now, let's see how rf_official works for three different use cases: Taxi-Demand, College-Test, and Poverty-Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 0.6\n",
    "taxi_demand = pd.read_csv('taxi-vehicle-collision-records-features-single-column-w-class')\n",
    "taxi_demand = taxi_demand.loc[taxi_demand['containment_fraction'] >= THETA]\n",
    "taxi_demand = normalize_dataset(taxi_demand)\n",
    "taxi_demand['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in taxi_demand.iterrows()]\n",
    "\n",
    "college_test = pd.read_csv('college-debt-records-features-single-column-w-class')\n",
    "college_test = college_test.loc[college_test['containment_fraction'] >= THETA]\n",
    "college_test = normalize_dataset(college_test)\n",
    "college_test['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in college_test.iterrows()]\n",
    "\n",
    "poverty_estimation = pd.read_csv('poverty-estimation-results-features-and-targets-training.csv')\n",
    "poverty_estimation = poverty_estimation.loc[poverty_estimation['containment_fraction'] >= THETA]\n",
    "poverty_estimation = normalize_dataset(poverty_estimation)\n",
    "poverty_estimation['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in poverty_estimation.iterrows()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see how many candidates, successful, and unsuccessful augmentations there are for each case study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 1.0 0.0\n",
      "111 0.7747747747747747 0.22522522522522523\n",
      "11 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(taxi_demand.shape[0], \n",
    "      taxi_demand.loc[taxi_demand['class'] == 'gain'].shape[0]/float(taxi_demand.shape[0]),\n",
    "      taxi_demand.loc[taxi_demand['class'] == 'loss'].shape[0]/float(taxi_demand.shape[0]))\n",
    "\n",
    "print(college_test.shape[0], \n",
    "      college_test.loc[college_test['class'] == 'gain'].shape[0]/float(college_test.shape[0]),\n",
    "      college_test.loc[college_test['class'] == 'loss'].shape[0]/float(college_test.shape[0]))\n",
    "\n",
    "print(poverty_estimation.shape[0], \n",
    "      poverty_estimation.loc[poverty_estimation['class'] == 'gain'].shape[0]/float(poverty_estimation.shape[0]),\n",
    "      poverty_estimation.loc[poverty_estimation['class'] == 'loss'].shape[0]/float(poverty_estimation.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.78      0.88        18\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.50      0.39      0.44        18\n",
      "weighted avg       1.00      0.78      0.88        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = rf_official.predict(taxi_demand[FEATURES])\n",
    "print(classification_report(taxi_demand['class'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.67      0.81        86\n",
      "        loss       0.47      1.00      0.64        25\n",
      "\n",
      "    accuracy                           0.75       111\n",
      "   macro avg       0.74      0.84      0.72       111\n",
      "weighted avg       0.88      0.75      0.77       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = rf_official.predict(college_test[FEATURES])\n",
    "print(classification_report(college_test['class'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        gain       1.00      0.82      0.90        11\n",
      "        loss       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82        11\n",
      "   macro avg       0.50      0.41      0.45        11\n",
      "weighted avg       1.00      0.82      0.90        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = rf_official.predict(poverty_estimation[FEATURES])\n",
    "print(classification_report(poverty_estimation['class'], preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use eli5 to understand why we got lower recall for the case studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 40)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "\n",
    "#low recall means false negatives.\n",
    "preds = rf_official.predict(taxi_demand[FEATURES])\n",
    "taxi_demand['pred'] = preds\n",
    "false_negative = taxi_demand.loc[(taxi_demand['class'] == 'gain') & (taxi_demand['pred'] == 'loss')]\n",
    "false_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.530</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.059\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.044\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.355\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.80%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.023\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.791\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.022\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.037\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.022\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.019\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.056\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.013\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.205\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.006\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.080\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.55%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.417\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.233\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.525\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.15%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.016\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.231\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.02%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.032\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.87%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.032\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_bias = lambda feature_name, feature_value: feature_name != '<BIAS>'\n",
    "eli5.show_prediction(rf_official, false_negative.iloc[0][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.583</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.107\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.005\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.54%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.054\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.037\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.277\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.026\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.018\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.209\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.015\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.037\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.719\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.005\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.418\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.005\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.231\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.141\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.012\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.525\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.177\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.042\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, false_negative.iloc[1][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.580</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.063\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -2.968\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.061\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.008\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.038\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.016\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.031\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.028\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            3.666\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.028\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.027\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.019\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.231\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.005\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.670\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.005\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            4.101\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.06%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.418\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.113\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.005\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.037\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.028\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.030\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.059\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, false_negative.iloc[2][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.620</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.083\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.079\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.012\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.75%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.028\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.253\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.022\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.019\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.016\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.235\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.36%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.113\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.037\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.010\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.703\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.006\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.050\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.005\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.231\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.24%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.646\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.418\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.23%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.053\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, false_negative.iloc[3][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf_official.predict(college_test[FEATURES])\n",
    "college_test['pred'] = preds\n",
    "false_negative = college_test.loc[(college_test['class'] == 'gain') & (college_test['pred'] == 'loss')]\n",
    "sample_false_negative = false_negative.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.530</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.056\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.001\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.047\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.229\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.031\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.021\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.136\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.018\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.017\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.37%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.460\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.54%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.006\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.457\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.127\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.88%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.007\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.009\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.056\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.44%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.037\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.48%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.029\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.029\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, sample_false_negative.iloc[0][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.557</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.074\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.007\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.044\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.039\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.296\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.022\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.061\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.013\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.136\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.460\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.270\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.007\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.457\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.056\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.014\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.092\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.027\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, sample_false_negative.iloc[1][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.520</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.059\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.046\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.455\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.042\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.033\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.027\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.026\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.017\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.059\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.009\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.136\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.457\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.006\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.097\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.013\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.460\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.68%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.026\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.405\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.027\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.034\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.150\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.036\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.604\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, sample_false_negative.iloc[2][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.540</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.083\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.273\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.052\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.047\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.26%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.044\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.038\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.232\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.026\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.019\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.035\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.015\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.363\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 98.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.001\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.457\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.136\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.023\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.029\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.144\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.40%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.029\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.460\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.041\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.052\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.252\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, sample_false_negative.iloc[3][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=loss\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.560</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "                <th style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">Value</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.056\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.267\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.048\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.036\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.036\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.024\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_columns\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.021\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_kurtosis\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.023\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.66%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.020\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -1.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.013\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_num_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.012\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_covariance\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            -0.136\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 93.86%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.131\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.009\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_max_skewness\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.102\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_spearman\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.457\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.000\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_num_of_rows\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 97.35%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_mutual_info\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.015\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.05%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.006\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_max_unique\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.008\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.460\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.051\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        query_row_column_ratio\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.000\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.058\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        candidate_target_max_pearson\n",
       "    </td>\n",
       "    \n",
       "        <td style=\"padding: 0 0.5em 0 1em; text-align: right; border: none;\">\n",
       "            0.130\n",
       "        </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(rf_official, sample_false_negative.iloc[4][FEATURES], \n",
    "                     show_feature_values=True, feature_filter=no_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 38)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rf_official.predict(poverty_estimation[FEATURES])\n",
    "poverty_estimation['pred'] = preds\n",
    "false_negative = poverty_estimation.loc[(poverty_estimation['class'] == 'gain') & (poverty_estimation['pred'] == 'loss')]\n",
    "#sample_false_negative = false_negative.sample(5)\n",
    "false_negative.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check how many candidates there are for each case study keeping THETA = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 39) (1103, 39) (130928, 37)\n"
     ]
    }
   ],
   "source": [
    "THETA = 0.0\n",
    "taxi_demand = pd.read_csv('taxi-vehicle-collision-records-features-single-column-w-class')\n",
    "taxi_demand = taxi_demand.loc[taxi_demand['containment_fraction'] >= THETA]\n",
    "taxi_demand = normalize_dataset(taxi_demand)\n",
    "taxi_demand['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in taxi_demand.iterrows()]\n",
    "\n",
    "college_test = pd.read_csv('college-debt-records-features-single-column-w-class')\n",
    "college_test = college_test.loc[college_test['containment_fraction'] >= THETA]\n",
    "college_test = normalize_dataset(college_test)\n",
    "college_test['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in college_test.iterrows()]\n",
    "\n",
    "poverty_estimation = pd.read_csv('poverty-estimation-results-features-and-targets-training.csv')\n",
    "poverty_estimation = poverty_estimation.loc[poverty_estimation['containment_fraction'] >= THETA]\n",
    "poverty_estimation = normalize_dataset(poverty_estimation)\n",
    "poverty_estimation['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in poverty_estimation.iterrows()]\n",
    "\n",
    "print(taxi_demand.shape, college_test.shape, poverty_estimation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447, 39) (130, 39) (11526, 37)\n"
     ]
    }
   ],
   "source": [
    "print(taxi_demand.loc[taxi_demand['class'] == 'gain'].shape, \n",
    "      college_test.loc[college_test['class'] == 'gain'].shape,\n",
    "      poverty_estimation.loc[poverty_estimation['class'] == 'gain'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The values remained pretty much the same. Let's see how the number candidates varies for different $\\theta$ values, and how IDA performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_for_different_containment_ratios(training, test_datasets):\n",
    "    thresholds = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    for thresh in thresholds:\n",
    "        tmp_training = training.loc[training['containment_fraction'] >= thresh]\n",
    "        tmp_training = normalize_dataset(tmp_training)\n",
    "        rf.fit(tmp_training[FEATURES], tmp_training['class'])\n",
    "        for test_name in test_datasets.keys():\n",
    "            tmp_test = test_datasets[test_name].loc[test_datasets[test_name]['containment_fraction'] >= thresh]\n",
    "            tmp_test = normalize_dataset(tmp_test)\n",
    "            preds = rf.predict(tmp_test[FEATURES])\n",
    "            print('****', test_name, 'containment_fraction >=', thresh)\n",
    "            print(classification_report(tmp_test['class'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('training-simplified-data-generation.csv')\n",
    "training['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in training.iterrows()]\n",
    "\n",
    "college = pd.read_csv('college-debt-records-features-single-column-w-class')\n",
    "college['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in college.iterrows()]\n",
    "\n",
    "poverty = pd.read_csv('poverty-estimation-results-features-and-targets-training.csv')\n",
    "poverty['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in poverty.iterrows()]\n",
    "\n",
    "taxi = pd.read_csv('taxi-vehicle-collision-records-features-single-column-w-class')\n",
    "taxi['class'] = ['gain' if row['gain_in_r2_score'] > 0 else 'loss' for index, row in taxi.iterrows()]\n",
    "\n",
    "test = {'college': college, 'poverty': poverty, 'taxi': taxi}\n",
    "\n",
    "calculate_performance_for_different_containment_ratios(training, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to run the code in the cell above here was taking too long, so I ran on ipython and these were the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**** college containment_fraction >= 1.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.67      0.80         6\n",
    "        loss       0.60      1.00      0.75         3\n",
    "\n",
    "    accuracy                           0.78         9\n",
    "   macro avg       0.80      0.83      0.77         9\n",
    "weighted avg       0.87      0.78      0.78         9\n",
    "\n",
    "**** poverty containment_fraction >= 1.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      1.00      1.00        11\n",
    "\n",
    "    accuracy                           1.00        11\n",
    "   macro avg       1.00      1.00      1.00        11\n",
    "weighted avg       1.00      1.00      1.00        11\n",
    "\n",
    "**** taxi containment_fraction >= 1.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.83      0.91         6\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.83         6\n",
    "   macro avg       0.50      0.42      0.45         6\n",
    "weighted avg       1.00      0.83      0.91         6\n",
    "\n",
    "**** college containment_fraction >= 0.9\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.77      0.98      0.86        84\n",
    "        loss       0.00      0.00      0.00        25\n",
    "\n",
    "    accuracy                           0.75       109\n",
    "   macro avg       0.38      0.49      0.43       109\n",
    "weighted avg       0.59      0.75      0.66       109\n",
    "\n",
    "**** poverty containment_fraction >= 0.9\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      1.00      1.00        11\n",
    "\n",
    "    accuracy                           1.00        11\n",
    "   macro avg       1.00      1.00      1.00        11\n",
    "weighted avg       1.00      1.00      1.00        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.9\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.89      0.94        18\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.89        18\n",
    "   macro avg       0.50      0.44      0.47        18\n",
    "weighted avg       1.00      0.89      0.94        18\n",
    "\n",
    "**** college containment_fraction >= 0.8\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.80      0.98      0.88        84\n",
    "        loss       0.71      0.20      0.31        25\n",
    "\n",
    "    accuracy                           0.80       109\n",
    "   macro avg       0.76      0.59      0.60       109\n",
    "weighted avg       0.78      0.80      0.75       109\n",
    "\n",
    "**** poverty containment_fraction >= 0.8\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.91      0.95        11\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.91        11\n",
    "   macro avg       0.50      0.45      0.48        11\n",
    "weighted avg       1.00      0.91      0.95        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.8\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.94      0.97        18\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.94        18\n",
    "   macro avg       0.50      0.47      0.49        18\n",
    "weighted avg       1.00      0.94      0.97        18\n",
    "\n",
    "**** college containment_fraction >= 0.7\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.79      1.00      0.88        84\n",
    "        loss       1.00      0.08      0.15        25\n",
    "\n",
    "    accuracy                           0.79       109\n",
    "   macro avg       0.89      0.54      0.51       109\n",
    "weighted avg       0.83      0.79      0.71       109\n",
    "\n",
    "**** poverty containment_fraction >= 0.7\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      1.00      1.00        11\n",
    "\n",
    "    accuracy                           1.00        11\n",
    "   macro avg       1.00      1.00      1.00        11\n",
    "weighted avg       1.00      1.00      1.00        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.7\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.72      0.84        18\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.72        18\n",
    "   macro avg       0.50      0.36      0.42        18\n",
    "weighted avg       1.00      0.72      0.84        18\n",
    "\n",
    "**** college containment_fraction >= 0.6\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.67      0.81        86\n",
    "        loss       0.47      1.00      0.64        25\n",
    "\n",
    "    accuracy                           0.75       111\n",
    "   macro avg       0.74      0.84      0.72       111\n",
    "weighted avg       0.88      0.75      0.77       111\n",
    "\n",
    "**** poverty containment_fraction >= 0.6\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.82      0.90        11\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.82        11\n",
    "   macro avg       0.50      0.41      0.45        11\n",
    "weighted avg       1.00      0.82      0.90        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.6\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.78      0.88        18\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.78        18\n",
    "   macro avg       0.50      0.39      0.44        18\n",
    "weighted avg       1.00      0.78      0.88        18\n",
    "\n",
    "**** college containment_fraction >= 0.5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.81      0.98      0.89        92\n",
    "        loss       0.67      0.16      0.26        25\n",
    "\n",
    "    accuracy                           0.80       117\n",
    "   macro avg       0.74      0.57      0.57       117\n",
    "weighted avg       0.78      0.80      0.75       117\n",
    "\n",
    "**** poverty containment_fraction >= 0.5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      1.00      1.00        11\n",
    "\n",
    "    accuracy                           1.00        11\n",
    "   macro avg       1.00      1.00      1.00        11\n",
    "weighted avg       1.00      1.00      1.00        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.94      0.97        18\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.94        18\n",
    "   macro avg       0.50      0.47      0.49        18\n",
    "weighted avg       1.00      0.94      0.97        18\n",
    "\n",
    "**** college containment_fraction >= 0.4\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.91      0.92      0.91        98\n",
    "        loss       0.67      0.64      0.65        25\n",
    "\n",
    "    accuracy                           0.86       123\n",
    "   macro avg       0.79      0.78      0.78       123\n",
    "weighted avg       0.86      0.86      0.86       123\n",
    "\n",
    "**** poverty containment_fraction >= 0.4\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      1.00      1.00        11\n",
    "\n",
    "    accuracy                           1.00        11\n",
    "   macro avg       1.00      1.00      1.00        11\n",
    "weighted avg       1.00      1.00      1.00        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.4\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.33      0.50        18\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.33        18\n",
    "   macro avg       0.50      0.17      0.25        18\n",
    "weighted avg       1.00      0.33      0.50        18\n",
    "\n",
    "**** college containment_fraction >= 0.3\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.82      0.98      0.89       100\n",
    "        loss       0.60      0.12      0.20        25\n",
    "\n",
    "    accuracy                           0.81       125\n",
    "   macro avg       0.71      0.55      0.55       125\n",
    "weighted avg       0.77      0.81      0.75       125\n",
    "\n",
    "**** poverty containment_fraction >= 0.3\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.91      0.95        11\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.91        11\n",
    "   macro avg       0.50      0.45      0.48        11\n",
    "weighted avg       1.00      0.91      0.95        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.3\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.50      0.67        18\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.50        18\n",
    "   macro avg       0.50      0.25      0.33        18\n",
    "weighted avg       1.00      0.50      0.67        18\n",
    "\n",
    "**** college containment_fraction >= 0.2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.73      1.00      0.84       120\n",
    "        loss       1.00      0.12      0.21        51\n",
    "\n",
    "    accuracy                           0.74       171\n",
    "   macro avg       0.86      0.56      0.53       171\n",
    "weighted avg       0.81      0.74      0.65       171\n",
    "\n",
    "**** poverty containment_fraction >= 0.2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      1.00      1.00        11\n",
    "\n",
    "    accuracy                           1.00        11\n",
    "   macro avg       1.00      1.00      1.00        11\n",
    "weighted avg       1.00      1.00      1.00        11\n",
    "\n",
    "**** taxi containment_fraction >= 0.2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.59      0.74        22\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.59        22\n",
    "   macro avg       0.50      0.30      0.37        22\n",
    "weighted avg       1.00      0.59      0.74        22\n",
    "\n",
    "**** college containment_fraction >= 0.1\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.72      0.97      0.83       122\n",
    "        loss       0.64      0.13      0.22        53\n",
    "\n",
    "    accuracy                           0.71       175\n",
    "   macro avg       0.68      0.55      0.52       175\n",
    "weighted avg       0.69      0.71      0.64       175\n",
    "\n",
    "**** poverty containment_fraction >= 0.1\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.80      0.80      0.80        15\n",
    "        loss       0.25      0.25      0.25         4\n",
    "\n",
    "    accuracy                           0.68        19\n",
    "   macro avg       0.53      0.53      0.53        19\n",
    "weighted avg       0.68      0.68      0.68        19\n",
    "\n",
    "**** taxi containment_fraction >= 0.1\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.98      0.99        66\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.98        66\n",
    "   macro avg       0.50      0.49      0.50        66\n",
    "weighted avg       1.00      0.98      0.99        66\n",
    "\n",
    "**** college containment_fraction >= 0.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.25      0.95      0.39       130\n",
    "        loss       0.99      0.61      0.75       973\n",
    "\n",
    "    accuracy                           0.65      1103\n",
    "   macro avg       0.62      0.78      0.57      1103\n",
    "weighted avg       0.90      0.65      0.71      1103\n",
    "\n",
    "**** poverty containment_fraction >= 0.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       0.10      0.60      0.18     11526\n",
    "        loss       0.93      0.50      0.65    119402\n",
    "\n",
    "    accuracy                           0.51    130928\n",
    "   macro avg       0.52      0.55      0.41    130928\n",
    "weighted avg       0.86      0.51      0.61    130928\n",
    "\n",
    "**** taxi containment_fraction >= 0.0\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        gain       1.00      0.53      0.69       447\n",
    "        loss       0.00      0.00      0.00         0\n",
    "\n",
    "    accuracy                           0.53       447\n",
    "   macro avg       0.50      0.27      0.35       447\n",
    "weighted avg       1.00      0.53      0.69       447"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
