#!/usr/bin/env python3
import json
import sys
from learning_task import *

if __name__ == '__main__':
    """This script reads files with features generated by 
    generate_data_for_augmentation_learning_spark.py, and  
    generates a machine learning model to learn relative gains 
    in performance metrics
    """

    # Reads a parameter file in the format described in the README
    if len(sys.argv) == 1:
        params = json.load(open('params.json'))
    else:
        params = json.load(open(sys.argv[1]))

    # Files with features and relative gains in performance after augmentation
    # If len(augmentation_learning_data_filenames) == 1, training and test are
    # determined by cross validation. Otherwise, if
    # len(augmentation_learning_data_filenames) == 2, training examples are in the
    # first file and test ones are in the second.
    augmentation_learning_data_filenames = params['augmentation_learning_data_filenames']

    # Reads data, learns models, and returns models and test_data for each data fold. 
    # The model can be a random forest, a decision tree, or a linear regression, and test_data is a
    # list where each item has the index of the test instances and their true relative
    # performance gain, so we can adequately evaluate the models over them. 
    #learning_task = LearningTask('training-test')
    learning_task = LearningTask('cross-validation')
    learning_task.read_features_and_targets(augmentation_learning_data_filenames)
    n_splits = params['n_splits']
    models, test_data = learning_task.execute_random_forest(n_splits) #, feature_ids=[20, 21, 22, 23, 24, 25])
