- Plot best regressors against target
- Understand cases to which the errors are very high
- Normalize metric: MSE is not very informative as of now
- Work with synthetic data in the format 
     <initial column, candidate-for-augmentation column, target variable, initial r2 score, r2 score after augmentation>
-- This is important for technical reasons (every instance finally leads to the same number of features, which is not possible with datasets because they have a variable number of columns), and to have a finer understanding of which parts of the datasets help in the augmentation best
- instead of using prediction of gains/losses in r2 squares, we could model the task as a binary classification: was the augmentation successful (final r2 score > initial r2 score) or not?
- how do random forests and linear regression compare in the generation of synthetic data sets (SD1 and SD2)? 
- should we use other features? what about latent features (like those derived from PCA)?
-- neural networks  are interesting here because they naturally create new features (plus being "fashionable", and finding a good architecture would be a contribution as well)
- does it help in practice? can we see if it's good for auctus?
