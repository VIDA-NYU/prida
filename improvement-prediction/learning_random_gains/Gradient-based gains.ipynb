{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we analyze whether using big drops (calculated in a gradient-based fashion) in the gains brought by candidate features might help us determine classes \"gain\" and \"loss\" in a way that is more meaningul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import median_absolute_deviation\n",
    "import math\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by analyzing the initial gain for the college dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(data, target_variable_name):\n",
    "    \"\"\"Builds a model using data to predict the target variable.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data.drop(target_variable_name, axis=1),\n",
    "        data[target_variable_name],\n",
    "        test_size=0.33,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # normalizing data first\n",
    "    scaler_X = StandardScaler().fit(X_train)\n",
    "    scaler_y = StandardScaler().fit(y_train.values.reshape(-1, 1))\n",
    "    X_train = scaler_X.transform(X_train)\n",
    "    y_train = scaler_y.transform(y_train.values.reshape(-1, 1))\n",
    "    X_test = scaler_X.transform(X_test)\n",
    "    y_test = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "    forest = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=len(data.columns)-1\n",
    "    )\n",
    "    forest.fit(X_train, y_train.ravel())\n",
    "    yfit = forest.predict(X_test)\n",
    "\n",
    "    return r2_score(y_test, yfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_scores(data, target_variable_name, missing_value_imputation):\n",
    "    \"\"\"Builds a model using data to predict the target variable,\n",
    "    returning different performance metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    if missing_value_imputation:\n",
    "        \n",
    "        # imputation on data\n",
    "        fill_NaN = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        new_data = pd.DataFrame(fill_NaN.fit_transform(data))\n",
    "        new_data.columns = data.columns\n",
    "        new_data.index = data.index\n",
    "\n",
    "        # training and testing model\n",
    "        return train_and_test_model(new_data, target_variable_name)\n",
    "\n",
    "    else:\n",
    "        return train_and_test_model(data, target_variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>PCIP16</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>UGDS_WHITE</th>\n",
       "      <th>UGDS_BLACK</th>\n",
       "      <th>UGDS_HISP</th>\n",
       "      <th>UGDS_ASIAN</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATWRMID</th>\n",
       "      <th>UGDS</th>\n",
       "      <th>DEBT_EARNINGS_RATIO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNITID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12268508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207564</th>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2297</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2164.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420024</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0.5665</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.0</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164492</th>\n",
       "      <td>0.7465</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2621</td>\n",
       "      <td>0.6518</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234085</th>\n",
       "      <td>0.4589</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7992</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>575.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1713.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PCTFLOAN  PCIP16  PPTUG_EF  UGDS_WHITE  UGDS_BLACK  UGDS_HISP  \\\n",
       "UNITID                                                                    \n",
       "12268508       NaN     NaN       NaN         NaN         NaN        NaN   \n",
       "207564      0.4750  0.0000    0.2297      0.2953      0.0291     0.0647   \n",
       "420024      0.8125  0.0000    0.2315      0.2808      0.5665     0.0493   \n",
       "164492      0.7465  0.0000    0.2621      0.6518      0.1258     0.1022   \n",
       "234085      0.4589  0.0321    0.0000      0.7992      0.0607     0.0584   \n",
       "\n",
       "          UGDS_ASIAN  SATMTMID  SATVRMID  SATWRMID    UGDS  \\\n",
       "UNITID                                                       \n",
       "12268508         NaN       NaN       NaN       NaN     NaN   \n",
       "207564        0.0051       NaN       NaN       NaN  2164.0   \n",
       "420024        0.0000       NaN       NaN       NaN   203.0   \n",
       "164492        0.0123       NaN       NaN       NaN  1057.0   \n",
       "234085        0.0420     575.0     575.0       NaN  1713.0   \n",
       "\n",
       "          DEBT_EARNINGS_RATIO  \n",
       "UNITID                         \n",
       "12268508                   49  \n",
       "207564                     36  \n",
       "420024                    127  \n",
       "164492                     76  \n",
       "234085                     53  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_debt = pd.read_csv('data/college-debt-v2.csv')\n",
    "college_debt.index = college_debt['UNITID']\n",
    "college_debt.drop(['UNITID'], axis=1, inplace=True)\n",
    "college_debt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39565581099809455"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_query = get_performance_scores(\n",
    "    college_debt,\n",
    "    'DEBT_EARNINGS_RATIO',\n",
    "    True\n",
    ")\n",
    "scores_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's see the gains that we get for all of its candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>target</th>\n",
       "      <th>candidate</th>\n",
       "      <th>query_num_of_columns</th>\n",
       "      <th>query_num_of_rows</th>\n",
       "      <th>query_row_column_ratio</th>\n",
       "      <th>query_max_mean</th>\n",
       "      <th>query_max_outlier_percentage</th>\n",
       "      <th>query_max_skewness</th>\n",
       "      <th>query_max_kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>decrease_in_mae</th>\n",
       "      <th>decrease_in_mse</th>\n",
       "      <th>decrease_in_medae</th>\n",
       "      <th>gain_in_r2_score</th>\n",
       "      <th>r2_score_before</th>\n",
       "      <th>r2_score_after</th>\n",
       "      <th>class</th>\n",
       "      <th>p(gain)</th>\n",
       "      <th>p(loss)</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>DEBT_EARNINGS_RATIO</td>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>415.833333</td>\n",
       "      <td>3141.540889</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>5.838487</td>\n",
       "      <td>50.966273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>-0.018932</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.095708</td>\n",
       "      <td>0.395656</td>\n",
       "      <td>0.357789</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.27</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>DEBT_EARNINGS_RATIO</td>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>415.833333</td>\n",
       "      <td>3141.540889</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>5.838487</td>\n",
       "      <td>50.966273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>-0.018932</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.095708</td>\n",
       "      <td>0.395656</td>\n",
       "      <td>0.357789</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>DEBT_EARNINGS_RATIO</td>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>415.833333</td>\n",
       "      <td>3141.540889</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>5.838487</td>\n",
       "      <td>50.966273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>-0.018932</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.095708</td>\n",
       "      <td>0.395656</td>\n",
       "      <td>0.357789</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>DEBT_EARNINGS_RATIO</td>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>415.833333</td>\n",
       "      <td>3141.540889</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>5.838487</td>\n",
       "      <td>50.966273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>-0.018932</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.095708</td>\n",
       "      <td>0.395656</td>\n",
       "      <td>0.357789</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>DEBT_EARNINGS_RATIO</td>\n",
       "      <td>/Users/fchirigati/projects/dataset-ranking/use...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>415.833333</td>\n",
       "      <td>3141.540889</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>5.838487</td>\n",
       "      <td>50.966273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012156</td>\n",
       "      <td>-0.018932</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>-0.095708</td>\n",
       "      <td>0.395656</td>\n",
       "      <td>0.357789</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>fp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query               target  \\\n",
       "0  /Users/fchirigati/projects/dataset-ranking/use...  DEBT_EARNINGS_RATIO   \n",
       "1  /Users/fchirigati/projects/dataset-ranking/use...  DEBT_EARNINGS_RATIO   \n",
       "2  /Users/fchirigati/projects/dataset-ranking/use...  DEBT_EARNINGS_RATIO   \n",
       "3  /Users/fchirigati/projects/dataset-ranking/use...  DEBT_EARNINGS_RATIO   \n",
       "4  /Users/fchirigati/projects/dataset-ranking/use...  DEBT_EARNINGS_RATIO   \n",
       "\n",
       "                                           candidate  query_num_of_columns  \\\n",
       "0  /Users/fchirigati/projects/dataset-ranking/use...                  12.0   \n",
       "1  /Users/fchirigati/projects/dataset-ranking/use...                  12.0   \n",
       "2  /Users/fchirigati/projects/dataset-ranking/use...                  12.0   \n",
       "3  /Users/fchirigati/projects/dataset-ranking/use...                  12.0   \n",
       "4  /Users/fchirigati/projects/dataset-ranking/use...                  12.0   \n",
       "\n",
       "   query_num_of_rows  query_row_column_ratio  query_max_mean  \\\n",
       "0             4990.0              415.833333     3141.540889   \n",
       "1             4990.0              415.833333     3141.540889   \n",
       "2             4990.0              415.833333     3141.540889   \n",
       "3             4990.0              415.833333     3141.540889   \n",
       "4             4990.0              415.833333     3141.540889   \n",
       "\n",
       "   query_max_outlier_percentage  query_max_skewness  query_max_kurtosis  ...  \\\n",
       "0                      0.009218            5.838487           50.966273  ...   \n",
       "1                      0.009218            5.838487           50.966273  ...   \n",
       "2                      0.009218            5.838487           50.966273  ...   \n",
       "3                      0.009218            5.838487           50.966273  ...   \n",
       "4                      0.009218            5.838487           50.966273  ...   \n",
       "\n",
       "   decrease_in_mae  decrease_in_mse  decrease_in_medae  gain_in_r2_score  \\\n",
       "0         0.012156        -0.018932          -0.013892         -0.095708   \n",
       "1         0.012156        -0.018932          -0.013892         -0.095708   \n",
       "2         0.012156        -0.018932          -0.013892         -0.095708   \n",
       "3         0.012156        -0.018932          -0.013892         -0.095708   \n",
       "4         0.012156        -0.018932          -0.013892         -0.095708   \n",
       "\n",
       "   r2_score_before  r2_score_after  class  p(gain)  p(loss)  eval  \n",
       "0         0.395656        0.357789   loss     0.73     0.27    fp  \n",
       "1         0.395656        0.357789   loss     0.68     0.32    fp  \n",
       "2         0.395656        0.357789   loss     0.69     0.31    fp  \n",
       "3         0.395656        0.357789   loss     0.69     0.31    fp  \n",
       "4         0.395656        0.357789   loss     0.69     0.31    fp  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_candidate_gains = pd.read_csv('../classification/college-debt-records-features-single-column-w-class')\n",
    "college_candidate_gains.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the gain distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "OUTLIER_THRESHOLD_MAD = 2\n",
    "\n",
    "def remove_outliers_based_on_mad(data):\n",
    "    mad = median_absolute_deviation(data)\n",
    "    median = np.median(data)\n",
    "    return [i for i in data if np.fabs((i - median)/mad) < OUTLIER_THRESHOLD_MAD]\n",
    "\n",
    "def plot_histogram(case_study, gains, remove_outliers_mad=False):\n",
    "    if remove_outliers_mad:\n",
    "        gains = remove_outliers_based_on_mad(gains)\n",
    "\n",
    "    weights = np.ones_like(gains)/float(len(gains))\n",
    "    plt.hist(gains, bins=20, weights=weights)\n",
    "    plt.xlabel('Value Ranges')\n",
    "    plt.ylabel('Percentages')\n",
    "    plt.title('Gains in R2-score - ' + case_study)\n",
    "    plt.show()\n",
    "\n",
    "gains = college_candidate_gains['gain_in_r2_score']\n",
    "plot_histogram('College-Debt', gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the gain distribution for other case studies, too, starting with taxi_collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "taxi_collision = pd.read_csv('../classification/taxi-vehicle-collision-different-class-definitions.csv')\n",
    "gains = taxi_collision['gain_in_r2_score']\n",
    "plot_histogram('Taxi-Collision', gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And for poverty_estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfqklEQVR4nO3de5wcVZn/8c+XhHCHABmRSyQBghoUEWJcZMW4gASR4C7skngDLyDLsnhdDaL8EC+L6IqKuFyUBUTAgC4GzBJFwV1UIIMikEAkBDThOkQChHvk+f1RZ5JK58x0TaZrukm+79erX1N16lTV0zXd9VSdqjqtiMDMzKzReu0OwMzMOpMThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QawFJL1C0jJJw1q83LmSJrVymbbuGsrPk6TPSPruUKxrbeYE0SEkTZV0k6SnJD2Sho+TpGbzRsSfI2LTiPhrK2OKiN0i4vo1mVdSpPeyTNL9kr5eTmCSvibpbklPSrpL0vtaFngHkDQmbYNl6XWfpOltiGOSpMWDmP8USS+U3scySUsrzHeBpC+WywbzeWqyrtXeY0R8OSI+1Op1rWucIDqApE8A3wS+Crwc2AY4FtgHGNHG0AbrdRGxKfAW4AjgA6VpTwGHAFsARwLflPSmoQ+x0Oqzr5KRaRtMA06WNLmm9axG0vAWLeqH6QCk9zWyRcu1ThcRfrXxRbGDfAo4rEm9g4HfA08Ai4BTStPGAAEMT+PXA18Afg08CfwMGJWmbQhcDCwBlgJzgG36WOd9wP5p+BRgBnBRWuZcYEI/8QawS2l8BnBWP/VnAp/oZ/pRwMK07nuBd5emHQ3cmabNA/ZM5a9O22JpindKaZ4LgP8EZqXtvz+wAfA14M/Aw8DZwEZr+H9d5X+SyuYAn0zDb0rjj6e/b0rlU4HuhmV9DJiZhvuMEZgELAY+DTwEXA48A7wILEuv7YCnga1Ly98L6AHWz7yPU4CL+3iPAs4AHknv4zbgNcAxwAvA82mdV/Xxebo8fRafBG4HdgVOTMtbBLyttK73l/7HC4EPp/JN+niPq8QNTEmfgaXpM/Hqhs/5J1P8jwM/BDZs976hE15tD2BdfwGTgeXlHUkf9SYBr6U469s97RzemaatsjNKX4B70hduozR+Wpr2YeAqYGNgWNo5bN7HOhu/0M8Cb0/z/TtwYz/xrkgQwKuAB4GP9VF3ozR9ch/TN6FIjK9M49sCu6XhfwTuB96Qdli7ADsC6wMLgM9QnIX9Xdq59C7jgrQz2Cdt0w2Bb1Akqq2AzdJ2+vc1/L+u+J+kuPah2DHvl5b/GPDeNH1aGt86/V+eBMaVljUHmJqG+4wxfUaWA1+hSCQbpbLFDbHNAv65NH4GcGYf7+MU+k4QBwK3ACPTe3w1sG1p+36xwufpwLQNLqJI/Cel/93RwL2leQ8Gdk7reUvalnuW3nfje1wRN8X34CnggLTsT6XPxohSXDdTJJatKBLRse3eN3TCq+0BrOsv4D3AQw1lv6E40nkG2LeP+b4BnJGGV+yM0vj1wGdLdY8DrknDH0jL371CbI1f6GtL08YDz/Qzb1Ds1J9Kw5cCG/RR90LgGkB9TN8kbY/DaDiiB2YDH8nM82aKo+j1SmWXks680g7sotI0pVh3LpXtXd5JDfD/2vs/WUqx878TOCFNey9wc0P93wJHpeGLgZPT8DiKhLFxsxjTjvJ5Ske/5HeeRwC/TsPD0naa2Mf7OCUtc2npdV2a9nfAH4G/KW/n0vZtliB+Xpp2CMXR/7A0vlnafiP7iOvK3v97H+/xFFYmiM8BM0rT1qM4qJhUius9pemnA2evyf99bXv5GkT7LQFGlduLI+JNUbTzLiFdJ5L0RknXSeqR9DjFNYpR/Sz3odLw08Cmafj7FDvVyyQ9IOl0SetXjLVxmRs2aefeM633COCNFDv6VUj6KkWzxD9F+nZKOrt0QfQzEfFUWsaxwIOSfirpVWkRoynOlhptByyKiBdLZX8Cti+NLyoNd1HshG+RtDRdiL0mla8m3ZHTG+Ob+9kGoyJiy4h4dUR8qxTbnxrqlWO7hOKsAuBdwJUR8XTFGHsi4tl+4gH4CTBe0k4UR9WPR8TN/dSfEREjS6+3AkTEL4FvA2cBD0s6V9LmTdZd9nBp+Bng0Vh5o8Uz6e+mAJIOknSjpL+k9/12+v/8l62yvdNnYhGrfhb6+r6s05wg2u+3wHPAoU3qXULRtDA6IragaHtueodTo4h4ISI+HxHjKdrB3wHUdgdRFGZQvM+Ty9MkfR44iKKt+YnSPMfGyguiX05lsyPiAIrmpbuA81L1RRRND40eAEZLKn/GX0Fx5LhiVaXhRyl2SruVdoRbRHGBOfe+divF+H9NN8Tqse3YUFaO7WcUBw17UCSKSwYQY2P3zKt115wSyAzg3RRnM98fYPzlZX0rIvYCdqNoyvm3vta7piRtAPyI4trLNungaRYrP//N1rXK9k53Bo5m1c+CZThBtFlELAU+D3xH0uGSNpW0Xto5lI+4NwP+EhHPSppIcWQ5YJLeKum16a6dJyguJrb09tg+nAYcI+nlKY4TKd7DARGxpL8ZJW0jaYqkTSiS6TJWxvxd4JOS9lJhF0k7AjdRNMd8StL66f77Q4DLcutIR5XnAWdIella7/aSDhzc286aBewq6V2Shks6gqLJ7uoUy3LgCoq72rYCfj6IGB8Gtpa0RUP5RRQX/qdQNGkNmKQ3pDPb9Sm29bOs/L88DOy0JsvNGEFxTaUHWC7pIOBtpel9vcdeM4CDJe2XYv0ExefoNy2Kb63lBNEBIuJ04OMUF88eofjAn0NxN0rvh/g44FRJT1Icic9Yw9W9nGLn8wRFu/ivWMMdxEBExO1pXb1HmF+mOGq+u9yc1Mfs61F8qR8A/kJxkfK4tNzLgS9RHGU/SdE2vVVEPE+x8zuI4sj7O8D7IuKufsL8NMXFyxslPQFcC7xyzd5x31JCfEd6T0so/u/viIhHS9Uuobiz6vKUMNYoxvR+LwUWpmap7VL5rynu/PldRNzXJOQjGp6DWJYS1OYUCesxiiacJRRH+QDfo2jGWirpyibL71dEPAmcQPGZf4ziwGJms/dYmj6f4lrfmRSfhUOAQ9JnxPqh1OxrZusYSb8ELokIP3FsWU4QZusgSW+gaLoanY7QzVbjJiazdYykCymapj7q5GD98RmEmZll+QzCzMyyWtWZ15AZNWpUjBkzpt1hmJm9pNxyyy2PRkT2wc++vOQSxJgxY+ju7m53GGZmLymSGp/eb8pNTGZmluUEYWZmWU4QZmaW5QRhZmZZThBmZpblBGFmZllOEGZmluUEYWZmWU4QZmaW9ZJ7krqdxkz/6RrPe99pB7cwEjOz+vkMwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLKcIMzMLMsJwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLJqTRCSJkuaL2mBpOl91PknSfMkzZV0SZ3xmJlZdbV11idpGHAWcACwGJgjaWZEzCvVGQecCOwTEY9Jelld8ZiZ2cDUeQYxEVgQEQsj4nngMuDQhjpHA2dFxGMAEfFIjfGYmdkA1JkgtgcWlcYXp7KyXYFdJf1a0o2SJucWJOkYSd2Sunt6emoK18zMyupMEMqURcP4cGAcMAmYBnxX0sjVZoo4NyImRMSErq6ulgdqZmarqzNBLAZGl8Z3AB7I1PlJRLwQEfcC8ykShpmZtVmdCWIOME7SWEkjgKnAzIY6VwJvBZA0iqLJaWGNMZmZWUW1JYiIWA4cD8wG7gRmRMRcSadKmpKqzQaWSJoHXAf8W0QsqSsmMzOrrtbfpI6IWcCshrKTS8MBfDy9zMysg/hJajMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8tygjAzsywnCDMzy3KCMDOzLCcIMzPLcoIwM7MsJwgzM8uqNUFImixpvqQFkqZnph8lqUfSren1oTrjMTOz6obXtWBJw4CzgAOAxcAcSTMjYl5D1R9GxPF1xWFmZmumzjOIicCCiFgYEc8DlwGH1rg+MzNroToTxPbAotL44lTW6DBJt0m6QtLo3IIkHSOpW1J3T09PHbGamVmDOhOEMmXRMH4VMCYidgeuBS7MLSgizo2ICRExoaurq8VhmplZTp0JYjFQPiPYAXigXCEilkTEc2n0PGCvGuMxM7MBqDNBzAHGSRoraQQwFZhZriBp29LoFODOGuMxM7MBqO0upohYLul4YDYwDDg/IuZKOhXojoiZwAmSpgDLgb8AR9UVj5mZDUxtCQIgImYBsxrKTi4NnwicWGcMZma2ZvwktZmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWU5QZiZWZYThJmZZTlBmJlZlhOEmZllOUGYmVmWE4SZmWVVShCSdpa0QRqeJOkESSPrDc3MzNqp6hnEj4C/StoF+B4wFriktqjMzKztqiaIFyNiOfD3wDci4mPAtvWFZWZm7VY1QbwgaRpwJHB1Klu/npDMzKwTVE0Q7wf2Br4UEfdKGgtcXF9YZmbWbsOrVIqIeZI+Dbwijd8LnFZnYGZm1l5V72I6BLgVuCaN7yFpZoX5JkuaL2mBpOn91DtcUkiaUDVwMzOrV9UmplOAicBSgIi4leJOpj5JGgacBRwEjAemSRqfqbcZcAJwU+WozcysdlUTxPKIeLyhLJrMMxFYEBELI+J54DLg0Ey9LwCnA89WjMXMzIZA1QRxh6R3AcMkjZN0JvCbJvNsDywqjS9OZStIej0wOiKuph+SjpHULam7p6enYshmZjYYVRPEvwK7Ac8BlwJPAB9tMo8yZSvOOiStB5wBfKLZyiPi3IiYEBETurq6KoZsZmaDUfUupqeBk9KrqsXA6NL4DsADpfHNgNcA10sCeDkwU9KUiOgewHrMzKwGlRKEpKtY/ZrD40A3cE5E5K4fzAHGpWcm7gemAu/qnZiuaYwqreN64JNODmZmnaFqE9NCYBlwXno9ATwM7JrGV5O65jgemA3cCcyIiLmSTpU0ZbCBm5lZvSqdQQCvj4h9S+NXSfrfiNhX0ty+ZoqIWcCshrKT+6g7qWIsZmY2BKqeQXRJekXvSBrubR56vuVRmZlZ21U9g/gEcIOkeyjuThoLHCdpE+DCuoIzM7P2qXoX0yxJ44BXUSSIu0oXpr9RV3BmZtY+Vc8gAMYBrwQ2BHaXRERcVE9YZmbWblVvc/1/wCSKPpVmUfSvdAPgBGFmtpaqepH6cGA/4KGIeD/wOmCD2qIyM7O2q5ognomIF4HlkjYHHgF2qi8sMzNrt6rXILoljaR4KO4Wiofmbq4tKjMza7uqdzEdlwbPlnQNsHlE3FZfWGZm1m5Vf1HuF73DEXFfRNxWLjMzs7VPv2cQkjYENgZGSdqSlV14bw5sV3NsZmbWRs2amD5M8bsP21Fce+hNEE9Q/JyomZmtpfpNEBHxTeCbkv41Is4copjMzKwDVL1IfaakNwFjyvP4SWozs7VX1Sepvw/sDNwK/DUVB36S2sxsrVX1OYgJwPiIaPxVOTMzW0tVfZL6DorfjDYzs3VE1TOIUcA8STcDz/UWRoR/OtTMbC1VNUGcUmcQZmbWearexfQrSTsC4yLiWkkbA8PqDc3MzNqpalcbRwNXAOekou2BK+sKyszM2q/qRep/AfaheIKaiLgbeFldQZmZWftVTRDPRcTzvSOShlM8B2FmZmupqgniV5I+A2wk6QDgcuCqZjNJmixpvqQFkqZnph8r6XZJt0q6QdL4gYVvZmZ1qZogpgM9wO0UHfjNAj7b3wyShlF06HcQxW9ZT8skgEsi4rURsQdwOvD1AcRuZmY1qnqb60bA+RFxHqzY+W8EPN3PPBOBBRGxMM1zGXAoMK+3QkQ8Uaq/CW62MjPrGFXPIH5BkRB6bQRc22Se7YFFpfHFqWwVkv5F0j0UZxAn5BYk6RhJ3ZK6e3p6KoZsZmaDUTVBbBgRy3pH0vDGTeZRpmy1M4SIOCsidgY+TR/NVhFxbkRMiIgJXV1dFUM2M7PBqJognpK0Z++IpL2AZ5rMsxgYXRrfAXign/qXAe+sGI+ZmdWs6jWIjwCXS+rdwW8LHNFknjnAOEljgfuBqcC7yhUkjUvPVAAcDNyNmZl1hKYJQtJ6wAjgVcArKZqO7oqIF/qbLyKWSzoemE3RLcf5ETFX0qlAd0TMBI6XtD/wAvAYcOSg3o2ZmbVM0wQRES9K+o+I2Jui2+/KImIWxS2x5bKTS8MfGcjyzMxs6FS9BvEzSYdJyl14NjOztVDVaxAfp3hO4a+SnqFoZoqI2Ly2yMzMrK2qdve9Wd2BmJlZZ6na3bckvUfS59L4aEkT6w3NzMzaqeo1iO8Ae7PyNtVlFP0smZnZWqrqNYg3RsSekn4PEBGPSRpRY1xmZtZmVc8gXkgd9AWApC7gxdqiMjOztquaIL4F/DfwMklfAm4AvlxbVGZm1nZV72L6gaRbgP0obnF9Z0TcWWtkZmbWVv0mCEkbAscCu1D8WNA5EbF8KAIzM7P2atbEdCEwgSI5HAR8rfaIzMysIzRrYhofEa8FkPQ94Ob6QzIzs07Q7AxiRY+tbloyM1u3NDuDeJ2k3t+NFrBRGndfTGZma7l+E0REDBuqQMzMrLNUfQ7CzMzWMU4QZmaW5QRhZmZZThBmZpblBGFmZllOEGZmluUEYWZmWU4QZmaWVWuCkDRZ0nxJCyRNz0z/uKR5km6T9AtJO9YZj5mZVVdbgki/QHcWRS+w44FpksY3VPs9MCEidgeuAE6vKx4zMxuYOs8gJgILImJhRDwPXAYcWq4QEddFxNNp9EZghxrjMTOzAagzQWwPLCqNL05lffkg8D+5CZKOkdQtqbunp6eFIZqZWV/qTBDKlEW2ovQeih8m+mpuekScGxETImJCV1dXC0M0M7O+VPpN6jW0GBhdGt8BeKCxkqT9gZOAt0TEczXGY2ZmA1DnGcQcYJyksZJGAFOBmeUKkl4PnANMiYhHaozFzMwGqLYEkX6B7nhgNnAnMCMi5ko6VdKUVO2rwKbA5ZJulTSzj8WZmdkQq7OJiYiYBcxqKDu5NLx/nes3M7M15yepzcwsywnCzMyynCDMzCzLCcLMzLKcIMzMLMsJwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLKcIMzMLMsJwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLKcIMzMLMsJwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLKcIMzMLKvWBCFpsqT5khZImp6Zvq+k30laLunwOmMxM7OBqS1BSBoGnAUcBIwHpkka31Dtz8BRwCV1xWFmZmtmeI3LnggsiIiFAJIuAw4F5vVWiIj70rQXa4xjhTHTfzoUqzEzWyvU2cS0PbCoNL44lQ2YpGMkdUvq7unpaUlwZmbWvzoThDJlsSYLiohzI2JCREzo6uoaZFhmZlZFnQliMTC6NL4D8ECN6zMzsxaqM0HMAcZJGitpBDAVmFnj+szMrIVqSxARsRw4HpgN3AnMiIi5kk6VNAVA0hskLQb+EThH0ty64jEzs4Gp8y4mImIWMKuh7OTS8ByKpiczM+swfpLazMyynCDMzCyr1iYmM7O6DObB1/tOO7iFkay9fAZhZmZZPoMwMxuAdenMxQliiKxLHyozWzu4icnMzLKcIMzMLMsJwszMspwgzMwsywnCzMyynCDMzCzLCcLMzLKcIMzMLMsJwszMspwgzMwsywnCzMyynCDMzCzLnfWZ2TpnMJ1nrkucIMzMhshgE9NQ9+zsJiYzM8tygjAzsywnCDMzy6o1QUiaLGm+pAWSpmembyDph2n6TZLG1BmPmZlVV1uCkDQMOAs4CBgPTJM0vqHaB4HHImIX4AzgK3XFY2ZmA1PnGcREYEFELIyI54HLgEMb6hwKXJiGrwD2k6QaYzIzs4rqvM11e2BRaXwx8Ma+6kTEckmPA1sDj5YrSToGOCaNLpO0pLFOBxpFi2JUfedVLYuxRo6xdV4KcTrGfgxgX5CLcceBrq/OBJE7E4g1qENEnAucu2ImqTsiJgwuvHo5xtZwjK3zUojTMbZGq2Kss4lpMTC6NL4D8EBfdSQNB7YA/lJjTGZmVlGdCWIOME7SWEkjgKnAzIY6M4Ej0/DhwC8jYrUzCDMzG3q1NTGlawrHA7OBYcD5ETFX0qlAd0TMBL4HfF/SAoozh6kVF39u8ypt5xhbwzG2zkshTsfYGi2JUT5gNzOzHD9JbWZmWU4QZmaW1ZEJQtJWkn4u6e70d8tMnR0l3SLpVklzJR1bmnZ96uLj1vR6WYfGuZek21NXI9+q4yHBijHuIem3Kb7bJB1RmnaBpHtL23KPDoxxbOqq5e7UdcuIdsSY6l0jaamkqxvKa9+OLYqzk7blkanO3ZKOLJXX9v3WILoHknRiKp8v6cBWxdSqGCWNkfRMabud3XRlEdFxL+B0YHoang58JVNnBLBBGt4UuA/YLo1fD0x4CcR5M7A3xfMg/wMc1KYYdwXGpeHtgAeBkWn8AuDwDtiO/cU4A5iahs8G/rkdMaZp+wGHAFc3lNe+HVsUZ0dsS2ArYGH6u2Ua3jJNq+X7TXEzzT3ATul7+wdgfEOd44Cz0/BU4IdpeHyqvwEwNi1nWIfFOAa4Y0Drq/sDu4YbYT6wbRreFpjfpP7WwJ8Z+gSxxnGm+neVpk0Dzml3jKneH1i5M659xzaYGCmS66PA8FS+NzC7nTECkzI73tq342Dj7KRt2fh9AM4BpqXhWr7fje8XOBE4saHObGDvNDw8bS811i3X66AYxzDABNGRTUzANhHxIED6mz2FlDRa0m0U3XV8JSLKD+L9VzqN+lwdTTctiHN7igcFey1OZW2JsRTrRIojk3tKxV9KzTpnSNqgw2LcGlgaEcvT5I7Yjn2oezvC4OLspG2Z66qnHEsd3+9m61ylTtpOvd0DVZm33TECjJX0e0m/kvTmZitr20+OSroWeHlm0klVlxERi4DdJW0HXCnpioh4GHh3RNwvaTPgR8B7gYs6KU4qdjMyVDGm5WwLfB84MiJeTMUnAg9R7JDPBT4NnNopMfaxc2jrduxDS7Yj1BpnJ23L/mJp2fd7AOtsVqdl266JwcT4IPCKiFgiaS+KfdFuEfFEXytrW4KIiP37mibpYUnbRsSDaYfwSJNlPSBpLvBm4IqIuD+VPynpEoqeZdfoA1RjnL+m6H6kV64rkiGLUdLmwE+Bz0bEjaVlP5gGn5P0X8AnOyzGR4GRkoano6W2bsd+lt2S7VhznJ20LRdTNIH12oGiaYlWfr8z66zaPdBirdo9UJV5W2GNY4yizek5gIi4RdI9FNf2uvtaWac2MZW74DgS+EljBUk7SNooDW8J7APMlzRc0qhUvj7wDuCOTosz7TCelPQ36Sj4fbn5hyjGEcB/AxdFxOUN07ZNfwW8k3q25RrHmD7011F01dLn/EMRY3+GaDvCIOLssG05G3ibpC3T9+ZtwOyav9+D6R5oJjA13UE0luL62M0tiqslMUrqUvE7PUjaKcW4sN+1tfoiSosuxGwN/AK4O/3dKpVPAL6bhg8AbqO4WHkbcEwq3wS4JZXNBb5JDXcTDDbOUr07KNrSv016sr0NMb4HeAG4tfTaI037JXB7ivNiYNMOjHEnii/jAuBy0l1jQx1jGv8/oAd4huJI7sCh2o4tirOTtuUHUhwLgPenslq/38DbgT+m7+RJqexUYEoa3jBtlwVpO+1UmvekNN98argjcbAxAoelbfYH4HfAIc3W5a42zMwsq1ObmMzMrM2cIMzMLMsJwszMspwgzMwsywnCzMyynCDsJU9F754HNpR9VNJ3msy3rEXrP0XS/anrh3mSprViuWbt5gRha4NLWf3naqem8qFyRkTsARwKnJMe4jJ7SXOCsLXBFcA7ejvAU9H//XbADZI2lfQLSb9T8dsbhzbOLGmSSr+LIOnbko5Kw3uljs1ukTS794novkTE3cDTFF1UI+loSXMk/UHSjyRtnMovUPEbIL+RtFDS4al8PUnfUfG7F1dLmlWalo1F0gnpzOU2SZcNblOareQEYS95EbGE4onRyamotw/8AJ4F/j4i9gTeCvxH6u6iqXQWcCZFN917AecDX2oyz57A3RHR27/QjyPiDRHxOuBO4IOl6tsCf0vRXcRpqewfKLplfi3wIYrunZvFMh14fUTsDqz4QSqzwWpbZ31mLdbbzPST9PcDqVzAlyXtC7xI0RXyNhQ9qzbzSuA1wM9TThlG0SNmzsckHU3RVcXkUvlrJH0RGEnxg1GzS9OujKLX3HmStkllfwtcnsofknRdhVhuA34g6Urgygrvy6wSJwhbW1wJfD0dwW8UEb9L5e8GuoC9IuIFSfdR9FVTtpxVz6Z7pwuYGxF7V1j/GRHxNUn/AFwkaeeIeJbih4LeGRF/SM1Wk0rzPFcaVsPfRv3FcjCwLzAF+JyKLpyXZ+qZDYibmGytEBHLKLqDPp9VL05vATySksNbgR0zs/8JGJ964tyC4uc4oeh0rUvSimYeSbs1iePHFN0n9/amuRnwYGoieneFt3IDcFi6FrENKxNKNhZJ6wGjI+I64FOsPFMxGzSfQdja5FLgx6x6R9MPgKskdVP0AHtX40wRsUjSDIqmmruB36fy59MF4m+lxDEc+AZFj5j9ORW4RNJ5wOeAmyiS0O0UCaM/P6JIUHdQ9Nh5E/B4P7H8Ebg4lYniTGZpk3WYVeLeXM06jKRNI2KZpK0pLr7vExFVrpmYtZTPIMw6z9WSRlL8POkXnBysXXwGYWZmWb5IbWZmWU4QZmaW5QRhZmZZThBmZpblBGFmZln/H90e2et6yS20AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poverty_estimation = pd.read_csv('../classification/poverty-estimation-different-class-definitions.csv')\n",
    "gains = poverty_estimation['gain_in_r2_score']\n",
    "plot_histogram('Poverty Estimation', gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compute the gradients to see when the gains start dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.upload.a817349748524c618bec5505f46feaef_UNITID_RET_FTL4',\n",
       "  0.19484267796557944,\n",
       "  0.0],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.socrata.data-wa-gov.wajg-ig9g_UNITID_OPEID6',\n",
       "  0.2443284449850829,\n",
       "  0.04948576701950347],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.upload.a817349748524c618bec5505f46feaef_UNITID_OPEID6',\n",
       "  0.2443284449850829,\n",
       "  0.0],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.socrata.data-wa-gov.wajg-ig9g_UNITID_OPEID',\n",
       "  0.2719458459180579,\n",
       "  0.027617400932975017],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.upload.a817349748524c618bec5505f46feaef_UNITID_OPEID',\n",
       "  0.2719458459180582,\n",
       "  2.7755575615628914e-16],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.socrata.data-wa-gov.wajg-ig9g_UNITID_RET_FT4',\n",
       "  0.28538799230431744,\n",
       "  0.013442146386259235],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.upload.a817349748524c618bec5505f46feaef_UNITID_RET_FT4',\n",
       "  0.28538799230431744,\n",
       "  0.0],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.socrata.data-wa-gov.wajg-ig9g_UNITID_PCIP52',\n",
       "  0.2924862570862705,\n",
       "  0.007098264781953079],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.upload.a817349748524c618bec5505f46feaef_UNITID_PCIP52',\n",
       "  0.2924862570862705,\n",
       "  0.0],\n",
       " ['/Users/fchirigati/projects/dataset-ranking/use-cases/data/college-debt/college-debt-v2.csv',\n",
       "  '/Users/fchirigati/projects/dataset-ranking/use-cases/datamart-data/companion-datasets-single-column/datamart.socrata.data-wa-gov.wajg-ig9g_UNITID_PREDDEG',\n",
       "  0.3632643909555502,\n",
       "  0.07077813386927967]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_gradients(candidate_gains):\n",
    "    '''\n",
    "    given a table with features 'candidate' and 'gain_in_r2_score', \n",
    "    this method creates a list with these two fields, sorts it in ascending order of gains \n",
    "    and computes the gradients between elements in positions x and x - 1\n",
    "    '''\n",
    "    gains = sorted([[row['query'], row['candidate'], row['gain_in_r2_score']] \n",
    "                    for index, row in candidate_gains.iterrows()], \n",
    "                   key=lambda x: x[2])\n",
    "    gradients = [float('-inf')]\n",
    "    for index, elem in enumerate(gains):\n",
    "        if index < len(gains) - 1:\n",
    "            gradients.append(gains[index + 1][2] - gains[index][2])\n",
    "            \n",
    "    gains_gradients = []\n",
    "    for gain, gradient in zip(gains, gradients):\n",
    "        gain.append(gradient)\n",
    "        gains_gradients.append(gain)\n",
    "        \n",
    "    return gains_gradients\n",
    "\n",
    "college_gains_gradients = compute_gradients(college_candidate_gains)\n",
    "college_gains_gradients[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It looks like the biggest drop is between the top-rated candidate and the second one. Is it safe to assume that we only have one really good candidate? Maybe we can implement a few different policies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harsh_gradient_policy(candidates_gains_gradients):\n",
    "    '''\n",
    "    Given a list of candidates such that each entry corresponds to \n",
    "    \n",
    "        ['query', candidate', 'gain', 'gradient']\n",
    "    \n",
    "    and the list is sorted (ascending order) based on 'gain',\n",
    "    this method finds the position that corresponds to the largest gradient, \n",
    "    and then sets the class of every candidate equals to or below it position-wise to 'loss'. \n",
    "    The other candidates are linked to label 'gain' unless their 'gain' values are negative.\n",
    "    '''\n",
    "    \n",
    "    # Can't use Python's \"index\" function because it gets the first occurrence of a value. If \n",
    "    # the maximum gradient occurs more than once, we're interested in its last occurrence.\n",
    "    max_gradient = float('-inf')\n",
    "    position = -1\n",
    "    for index, elem in enumerate(reversed(candidates_gains_gradients)):\n",
    "        if elem[3] >= max_gradient:\n",
    "            max_gradient = elem[3]\n",
    "        else: # drop in gradient\n",
    "            position = len(candidates_gains_gradients) - index -1\n",
    "            break\n",
    "    \n",
    "    labels = [(elem[0], elem[1], 'gain') if index > position and elem[2] > 0 else (elem[0], elem[1], 'loss') \n",
    "              for index, elem in enumerate(candidates_gains_gradients)]\n",
    "     \n",
    "    return pd.DataFrame(labels, columns = ['query', 'candidate', 'harsh_grad_class'])\n",
    "\n",
    "def nth_gradient_drop_policy(candidates_gains_gradients, n):\n",
    "    '''\n",
    "    Given a list of candidates such that each entry corresponds to \n",
    "    \n",
    "        ['query', candidate', 'gain', 'gradient']\n",
    "    \n",
    "    and the list is sorted (ascending order) based on 'gain', \n",
    "    and an integer n, this method finds the position that corresponds \n",
    "    to the n-th gradient drop. Next, it sets the class of every candidate \n",
    "    equals to or below it (position-wise) to 'loss'. The other candidates are \n",
    "    linked to label 'gain'.\n",
    "    '''\n",
    "    \n",
    "    max_gradient = float('-inf')\n",
    "    position = -1\n",
    "    drops_seen = 0\n",
    "    for index, elem in enumerate(reversed(candidates_gains_gradients)):\n",
    "        if elem[3] >= max_gradient:\n",
    "            max_gradient = elem[3]\n",
    "        else: # drop in gradient\n",
    "            drops_seen += 1\n",
    "            position = len(candidates_gains_gradients) - index -1\n",
    "            if drops_seen == n:\n",
    "                break\n",
    "            else:\n",
    "                max_gradient = elem[3] #refactor this repetition\n",
    "   \n",
    "    labels = [(elem[0], elem[1], 'gain') if index > position and elem[2] > 0 else (elem[0], elem[1], 'loss') \n",
    "              for index, elem in enumerate(candidates_gains_gradients)]\n",
    "     \n",
    "    return pd.DataFrame(labels, columns = ['query', 'candidate', str(n) + 'th_grad_drop_class'])\n",
    "\n",
    "def get_order_of_magnitude(value):\n",
    "    '''\n",
    "    Returns order of magnitude of a given value\n",
    "    '''\n",
    "    if not value:\n",
    "        return float('-inf')\n",
    "    try:\n",
    "        return math.floor(math.log(np.fabs(value), 10))\n",
    "    except ValueError:\n",
    "        print('*** ERRRRRROOOOOORRR', value)\n",
    "        return None\n",
    "\n",
    "def order_of_magnitude_drop_policy(candidates_gains_gradients):\n",
    "    '''\n",
    "    Given a list of candidates such that each entry corresponds to \n",
    "    \n",
    "        ['query', candidate', 'gain', 'gradient']\n",
    "    \n",
    "    and the list is sorted (ascending order) based on 'gain', this method \n",
    "    finds the position that corresponds to the first drop in an order of \n",
    "    magnitude and sets the class of every candidate equals to or below it \n",
    "    (position-wise) to 'loss'. The other candidates are linked to label 'gain'.\n",
    "    '''\n",
    "    highest_order_of_magnitude = get_order_of_magnitude(candidates_gains_gradients[-1][2])\n",
    "    position = -1\n",
    "    for index, elem in enumerate(reversed(candidates_gains_gradients)):\n",
    "        if get_order_of_magnitude(elem[2]) < highest_order_of_magnitude:\n",
    "            position = len(candidates_gains_gradients) - index -1\n",
    "            break\n",
    "\n",
    "    labels = [(elem[0], elem[1], 'gain') if index > position and elem[2] > 0 else (elem[0], elem[1], 'loss') \n",
    "              for index, elem in enumerate(candidates_gains_gradients)]\n",
    "     \n",
    "    return pd.DataFrame(labels, columns = ['query', 'candidate', 'order_of_mag_drop_class'])\n",
    "\n",
    "def median_based_policy(candidates_gains_gradients):\n",
    "    '''\n",
    "    Given a list of candidates such that each entry corresponds to \n",
    "    \n",
    "        ['query', candidate', 'gain', 'gradient']\n",
    "    \n",
    "    and the list is sorted (ascending order) based on 'gain', this method \n",
    "    gets the median position and sets the class of every candidate equals to or below it \n",
    "    (position-wise) to 'loss'. The other candidates are linked to label 'gain'.\n",
    "    '''\n",
    "    position = math.ceil(len(candidates_gains_gradients)/2)\n",
    "    labels = [(elem[0], elem[1], 'gain') if index > position and elem[2] > 0 else (elem[0], elem[1], 'loss') \n",
    "              for index, elem in enumerate(candidates_gains_gradients)]\n",
    "     \n",
    "    return pd.DataFrame(labels, columns = ['query', 'candidate', 'median_based_class'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's create class labels for datasets based on these different policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original column 'class' in the dataset is such that if 'gain_in_r2_score' > 0, \n",
    "# the label is 'gain'; otherwise, it is 'loss'.\n",
    "college_candidate_gains = college_candidate_gains.rename(columns={'class': 'class_pos_neg'})\n",
    "harsh_gradient_classes = harsh_gradient_policy(college_gains_gradients)\n",
    "second_grad_drop_classes = nth_gradient_drop_policy(college_gains_gradients, 2)\n",
    "order_of_magnitude_drop_classes = order_of_magnitude_drop_policy(college_gains_gradients)\n",
    "median_based_classes = median_based_policy(college_gains_gradients)\n",
    "\n",
    "college_candidate_gains = college_candidate_gains.merge(harsh_gradient_classes, on=['query', 'candidate']) \n",
    "college_candidate_gains = college_candidate_gains.merge(second_grad_drop_classes, on=['query', 'candidate'])\n",
    "college_candidate_gains = college_candidate_gains.merge(order_of_magnitude_drop_classes, on=['query', 'candidate'])\n",
    "college_candidate_gains = college_candidate_gains.merge(median_based_classes, on=['query', 'candidate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 47)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_candidate_gains.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do the same for taxi, poverty, and openml-based datasets that were created for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (447, 39)\n",
      "after (447, 43)\n"
     ]
    }
   ],
   "source": [
    "taxi_candidate_gains = pd.read_csv('../classification/taxi-vehicle-collision-records-features-single-column-w-class')\n",
    "taxi_gains_gradients = compute_gradients(taxi_candidate_gains)\n",
    "print('before', taxi_candidate_gains.shape)\n",
    "\n",
    "taxi_candidate_gains = taxi_candidate_gains.rename(columns={'class': 'class_pos_neg'})\n",
    "harsh_gradient_classes = harsh_gradient_policy(taxi_gains_gradients)\n",
    "second_grad_drop_classes = nth_gradient_drop_policy(taxi_gains_gradients, 2)\n",
    "order_of_magnitude_drop_classes = order_of_magnitude_drop_policy(taxi_gains_gradients)\n",
    "median_based_classes = median_based_policy(taxi_gains_gradients)\n",
    "\n",
    "taxi_candidate_gains = taxi_candidate_gains.merge(harsh_gradient_classes, on=['query', 'candidate']) \n",
    "taxi_candidate_gains = taxi_candidate_gains.merge(second_grad_drop_classes, on=['query', 'candidate'])\n",
    "taxi_candidate_gains = taxi_candidate_gains.merge(order_of_magnitude_drop_classes, on=['query', 'candidate'])\n",
    "taxi_candidate_gains = taxi_candidate_gains.merge(median_based_classes, on=['query', 'candidate'])\n",
    "print('after', taxi_candidate_gains.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before (130928, 37)\n",
      "after (130928, 41)\n"
     ]
    }
   ],
   "source": [
    "poverty_candidate_gains = pd.read_csv('../classification/poverty-estimation-results-features-and-targets-training.csv')\n",
    "poverty_candidate_gains.drop_duplicates(subset=['query', 'candidate'])\n",
    "poverty_gains_gradients = compute_gradients(poverty_candidate_gains)\n",
    "print('before', poverty_candidate_gains.shape)\n",
    "\n",
    "poverty_candidate_gains = poverty_candidate_gains.rename(columns={'class': 'class_pos_neg'})\n",
    "harsh_gradient_classes = harsh_gradient_policy(poverty_gains_gradients).drop_duplicates(subset=['query', 'candidate'])\n",
    "second_grad_drop_classes = nth_gradient_drop_policy(poverty_gains_gradients, 2).drop_duplicates(subset=['query', 'candidate'])\n",
    "order_of_magnitude_drop_classes = order_of_magnitude_drop_policy(poverty_gains_gradients).drop_duplicates(subset=['query', 'candidate'])\n",
    "median_based_classes = median_based_policy(poverty_gains_gradients).drop_duplicates(subset=['query', 'candidate'])\n",
    "\n",
    "poverty_candidate_gains = poverty_candidate_gains.merge(harsh_gradient_classes, on=['query', 'candidate'], how='left') \n",
    "poverty_candidate_gains = poverty_candidate_gains.merge(second_grad_drop_classes, on=['query', 'candidate'], how='left')\n",
    "poverty_candidate_gains = poverty_candidate_gains.merge(order_of_magnitude_drop_classes, on=['query', 'candidate'], how='left')\n",
    "poverty_candidate_gains = poverty_candidate_gains.merge(median_based_classes, on=['query', 'candidate'], how='left')\n",
    "print('after', poverty_candidate_gains.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, regarding the openml-based datasets, we need to separate query by query and treat each one of them as a subproblem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NUMBER OF QUERIES 5138\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "openml_training_candidate_gains = pd.read_csv('../classification/training-simplified-data-generation-many-candidates-per-query_with_median_and_mean_based_classes.csv')\n",
    "openml_training_candidate_gains['class_pos_neg'] = ['loss' if row['gain_in_r2_score'] <= 0 else 'gain' \n",
    "                                                    for index, row in openml_training_candidate_gains.iterrows()]\n",
    "openml_training_candidate_gains = openml_training_candidate_gains.drop_duplicates(subset=['query', 'candidate'])\n",
    "\n",
    "harsh_gradient_classes = []\n",
    "second_grad_drop_classes = []\n",
    "order_of_magnitude_drop_classes = []\n",
    "median_based_classes = []\n",
    "\n",
    "queries = set(openml_training_candidate_gains['query'])\n",
    "number_of_queries = len(queries); i = 0\n",
    "print('*** NUMBER OF QUERIES', number_of_queries)\n",
    "for q in queries:\n",
    "    subtable = openml_training_candidate_gains.loc[openml_training_candidate_gains['query'] == q]\n",
    "    sub_gains_gradients = compute_gradients(subtable)    \n",
    "    \n",
    "    sub_harsh_gradient_classes = harsh_gradient_policy(sub_gains_gradients)\n",
    "    harsh_gradient_classes.append(sub_harsh_gradient_classes)\n",
    "    \n",
    "    sub_second_grad_drop_classes = nth_gradient_drop_policy(sub_gains_gradients, 2)\n",
    "    second_grad_drop_classes.append(sub_second_grad_drop_classes)\n",
    "    \n",
    "    sub_order_of_magnitude_drop_classes = order_of_magnitude_drop_policy(sub_gains_gradients)\n",
    "    order_of_magnitude_drop_classes.append(sub_order_of_magnitude_drop_classes)\n",
    "    \n",
    "    sub_median_based_classes = median_based_policy(sub_gains_gradients)\n",
    "    median_based_classes.append(sub_median_based_classes)\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "harsh_gradient_classes = pd.concat(harsh_gradient_classes).drop_duplicates(subset=['query', 'candidate'])\n",
    "second_grad_drop_classes = pd.concat(second_grad_drop_classes).drop_duplicates(subset=['query', 'candidate'])\n",
    "order_of_magnitude_drop_classes = pd.concat(order_of_magnitude_drop_classes).drop_duplicates(subset=['query', 'candidate'])\n",
    "median_based_classes = pd.concat(median_based_classes).drop_duplicates(subset=['query', 'candidate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('openml_training_many_candidates_harsh_grad_classes.csv', 'w')\n",
    "f.write(harsh_gradient_classes.to_csv(index=False))\n",
    "f.close()\n",
    "\n",
    "f = open('openml_training_many_candidates_second_grad_drop_classes.csv', 'w')\n",
    "f.write(second_grad_drop_classes.to_csv(index=False))\n",
    "f.close()\n",
    "\n",
    "f = open('openml_training_many_candidates_order_magnitude_drop_classes.csv', 'w')\n",
    "f.write(order_of_magnitude_drop_classes.to_csv(index=False))\n",
    "f.close()\n",
    "\n",
    "f = open('openml_training_many_candidates_median_based_classes.csv', 'w')\n",
    "f.write(median_based_classes.to_csv(index=False))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529214, 3) (529214, 3) (529214, 3) (529214, 3) (529214, 39)\n",
      "before (529214, 39)\n",
      "after (529214, 43)\n"
     ]
    }
   ],
   "source": [
    "print(harsh_gradient_classes.shape, \n",
    "      second_grad_drop_classes.shape, \n",
    "      order_of_magnitude_drop_classes.shape,\n",
    "      median_based_classes.shape,\n",
    "      openml_training_candidate_gains.shape\n",
    "     )\n",
    "\n",
    "print('before', openml_training_candidate_gains.shape)\n",
    "openml_training_candidate_gains = openml_training_candidate_gains.merge(harsh_gradient_classes, on=['query', 'candidate'], how='left') \n",
    "openml_training_candidate_gains = openml_training_candidate_gains.merge(second_grad_drop_classes, on=['query', 'candidate'], how='left')\n",
    "openml_training_candidate_gains = openml_training_candidate_gains.merge(order_of_magnitude_drop_classes, on=['query', 'candidate'], how='left')\n",
    "openml_training_candidate_gains = openml_training_candidate_gains.merge(median_based_classes, on=['query', 'candidate'], how='left')\n",
    "print('after', openml_training_candidate_gains.shape)\n",
    "#openml_training_candidate_gains.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do it for the openml test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NUMBER OF QUERIES 1942\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "openml_test_candidate_gains = pd.read_csv('../classification/test-simplified-data-generation-many-candidates-per-query_with_median_and_mean_based_classes.csv')\n",
    "openml_test_candidate_gains['class_pos_neg'] = ['loss' if row['gain_in_r2_score'] <= 0 else 'gain' \n",
    "                                                    for index, row in openml_test_candidate_gains.iterrows()]\n",
    "openml_test_candidate_gains = openml_test_candidate_gains.drop_duplicates(subset=['query', 'candidate'])\n",
    "\n",
    "harsh_gradient_classes = []\n",
    "second_grad_drop_classes = []\n",
    "order_of_magnitude_drop_classes = []\n",
    "median_based_classes = []\n",
    "\n",
    "queries = set(openml_test_candidate_gains['query'])\n",
    "number_of_queries = len(queries); i = 0\n",
    "print('*** NUMBER OF QUERIES', number_of_queries)\n",
    "for q in queries:\n",
    "    subtable = openml_test_candidate_gains.loc[openml_test_candidate_gains['query'] == q]\n",
    "    sub_gains_gradients = compute_gradients(subtable)    \n",
    "    \n",
    "    sub_harsh_gradient_classes = harsh_gradient_policy(sub_gains_gradients)\n",
    "    harsh_gradient_classes.append(sub_harsh_gradient_classes)\n",
    "    \n",
    "    sub_second_grad_drop_classes = nth_gradient_drop_policy(sub_gains_gradients, 2)\n",
    "    second_grad_drop_classes.append(sub_second_grad_drop_classes)\n",
    "    \n",
    "    sub_order_of_magnitude_drop_classes = order_of_magnitude_drop_policy(sub_gains_gradients)\n",
    "    order_of_magnitude_drop_classes.append(sub_order_of_magnitude_drop_classes)\n",
    "    \n",
    "    sub_median_based_classes = median_based_policy(sub_gains_gradients)\n",
    "    median_based_classes.append(sub_median_based_classes)\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "harsh_gradient_classes = pd.concat(harsh_gradient_classes).drop_duplicates(subset=['query', 'candidate'])\n",
    "second_grad_drop_classes = pd.concat(second_grad_drop_classes).drop_duplicates(subset=['query', 'candidate'])\n",
    "order_of_magnitude_drop_classes = pd.concat(order_of_magnitude_drop_classes).drop_duplicates(subset=['query', 'candidate'])\n",
    "median_based_classes = pd.concat(median_based_classes).drop_duplicates(subset=['query', 'candidate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75738, 3) (75738, 3) (75738, 3) (75738, 3) (75738, 39)\n",
      "before (75738, 39)\n",
      "after (75738, 43)\n"
     ]
    }
   ],
   "source": [
    "print(harsh_gradient_classes.shape, \n",
    "      second_grad_drop_classes.shape, \n",
    "      order_of_magnitude_drop_classes.shape,\n",
    "      median_based_classes.shape,\n",
    "      openml_test_candidate_gains.shape\n",
    "     )\n",
    "\n",
    "print('before', openml_test_candidate_gains.shape)\n",
    "openml_test_candidate_gains = openml_test_candidate_gains.merge(harsh_gradient_classes, on=['query', 'candidate'], how='left') \n",
    "openml_test_candidate_gains = openml_test_candidate_gains.merge(second_grad_drop_classes, on=['query', 'candidate'], how='left')\n",
    "openml_test_candidate_gains = openml_test_candidate_gains.merge(order_of_magnitude_drop_classes, on=['query', 'candidate'], how='left')\n",
    "openml_test_candidate_gains = openml_test_candidate_gains.merge(median_based_classes, on=['query', 'candidate'], how='left')\n",
    "print('after', openml_test_candidate_gains.shape)\n",
    "#openml_training_candidate_gains.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's save all these new versions of the datasets on disk now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../classification/college-debt-different-class-definitions.csv', 'w')\n",
    "f.write(college_candidate_gains.to_csv(index=False))\n",
    "f.close()\n",
    "\n",
    "f = open('../classification/taxi-vehicle-collision-different-class-definitions.csv', 'w')\n",
    "f.write(taxi_candidate_gains.to_csv(index=False))\n",
    "f.close()\n",
    "\n",
    "f = open('../classification/poverty-estimation-different-class-definitions.csv', 'w')\n",
    "f.write(poverty_candidate_gains.to_csv(index=False))\n",
    "f.close()\n",
    "\n",
    "f = open('../classification/training-simplified-data-generation-many-candidates-different-class-definitions.csv', 'w')\n",
    "f.write(openml_training_candidate_gains.to_csv(index=False))\n",
    "f.close()\n",
    "\n",
    "f = open('../classification/test-simplified-data-generation-many-candidates-different-class-definitions.csv', 'w')\n",
    "f.write(openml_test_candidate_gains.to_csv(index=False))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
