spark2-submit --deploy-mode cluster --master yarn --files .params.json --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./env/use-cases-data-generation/bin/python --archives use-cases-data-generation-environment.zip#env --driver-memory 3GB --conf spark.driver.memoryOverhead=1G --conf spark.executor.memoryOverhead=1G --num-executors 400 --executor-cores 2 --executor-memory 60G --conf spark.network.timeout=600s --conf spark.dynamicAllocation.enabled=false split-data-for-use-cases.py
