spark2-submit --deploy-mode cluster --master yarn --files .params.json --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./env/data-generation/bin/python --archives data-generation-environment.zip#env --driver-memory 6GB --conf spark.driver.memoryOverhead=3G --conf spark.executor.memoryOverhead=3G --num-executors 200 --executor-cores 2 --executor-memory 60G --conf spark.network.timeout=600s --conf spark.dynamicAllocation.enabled=false generate-training-data-from-datasets.py
