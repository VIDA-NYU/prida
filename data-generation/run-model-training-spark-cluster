spark2-submit --deploy-mode cluster --master yarn --files .params.json --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./env/data-generation/bin/python --archives data-generation-environment.zip#env --driver-memory 3GB --conf spark.driver.memoryOverhead=4G --conf spark.executor.memoryOverhead=4G --num-executors 600 --executor-cores 2 --executor-memory 50G --conf spark.network.timeout=600s --conf spark.executor.heartbeatInterval=30s --conf spark.dynamicAllocation.enabled=false generate-training-data-from-datasets.py
