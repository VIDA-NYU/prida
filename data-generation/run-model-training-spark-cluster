spark2-submit --deploy-mode cluster --master yarn --files .params.json --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./env/data-generation/bin/python --archives data-generation-environment.zip#env --driver-memory 6GB --conf spark.driver.memoryOverhead=1G --conf spark.executor.memoryOverhead=1G --num-executors 240 --executor-cores 3 --executor-memory 10G --conf spark.network.timeout=600s --conf spark.dynamicAllocation.enabled=false generate-training-data-from-datasets.py
